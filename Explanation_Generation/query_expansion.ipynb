{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anamikaghosh_umass_edu/.conda/envs/gpu-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-02 21:57:13,353\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-02 21:57:15 __init__.py:207] Automatically detected platform cuda.\n",
      "WARNING 04-02 21:57:15 config.py:2448] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 04-02 21:57:30 config.py:549] This model supports multiple tasks: {'score', 'generate', 'classify', 'reward', 'embed'}. Defaulting to 'generate'.\n",
      "INFO 04-02 21:57:30 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='/datasets/ai/ibm-granite/hub/models--ibm-granite--granite-3.0-2b-instruct/snapshots/69e41fe735f54cec1792de2ac4f124b6cc84638f', speculative_config=None, tokenizer='/datasets/ai/ibm-granite/hub/models--ibm-granite--granite-3.0-2b-instruct/snapshots/69e41fe735f54cec1792de2ac4f124b6cc84638f', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/datasets/ai/ibm-granite/hub/models--ibm-granite--granite-3.0-2b-instruct/snapshots/69e41fe735f54cec1792de2ac4f124b6cc84638f, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "INFO 04-02 21:57:32 cuda.py:229] Using Flash Attention backend.\n",
      "INFO 04-02 21:57:32 model_runner.py:1110] Starting to load model /datasets/ai/ibm-granite/hub/models--ibm-granite--granite-3.0-2b-instruct/snapshots/69e41fe735f54cec1792de2ac4f124b6cc84638f...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:01<00:01,  1.34s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.61it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.37it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-02 21:57:34 model_runner.py:1115] Loading model weights took 4.7199 GB\n",
      "INFO 04-02 21:57:35 worker.py:267] Memory profiling takes 0.49 seconds\n",
      "INFO 04-02 21:57:35 worker.py:267] the current vLLM instance can use total_gpu_memory (44.52GiB) x gpu_memory_utilization (0.90) = 40.07GiB\n",
      "INFO 04-02 21:57:35 worker.py:267] model weights take 4.72GiB; non_torch_memory takes 0.08GiB; PyTorch activation peak memory takes 0.47GiB; the rest of the memory reserved for KV Cache is 34.80GiB.\n",
      "INFO 04-02 21:57:35 executor_base.py:111] # cuda blocks: 28506, # CPU blocks: 3276\n",
      "INFO 04-02 21:57:35 executor_base.py:116] Maximum concurrency for 4096 tokens per request: 111.35x\n",
      "INFO 04-02 21:57:36 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graph shapes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:11<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-02 21:57:48 model_runner.py:1562] Graph capturing finished in 12 secs, took 0.31 GiB\n",
      "INFO 04-02 21:57:48 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 14.44 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "model_name = \"/datasets/ai/ibm-granite/hub/models--ibm-granite--granite-3.0-2b-instruct/snapshots/69e41fe735f54cec1792de2ac4f124b6cc84638f\"\n",
    "# model_name = \"/datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa\"\n",
    "\n",
    "llm = LLM(\n",
    "            model=model_name,\n",
    "            dtype=\"half\"\n",
    ")\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "            temperature=0.7,\n",
    "            top_p=0.95,\n",
    "            max_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.60s/it, est. speed input: 16.56 toks/s, output: 110.90 toks/s]\n"
     ]
    }
   ],
   "source": [
    "query = \"sort a list in python\"\n",
    "prompts = [f\"Expand the following search query with additional relevant terms and make 20 expanded queries. Seperate each expanded query with '\\n' seperator. \\nQuery: {query}\\nExpanded Queries:\"]\n",
    "\n",
    "results = llm.generate(prompts, sampling_params)\n",
    "explanations = [result.outputs[0].text for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n1. sort a list in python using built-in sort function\\n2. sort a list in python using sorted() function\\n3. sort a list in python using lambda function\\n4. sort a list in python using custom sort function\\n5. sort a list in python using key function\\n6. sort a list in python using reverse order\\n7. sort a list in python using multiple keys\\n8. sort a list in python using custom key function\\n9. sort a list in python using custom comparison function\\n10. sort a list in python using custom sorting algorithm\\n11. sort a list in python using heapq module\\n12. sort a list in python using bisect module\\n13. sort a list in python using heapq.nsmallest() function\\n14. sort a list in python using heapq.nlargest() function\\n15. sort a list in python using sorted() function with key and reverse\\n16. sort a list in python using list.sort() method with key and reverse\\n17. sort a list in python using sorted() function with custom comparison function\\n18. sort a list in python using list.sort() method with custom comparison function\\n19. sort a list in python using heapq.heapify() function\\n20. sort a list in python using heapq.heappush() function']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Scores for candidate explanations: [1.18711262 1.047546   1.15146349 1.18711262 1.15146349 1.15146349\n",
      " 1.15146349 1.09704935 1.09704935 1.09704935 1.15146349 1.15146349\n",
      " 1.047546   1.047546   0.88737757 0.88737757 0.88737757 0.88737757\n",
      " 1.047546   1.047546  ]\n",
      "\n",
      "Original Query: sort a list in python\n",
      "Best Explanation: \n",
      "1. sort a list in python using built-in sort function\n",
      "2. sort a list in python using sorted() function\n",
      "3. sort a list in python using lambda function\n",
      "4. sort a list in python using custom sort function\n",
      "5. sort a list in python using key function\n",
      "6. sort a list in python using reverse order\n",
      "7. sort a list in python using multiple keys\n",
      "8. sort a list in python using custom key function\n",
      "9. sort a list in python using custom comparison function\n",
      "10. sort a list in python using custom sorting algorithm\n",
      "11. sort a list in python using heapq module\n",
      "12. sort a list in python using bisect module\n",
      "13. sort a list in python using heapq.nsmallest() function\n",
      "14. sort a list in python using heapq.nlargest() function\n",
      "15. sort a list in python using sorted() function with key and reverse\n",
      "16. sort a list in python using list.sort() method with key and reverse\n",
      "17. sort a list in python using sorted() function with custom comparison function\n",
      "18. sort a list in python using list.sort() method with custom comparison function\n",
      "19. sort a list in python using heapq.heapify() function\n",
      "20. sort a list in python using heapq.heappush() function\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/anamikaghosh_umass_edu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Ensure you have installed the required packages:\n",
    "# pip install rank-bm25 nltk\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "splitted_explanations = [line.strip() for line in explanations[0].split('\\n') if line.strip()]\n",
    "\n",
    "splitted_explanations = [re.sub(r'^\\d+\\.\\s*', '', exp) for exp in splitted_explanations]\n",
    "\n",
    "original_query = \"sort a list in python\"\n",
    "\n",
    "tokenized_explanations = [word_tokenize(exp.lower()) for exp in splitted_explanations]\n",
    "tokenized_query = word_tokenize(original_query.lower())\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_explanations)\n",
    "\n",
    "scores = bm25.get_scores(tokenized_query)\n",
    "print(\"BM25 Scores for candidate explanations:\", scores)\n",
    "\n",
    "best_index = np.argmax(scores)\n",
    "best_explanation = explanations[best_index]\n",
    "\n",
    "print(\"\\nOriginal Query:\", original_query)\n",
    "print(\"Best Explanation:\", best_explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/anamikaghosh_umass_edu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.50s/it, est. speed input: 7.34 toks/s, output: 111.24 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Enriched Query for BM25:\n",
      "1. Arrange a list in Python 2. Order a list in Python 3. Sort a collection of elements in Python 4. Rearrange a list in Python 5. Arrange elements in a list in Python 6. Order elements in a list in Python 7. Sort a sequence of items in Python 8. Reorder a sequence of items in Python 9. Sort a list of elements in Python 10. Order a list of elements in Python Here is a Python function that sorts a list: ```python def sort_list(input_list): return sorted(input_list) ``` This function uses the built-in `sorted()` function to sort the input list in ascending order. If you want to sort the list in descending order, you can use the `reverse=True` argument: ```python def sort_list_descending(input_list): return sorted(input_list, reverse=True) ``` You can also use the `sort()` method of the list object to sort the list in-place: ```python def sort_list_in_place(input_list): input_list.sort() return input_list ``` The `sort()` method sorts the list in-place, meaning that it modifies the original list and does not return a new sorted list. Here are some examples of how to use these functions: ```python # Sort a list in ascending order numbers = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5] sorted_numbers = sort_list(numbers) print(sorted_numbers)  # [1, 1, 2, 3, 3, 4, 5, 5, 5, 6, 9] # Sort a list in descending order sorted_numbers_descending = sort_list_descending(numbers) print(sorted_numbers_descending)  # [9, 6, 5, 5, 5, 4, 3, 3, 2, 1, 1] # Sort a list in-place sorted_numbers_in_place = sort_list_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "query = \"sort a list in python\"\n",
    "\n",
    "# Step 1: Prompt to generate 20 paraphrased/synonym-expanded versions of the query\n",
    "prompt = f\"\"\"Expand the following search query using synonyms or by rephrasing, maintaining the original intent.\n",
    "Query: {query}\n",
    "Expanded Queries:\n",
    "\"\"\"\n",
    "\n",
    "# Call your LLM to get the list of expanded queries\n",
    "results = llm.generate([prompt], sampling_params)\n",
    "raw_output = results[0].outputs[0].text.strip()\n",
    "\n",
    "# Step 2: Post-process LLM output\n",
    "expanded_queries = [q.strip() for q in raw_output.split(\"\\n\") if q.strip()]\n",
    "\n",
    "# Step 3: Concatenate all expanded queries into a single, enriched query string\n",
    "rich_query = \" \".join(expanded_queries)\n",
    "\n",
    "print(\"üîç Enriched Query for BM25:\")\n",
    "print(rich_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Arrange a list in Python 2. Order a list in Python 3. Sort a collection of elements in Python 4. Rearrange a list in Python 5. Arrange elements in a list in Python 6. Order elements in a list in Python 7. Sort a sequence of items in Python 8. Reorder a sequence of items in Python 9. Sort a list of elements in Python 10. Order a list of elements in Python Here is a Python function that sorts a list: ```python def sort_list(input_list): return sorted(input_list) ``` This function uses the built-in `sorted()` function to sort the input list in ascending order. If you want to sort the list in descending order, you can use the `reverse=True` argument: ```python def sort_list_descending(input_list): return sorted(input_list, reverse=True) ``` You can also use the `sort()` method of the list object to sort the list in-place: ```python def sort_list_in_place(input_list): input_list.sort() return input_list ``` The `sort()` method sorts the list in-place, meaning that it modifies the original list and does not return a new sorted list. Here are some examples of how to use these functions: ```python # Sort a list in ascending order numbers = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5] sorted_numbers = sort_list(numbers) print(sorted_numbers)  # [1, 1, 2, 3, 3, 4, 5, 5, 5, 6, 9] # Sort a list in descending order sorted_numbers_descending = sort_list_descending(numbers) print(sorted_numbers_descending)  # [9, 6, 5, 5, 5, 4, 3, 3, 2, 1, 1] # Sort a list in-place sorted_numbers_in_place = sort_list_'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rich_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_docs = [\n",
    "    \"Sort a list in Python using sorted(). def sort_list(lst): return sorted(lst)\",\n",
    "    \"Sort list elements in-place using list.sort(). def in_place_sort(lst): lst.sort()\",\n",
    "    \"Bubble sort implementation for list sorting. def bubble_sort(arr): for i in range(len(arr)): for j in range(0, len(arr)-i-1): if arr[j] > arr[j+1]: arr[j], arr[j+1] = arr[j+1], arr[j]\",\n",
    "    \"Reverse sort a list in Python. def reverse_sort(lst): return sorted(lst, reverse=True)\",\n",
    "    \"Recursive merge sort in Python. def merge_sort(arr): if len(arr) > 1: mid = len(arr)//2; L = arr[:mid]; R = arr[mid:]; ...\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = [nltk.word_tokenize(doc.lower()) for doc in corpus_docs]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Top Retrieved Code Snippets:\n",
      "\n",
      "1. [Score: 6.75]\n",
      "Bubble sort implementation for list sorting. def bubble_sort(arr): for i in range(len(arr)): for j in range(0, len(arr)-i-1): if arr[j] > arr[j+1]: arr[j], arr[j+1] = arr[j+1], arr[j]\n",
      "\n",
      "2. [Score: 3.54]\n",
      "Reverse sort a list in Python. def reverse_sort(lst): return sorted(lst, reverse=True)\n",
      "\n",
      "3. [Score: 2.26]\n",
      "Sort a list in Python using sorted(). def sort_list(lst): return sorted(lst)\n",
      "\n",
      "4. [Score: 0.88]\n",
      "Recursive merge sort in Python. def merge_sort(arr): if len(arr) > 1: mid = len(arr)//2; L = arr[:mid]; R = arr[mid:]; ...\n",
      "\n",
      "5. [Score: 0.60]\n",
      "Sort list elements in-place using list.sort(). def in_place_sort(lst): lst.sort()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Tokenize the query\n",
    "tokenized_query = nltk.word_tokenize(verbose_query.lower())\n",
    "\n",
    "# Step 3: Score the corpus using BM25\n",
    "scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "# Step 4: Rank documents by BM25 score\n",
    "ranked_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "top_docs = [(corpus_docs[i], scores[i]) for i in ranked_indices]\n",
    "\n",
    "# Step 5: Print top results\n",
    "print(\"üîç Top Retrieved Code Snippets:\\n\")\n",
    "for i, (doc, score) in enumerate(top_docs[:5], 1):\n",
    "    print(f\"{i}. [Score: {score:.2f}]\\n{doc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.68it/s, est. speed input: 232.69 toks/s, output: 92.33 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbose Query:\n",
      " How to systematically arrange a sequence of elements in ascending or descending order using Python's built-in sorting functionality?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"sort a list in python\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Instruction: \n",
    "Respond with only 1 improved query. Make the following query slightly more detailed, while keeping its original meaning. Please do not provide any code, just a rephrased query. Say it in third-person perspective.\n",
    "\n",
    "Query:{query}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# LLM call\n",
    "results = llm.generate([prompt], sampling_params)\n",
    "verbose_query = results[0].outputs[0].text.strip()\n",
    "\n",
    "print(\"Verbose Query:\\n\", verbose_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# raw_output = results[0].outputs[0].text.strip()\n",
    "\n",
    "# match = re.search(r\"Improved Query:\\s*(.*)\", raw_output, re.IGNORECASE)\n",
    "# improved_query = match.group(1).strip() if match else raw_output.strip()\n",
    "\n",
    "# print(\"Improved Query:\", verbose_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_docs = [\n",
    "    \"Sort a list in Python using sorted(). def sort_list(lst): return sorted(lst)\",\n",
    "    \"Sort list elements in-place using list.sort(). def in_place_sort(lst): lst.sort()\",\n",
    "    \"Bubble sort implementation for list sorting. def bubble_sort(arr): for i in range(len(arr)): for j in range(0, len(arr)-i-1): if arr[j] > arr[j+1]: arr[j], arr[j+1] = arr[j+1], arr[j]\",\n",
    "    \"Reverse sort a list in Python. def reverse_sort(lst): return sorted(lst, reverse=True)\",\n",
    "    \"properly arrange a sequence of elements in order,def reverse_sort(lst): return sorted(lst, reverse=True) ?\",\n",
    "    \"Recursive merge sort in Python. def merge_sort(arr): if len(arr) > 1: mid = len(arr)//2; L = arr[:mid]; R = arr[mid:]; ...\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = [nltk.word_tokenize(doc.lower()) for doc in corpus_docs]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Top Retrieved Code Snippets:\n",
      "\n",
      "1. [Score: 8.33]\n",
      "properly arrange a sequence of elements in order,def reverse_sort(lst): return sorted(lst, reverse=True) ?\n",
      "\n",
      "2. [Score: 1.47]\n",
      "Sort list elements in-place using list.sort(). def in_place_sort(lst): lst.sort()\n",
      "\n",
      "3. [Score: 1.03]\n",
      "Bubble sort implementation for list sorting. def bubble_sort(arr): for i in range(len(arr)): for j in range(0, len(arr)-i-1): if arr[j] > arr[j+1]: arr[j], arr[j+1] = arr[j+1], arr[j]\n",
      "\n",
      "4. [Score: 0.87]\n",
      "Sort a list in Python using sorted(). def sort_list(lst): return sorted(lst)\n",
      "\n",
      "5. [Score: 0.18]\n",
      "Reverse sort a list in Python. def reverse_sort(lst): return sorted(lst, reverse=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Tokenize the query\n",
    "tokenized_query = nltk.word_tokenize(verbose_query.lower())\n",
    "\n",
    "# Step 3: Score the corpus using BM25\n",
    "scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "# Step 4: Rank documents by BM25 score\n",
    "ranked_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "top_docs = [(corpus_docs[i], scores[i]) for i in ranked_indices]\n",
    "\n",
    "# Step 5: Print top results\n",
    "print(\"üîç Top Retrieved Code Snippets:\\n\")\n",
    "for i, (doc, score) in enumerate(top_docs[:5], 1):\n",
    "    print(f\"{i}. [Score: {score:.2f}]\\n{doc}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to systematically arrange a sequence of elements in ascending or descending order using Python's built-in sorting functionality?\n"
     ]
    }
   ],
   "source": [
    "print(verbose_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
