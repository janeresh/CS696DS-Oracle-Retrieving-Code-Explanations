{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anamikaghosh_umass_edu/.conda/envs/gpu-env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import logging\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
    "from typing import List, Dict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class YourCustomDEModel:\n",
    "    def __init__(self, model_name=\"intfloat/e5-base-v2\", **kwargs):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(device)\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer.add_eos_token = False\n",
    "\n",
    "        print('YourCustomDEModel init')\n",
    "\n",
    "\n",
    "    def mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "\n",
    "    def cls_pooling(self, model_output, attention_mask):\n",
    "        # First element of model_output contains all token embeddings\n",
    "        token_embeddings = model_output[0]\n",
    "        # Extract the CLS token's embeddings (index 0) for each sequence in the batch\n",
    "        cls_embeddings = token_embeddings[:, 0, :]\n",
    "        return cls_embeddings\n",
    "\n",
    "    def last_token_pool(self, model_output, attention_mask):\n",
    "        last_hidden_states = model_output.last_hidden_state\n",
    "        left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "        if left_padding:\n",
    "            return last_hidden_states[:, -1]\n",
    "        else:\n",
    "            sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "            batch_size = last_hidden_states.shape[0]\n",
    "            return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "    def encode_text(self, texts: List[str], batch_size: int = 12, max_length: int = 128) -> np.ndarray:\n",
    "        logging.info(f\"Encoding {len(texts)} texts...\")\n",
    "\n",
    "        embeddings = []\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Encoding batches\", unit=\"batch\"):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            encoded_input = self.tokenizer(batch_texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(device)\n",
    "            with torch.no_grad():\n",
    "                model_output = self.model(**encoded_input)\n",
    "            batch_embeddings = self.mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "            embeddings.append(batch_embeddings.cpu())\n",
    "\n",
    "        embeddings = torch.cat(embeddings, dim=0)\n",
    "\n",
    "        if embeddings is None:\n",
    "            logging.error(\"Embeddings are None.\")\n",
    "        else:\n",
    "            logging.info(f\"Encoded {len(embeddings)} embeddings.\")\n",
    "\n",
    "        return embeddings.numpy()\n",
    "\n",
    "    def encode_queries(self, queries: List[str], batch_size: int = 12, max_length: int = 512, **kwargs) -> np.ndarray:\n",
    "        all_queries = [\"query: \"+ query for query in queries]\n",
    "        return self.encode_text(all_queries, batch_size, max_length)\n",
    "\n",
    "    def encode_corpus(self, corpus: List[Dict[str, str]], batch_size: int = 12, max_length: int = 512, **kwargs) -> np.ndarray:\n",
    "        all_texts = [\"passage: \"+ doc['text'] for doc in corpus]\n",
    "        #all_texts = [\"passage: \"+ doc for doc in corpus]\n",
    "\n",
    "        return self.encode_text(all_texts, batch_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YourCustomDEModel init\n"
     ]
    }
   ],
   "source": [
    "temp = YourCustomDEModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_multiple_exp(texts, method):\n",
    "#     embeddings = temp.encode_text(texts)\n",
    "#     print(embeddings.shape)\n",
    "\n",
    "#     if method == \"mean\":\n",
    "#         return np.mean(embeddings, axis=0)\n",
    "#     elif method == \"max\":\n",
    "#         return np.max(embeddings, axis=0)\n",
    "#     elif method == \"sum\":\n",
    "#         return np.sum(embeddings, axis=0)\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unsupported aggregation method: {method}\")\n",
    "    \n",
    "\n",
    "# df = pd.read_csv('/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/postprocessing/output/CSN_deepseek_valid_clean.csv')\n",
    "# df1 = df.head(10)\n",
    "# exp_list = df1[['explanation_deepseek_1_cleaned','explanation_deepseek_2_cleaned']].values.tolist()\n",
    "# # emb_list = [encode_multiple_exp(list, method='mean') for list in exp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df1 = pd.read_csv('/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/postprocessing/output/CSN_deepseek_valid_clean.csv')\n",
    "\n",
    "def encode_agg(df, exp_cols, method, model_obj):\n",
    "    exp_list = df[exp_cols].values.tolist()\n",
    "    flat_texts = list(chain.from_iterable(exp_list))  # total N = num_rows × num_explanations\n",
    "\n",
    "    all_embeddings = model_obj.encode_text(flat_texts)  # shape: (N, emb_dim)\n",
    "\n",
    "    num_rows = len(exp_list)\n",
    "    num_exps = len(exp_list[0])\n",
    "    all_embeddings = all_embeddings.reshape(num_rows, num_exps, -1)\n",
    "\n",
    "    # Aggregate in batch using NumPy\n",
    "    if method == \"mean\":\n",
    "        emb_list = np.mean(all_embeddings, axis=1)\n",
    "    elif method == \"max\":\n",
    "        emb_list = np.max(all_embeddings, axis=1)\n",
    "    elif method == \"sum\":\n",
    "        emb_list = np.sum(all_embeddings, axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method\")\n",
    "    end = time.time()\n",
    "    print(f'Total time = {end-start} seconds')\n",
    "\n",
    "    return emb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'query_id', 'corpus_id', 'doc', 'code', 'cleaned_code',\n",
       "       'explanation_deepseek_1', 'explanation_deepseek_2',\n",
       "       'explanation_deepseek_3', 'explanation_deepseek_4',\n",
       "       'explanation_deepseek_5', 'explanation_deepseek_1_cleaned',\n",
       "       'explanation_deepseek_2_cleaned', 'explanation_deepseek_3_cleaned',\n",
       "       'explanation_deepseek_4_cleaned', 'explanation_deepseek_5_cleaned'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding batches: 100%|██████████| 2298/2298 [00:37<00:00, 61.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time = 255.66733860969543 seconds\n"
     ]
    }
   ],
   "source": [
    "df1['mean_emb'] = list(encode_agg(df1, ['explanation_deepseek_1_cleaned','explanation_deepseek_2_cleaned'], 'mean', temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>doc</th>\n",
       "      <th>code</th>\n",
       "      <th>cleaned_code</th>\n",
       "      <th>explanation_deepseek_1</th>\n",
       "      <th>explanation_deepseek_2</th>\n",
       "      <th>explanation_deepseek_3</th>\n",
       "      <th>explanation_deepseek_4</th>\n",
       "      <th>explanation_deepseek_5</th>\n",
       "      <th>explanation_deepseek_1_cleaned</th>\n",
       "      <th>explanation_deepseek_2_cleaned</th>\n",
       "      <th>explanation_deepseek_3_cleaned</th>\n",
       "      <th>explanation_deepseek_4_cleaned</th>\n",
       "      <th>explanation_deepseek_5_cleaned</th>\n",
       "      <th>mean_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>q251820</td>\n",
       "      <td>c251820</td>\n",
       "      <td>Save model to a pickle located at `path`</td>\n",
       "      <td>def save_act(self, path=None):\\n        \"\"\"Sav...</td>\n",
       "      <td>\\ndef save_act(self, path=None):\\n\\n        if...</td>\n",
       "      <td>The code saves a model to a file and then uses...</td>\n",
       "      <td>Okay, I'm trying to understand this code snipp...</td>\n",
       "      <td>This code snippet does something to save and s...</td>\n",
       "      <td>The code snippet is a method called save_act w...</td>\n",
       "      <td>The code in entry['code'] sets the path for wh...</td>\n",
       "      <td>The code saves a model to a file and then uses...</td>\n",
       "      <td>Okay, I'm trying to understand this code snipp...</td>\n",
       "      <td>This code snippet does something to save and s...</td>\n",
       "      <td>The code snippet is a method called save_act w...</td>\n",
       "      <td>The code in entry['code'] sets the path for wh...</td>\n",
       "      <td>[-0.16336083, -0.67789125, -0.08247605, 0.0169...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>q251821</td>\n",
       "      <td>c251821</td>\n",
       "      <td>CNN from Nature paper.</td>\n",
       "      <td>def nature_cnn(unscaled_images, **conv_kwargs)...</td>\n",
       "      <td>\\ndef nature_cnn(unscaled_images, **conv_kwarg...</td>\n",
       "      <td>The code converts the input images into a scal...</td>\n",
       "      <td>Okay, I'm going to try to break down this code...</td>\n",
       "      <td>The code snippet does the following:\\n\\n1. It ...</td>\n",
       "      <td>The code snippet is a function called nature_c...</td>\n",
       "      <td>The code implements a deep neural network to p...</td>\n",
       "      <td>The code converts the input images into a scal...</td>\n",
       "      <td>Okay, I'm going to try to break down this code...</td>\n",
       "      <td>The code snippet does the following:1. It take...</td>\n",
       "      <td>The code snippet is a function called nature_c...</td>\n",
       "      <td>The code implements a deep neural network to p...</td>\n",
       "      <td>[-0.13151847, -0.74018204, -0.54601645, -0.100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>q251822</td>\n",
       "      <td>c251822</td>\n",
       "      <td>convolutions-only net\\n\\n    Parameters:\\n    ...</td>\n",
       "      <td>def conv_only(convs=[(32, 8, 4), (64, 4, 2), (...</td>\n",
       "      <td>\\ndef conv_only(convs=[(32, 8, 4), (64, 4, 2),...</td>\n",
       "      <td>The code defines a function called conv_only, ...</td>\n",
       "      <td>Okay, so I'm trying to understand this code sn...</td>\n",
       "      <td>This code creates a function called conv_only ...</td>\n",
       "      <td>The code defines a function called conv_only t...</td>\n",
       "      <td>The code snippet in entry['code'] implements a...</td>\n",
       "      <td>The code defines a function called conv_only, ...</td>\n",
       "      <td>Okay, so I'm trying to understand this code sn...</td>\n",
       "      <td>This code creates a function called conv_only ...</td>\n",
       "      <td>The code defines a function called conv_only t...</td>\n",
       "      <td>The code snippet in entry['code'] implements a...</td>\n",
       "      <td>[0.0032902882, -0.7050658, -0.36576706, -0.259...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>q251823</td>\n",
       "      <td>c251823</td>\n",
       "      <td>Create a wrapped, monitored SubprocVecEnv for ...</td>\n",
       "      <td>def make_vec_env(env_id, env_type, num_env, se...</td>\n",
       "      <td>\\ndef make_vec_env(env_id, env_type, num_env, ...</td>\n",
       "      <td>The code creates a vector environment for mult...</td>\n",
       "      <td>Okay, I'm trying to understand this code snipp...</td>\n",
       "      <td>This code creates a function called make_vec_e...</td>\n",
       "      <td>The code defines a function called make_vec_en...</td>\n",
       "      <td>The code snippet in entry['code'] is responsib...</td>\n",
       "      <td>The code creates a vector environment for mult...</td>\n",
       "      <td>Okay, I'm trying to understand this code snipp...</td>\n",
       "      <td>This code creates a function called make_vec_e...</td>\n",
       "      <td>The code defines a function called make_vec_en...</td>\n",
       "      <td>The code snippet in entry['code'] is responsib...</td>\n",
       "      <td>[0.16048774, -0.76488286, -0.4442173, -0.01827...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>q251824</td>\n",
       "      <td>c251824</td>\n",
       "      <td>Parse arguments not consumed by arg parser int...</td>\n",
       "      <td>def parse_unknown_args(args):\\n    \"\"\"\\n    Pa...</td>\n",
       "      <td>\\ndef parse_unknown_args(args):\\n\\n    retval ...</td>\n",
       "      <td>The code parses unknown arguments by looking f...</td>\n",
       "      <td>... (this...)\\n&lt;/think&gt;\\n\\ndef parse_unknown_a...</td>\n",
       "      <td>This code is used to parse unknown arguments. ...</td>\n",
       "      <td>def parse_unknown_args(args):\\n    def parse_u...</td>\n",
       "      <td>Please think about the connection between code...</td>\n",
       "      <td>The code parses unknown arguments by looking f...</td>\n",
       "      <td>... (this...)def parse_unknown_args(args):    ...</td>\n",
       "      <td>This code is used to parse unknown arguments. ...</td>\n",
       "      <td>def parse_unknown_args(args):    def parse_unk...</td>\n",
       "      <td>Please think about the connection between code...</td>\n",
       "      <td>[-0.1587004, -0.40531266, -0.6960724, -0.21294...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 query_id corpus_id  \\\n",
       "0           0  q251820   c251820   \n",
       "1           1  q251821   c251821   \n",
       "2           2  q251822   c251822   \n",
       "3           3  q251823   c251823   \n",
       "4           4  q251824   c251824   \n",
       "\n",
       "                                                 doc  \\\n",
       "0           Save model to a pickle located at `path`   \n",
       "1                             CNN from Nature paper.   \n",
       "2  convolutions-only net\\n\\n    Parameters:\\n    ...   \n",
       "3  Create a wrapped, monitored SubprocVecEnv for ...   \n",
       "4  Parse arguments not consumed by arg parser int...   \n",
       "\n",
       "                                                code  \\\n",
       "0  def save_act(self, path=None):\\n        \"\"\"Sav...   \n",
       "1  def nature_cnn(unscaled_images, **conv_kwargs)...   \n",
       "2  def conv_only(convs=[(32, 8, 4), (64, 4, 2), (...   \n",
       "3  def make_vec_env(env_id, env_type, num_env, se...   \n",
       "4  def parse_unknown_args(args):\\n    \"\"\"\\n    Pa...   \n",
       "\n",
       "                                        cleaned_code  \\\n",
       "0  \\ndef save_act(self, path=None):\\n\\n        if...   \n",
       "1  \\ndef nature_cnn(unscaled_images, **conv_kwarg...   \n",
       "2  \\ndef conv_only(convs=[(32, 8, 4), (64, 4, 2),...   \n",
       "3  \\ndef make_vec_env(env_id, env_type, num_env, ...   \n",
       "4  \\ndef parse_unknown_args(args):\\n\\n    retval ...   \n",
       "\n",
       "                              explanation_deepseek_1  \\\n",
       "0  The code saves a model to a file and then uses...   \n",
       "1  The code converts the input images into a scal...   \n",
       "2  The code defines a function called conv_only, ...   \n",
       "3  The code creates a vector environment for mult...   \n",
       "4  The code parses unknown arguments by looking f...   \n",
       "\n",
       "                              explanation_deepseek_2  \\\n",
       "0  Okay, I'm trying to understand this code snipp...   \n",
       "1  Okay, I'm going to try to break down this code...   \n",
       "2  Okay, so I'm trying to understand this code sn...   \n",
       "3  Okay, I'm trying to understand this code snipp...   \n",
       "4  ... (this...)\\n</think>\\n\\ndef parse_unknown_a...   \n",
       "\n",
       "                              explanation_deepseek_3  \\\n",
       "0  This code snippet does something to save and s...   \n",
       "1  The code snippet does the following:\\n\\n1. It ...   \n",
       "2  This code creates a function called conv_only ...   \n",
       "3  This code creates a function called make_vec_e...   \n",
       "4  This code is used to parse unknown arguments. ...   \n",
       "\n",
       "                              explanation_deepseek_4  \\\n",
       "0  The code snippet is a method called save_act w...   \n",
       "1  The code snippet is a function called nature_c...   \n",
       "2  The code defines a function called conv_only t...   \n",
       "3  The code defines a function called make_vec_en...   \n",
       "4  def parse_unknown_args(args):\\n    def parse_u...   \n",
       "\n",
       "                              explanation_deepseek_5  \\\n",
       "0  The code in entry['code'] sets the path for wh...   \n",
       "1  The code implements a deep neural network to p...   \n",
       "2  The code snippet in entry['code'] implements a...   \n",
       "3  The code snippet in entry['code'] is responsib...   \n",
       "4  Please think about the connection between code...   \n",
       "\n",
       "                      explanation_deepseek_1_cleaned  \\\n",
       "0  The code saves a model to a file and then uses...   \n",
       "1  The code converts the input images into a scal...   \n",
       "2  The code defines a function called conv_only, ...   \n",
       "3  The code creates a vector environment for mult...   \n",
       "4  The code parses unknown arguments by looking f...   \n",
       "\n",
       "                      explanation_deepseek_2_cleaned  \\\n",
       "0  Okay, I'm trying to understand this code snipp...   \n",
       "1  Okay, I'm going to try to break down this code...   \n",
       "2  Okay, so I'm trying to understand this code sn...   \n",
       "3  Okay, I'm trying to understand this code snipp...   \n",
       "4  ... (this...)def parse_unknown_args(args):    ...   \n",
       "\n",
       "                      explanation_deepseek_3_cleaned  \\\n",
       "0  This code snippet does something to save and s...   \n",
       "1  The code snippet does the following:1. It take...   \n",
       "2  This code creates a function called conv_only ...   \n",
       "3  This code creates a function called make_vec_e...   \n",
       "4  This code is used to parse unknown arguments. ...   \n",
       "\n",
       "                      explanation_deepseek_4_cleaned  \\\n",
       "0  The code snippet is a method called save_act w...   \n",
       "1  The code snippet is a function called nature_c...   \n",
       "2  The code defines a function called conv_only t...   \n",
       "3  The code defines a function called make_vec_en...   \n",
       "4  def parse_unknown_args(args):    def parse_unk...   \n",
       "\n",
       "                      explanation_deepseek_5_cleaned  \\\n",
       "0  The code in entry['code'] sets the path for wh...   \n",
       "1  The code implements a deep neural network to p...   \n",
       "2  The code snippet in entry['code'] implements a...   \n",
       "3  The code snippet in entry['code'] is responsib...   \n",
       "4  Please think about the connection between code...   \n",
       "\n",
       "                                            mean_emb  \n",
       "0  [-0.16336083, -0.67789125, -0.08247605, 0.0169...  \n",
       "1  [-0.13151847, -0.74018204, -0.54601645, -0.100...  \n",
       "2  [0.0032902882, -0.7050658, -0.36576706, -0.259...  \n",
       "3  [0.16048774, -0.76488286, -0.4442173, -0.01827...  \n",
       "4  [-0.1587004, -0.40531266, -0.6960724, -0.21294...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
