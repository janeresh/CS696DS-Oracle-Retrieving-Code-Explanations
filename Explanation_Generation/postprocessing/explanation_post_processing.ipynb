{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_output(text,keywords):\n",
    "#     for key in keywords:\n",
    "#         index = text.rfind(key)  # Find the last occurrence of keyword\n",
    "#         if index != -1:\n",
    "#             text =  text[index + len(key):].strip()  \n",
    "#     return text\n",
    "\n",
    "def clean_output(text, keywords):\n",
    "    for key in keywords:\n",
    "        text = text.replace(key, \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/output/CSN_deepseek_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'query_id', 'corpus_id', 'score', 'doc',\n",
       "       'code', 'cleaned_code', 'explanation_deepseek_1',\n",
       "       'explanation_deepseek_2', 'explanation_deepseek_3',\n",
       "       'explanation_deepseek_4', 'explanation_deepseek_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14702, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>score</th>\n",
       "      <th>doc</th>\n",
       "      <th>code</th>\n",
       "      <th>cleaned_code</th>\n",
       "      <th>explanation_deepseek_1</th>\n",
       "      <th>explanation_deepseek_2</th>\n",
       "      <th>explanation_deepseek_3</th>\n",
       "      <th>explanation_deepseek_4</th>\n",
       "      <th>explanation_deepseek_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>q265734</td>\n",
       "      <td>c265608</td>\n",
       "      <td>1</td>\n",
       "      <td>str-&gt;list\\n    Convert XML to URL List.\\n    F...</td>\n",
       "      <td>def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...</td>\n",
       "      <td>\\ndef sina_xml_to_url_list(xml_data):\\n\\n    r...</td>\n",
       "      <td>The code parses the XML data into a list of UR...</td>\n",
       "      <td>Here's a detailed explanation of the code snip...</td>\n",
       "      <td>The code parses an XML data and extracts URLs ...</td>\n",
       "      <td>The code defines a function called sina_xml_to...</td>\n",
       "      <td>The code snippet in entry['code'] implements t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>q265735</td>\n",
       "      <td>c265609</td>\n",
       "      <td>1</td>\n",
       "      <td>Downloads Dailymotion videos by URL.</td>\n",
       "      <td>def dailymotion_download(url, output_dir='.', ...</td>\n",
       "      <td>\\ndef dailymotion_download(url, output_dir='.'...</td>\n",
       "      <td>The code defines a function called dailymotion...</td>\n",
       "      <td>Okay, so I'm trying to understand this Python ...</td>\n",
       "      <td>This code snippet is a function called dailymo...</td>\n",
       "      <td>The code snippet is a function named dailymoti...</td>\n",
       "      <td>&lt;/think&gt;\\n\\n```python\\ndef dailymotion_downloa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>q265736</td>\n",
       "      <td>c265610</td>\n",
       "      <td>1</td>\n",
       "      <td>Downloads Sina videos by URL.</td>\n",
       "      <td>def sina_download(url, output_dir='.', merge=T...</td>\n",
       "      <td>\\ndef sina_download(url, output_dir='.', merge...</td>\n",
       "      <td>The code defines a function called sina_downlo...</td>\n",
       "      <td>&lt;/think&gt;\\n\\ndef sina_download(url, output_dir=...</td>\n",
       "      <td>The code snippet is a function called sina_dow...</td>\n",
       "      <td>The code snippet is a function called sina_dow...</td>\n",
       "      <td>The code snippet uses a series of regular expr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>q265737</td>\n",
       "      <td>c265611</td>\n",
       "      <td>1</td>\n",
       "      <td>Format text with color or other effects into A...</td>\n",
       "      <td>def sprint(text, *colors):\\n    \"\"\"Format text...</td>\n",
       "      <td>\\ndef sprint(text, *colors):\\n\\n    return \"\\3...</td>\n",
       "      <td>The code takes text and multiple colors, then ...</td>\n",
       "      <td>...\\n```\\n\\nNow, let's proceed to the problem....</td>\n",
       "      <td>This code takes a string of text and colors an...</td>\n",
       "      <td>``\\n\\nNow, create the code that can generate t...</td>\n",
       "      <td>The code snippet in entry['code'] implements t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>q265738</td>\n",
       "      <td>c265612</td>\n",
       "      <td>1</td>\n",
       "      <td>Print a log message to standard error.</td>\n",
       "      <td>def print_log(text, *colors):\\n    \"\"\"Print a ...</td>\n",
       "      <td>\\ndef print_log(text, *colors):\\n\\n    sys.std...</td>\n",
       "      <td>The code prints the log of the given text with...</td>\n",
       "      <td>Okay, so I'm trying to understand this code sn...</td>\n",
       "      <td>This code prints messages to standard error us...</td>\n",
       "      <td>Okay, I have to explain the code snippet and t...</td>\n",
       "      <td>``\\nThe code snippet 'entry['code']' in the co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0 query_id corpus_id  score  \\\n",
       "0             0           0  q265734   c265608      1   \n",
       "1             1           1  q265735   c265609      1   \n",
       "2             2           2  q265736   c265610      1   \n",
       "3             3           3  q265737   c265611      1   \n",
       "4             4           4  q265738   c265612      1   \n",
       "\n",
       "                                                 doc  \\\n",
       "0  str->list\\n    Convert XML to URL List.\\n    F...   \n",
       "1               Downloads Dailymotion videos by URL.   \n",
       "2                      Downloads Sina videos by URL.   \n",
       "3  Format text with color or other effects into A...   \n",
       "4             Print a log message to standard error.   \n",
       "\n",
       "                                                code  \\\n",
       "0  def sina_xml_to_url_list(xml_data):\\n    \"\"\"st...   \n",
       "1  def dailymotion_download(url, output_dir='.', ...   \n",
       "2  def sina_download(url, output_dir='.', merge=T...   \n",
       "3  def sprint(text, *colors):\\n    \"\"\"Format text...   \n",
       "4  def print_log(text, *colors):\\n    \"\"\"Print a ...   \n",
       "\n",
       "                                        cleaned_code  \\\n",
       "0  \\ndef sina_xml_to_url_list(xml_data):\\n\\n    r...   \n",
       "1  \\ndef dailymotion_download(url, output_dir='.'...   \n",
       "2  \\ndef sina_download(url, output_dir='.', merge...   \n",
       "3  \\ndef sprint(text, *colors):\\n\\n    return \"\\3...   \n",
       "4  \\ndef print_log(text, *colors):\\n\\n    sys.std...   \n",
       "\n",
       "                              explanation_deepseek_1  \\\n",
       "0  The code parses the XML data into a list of UR...   \n",
       "1  The code defines a function called dailymotion...   \n",
       "2  The code defines a function called sina_downlo...   \n",
       "3  The code takes text and multiple colors, then ...   \n",
       "4  The code prints the log of the given text with...   \n",
       "\n",
       "                              explanation_deepseek_2  \\\n",
       "0  Here's a detailed explanation of the code snip...   \n",
       "1  Okay, so I'm trying to understand this Python ...   \n",
       "2  </think>\\n\\ndef sina_download(url, output_dir=...   \n",
       "3  ...\\n```\\n\\nNow, let's proceed to the problem....   \n",
       "4  Okay, so I'm trying to understand this code sn...   \n",
       "\n",
       "                              explanation_deepseek_3  \\\n",
       "0  The code parses an XML data and extracts URLs ...   \n",
       "1  This code snippet is a function called dailymo...   \n",
       "2  The code snippet is a function called sina_dow...   \n",
       "3  This code takes a string of text and colors an...   \n",
       "4  This code prints messages to standard error us...   \n",
       "\n",
       "                              explanation_deepseek_4  \\\n",
       "0  The code defines a function called sina_xml_to...   \n",
       "1  The code snippet is a function named dailymoti...   \n",
       "2  The code snippet is a function called sina_dow...   \n",
       "3  ``\\n\\nNow, create the code that can generate t...   \n",
       "4  Okay, I have to explain the code snippet and t...   \n",
       "\n",
       "                              explanation_deepseek_5  \n",
       "0  The code snippet in entry['code'] implements t...  \n",
       "1  </think>\\n\\n```python\\ndef dailymotion_downloa...  \n",
       "2  The code snippet uses a series of regular expr...  \n",
       "3  The code snippet in entry['code'] implements t...  \n",
       "4  ``\\nThe code snippet 'entry['code']' in the co...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(df, columns_list, output_path):\n",
    "    cleaned_cols = []\n",
    "    for col in columns_list:\n",
    "        df[f'{col}_cleaned'] = df[f'{col}'].apply(lambda x: clean_output(x, [\"Answer:\", \"</think>\", \"\\n\"]))\n",
    "        cleaned_cols.append(f'{col}_cleaned')\n",
    "    \n",
    "    final_cols = ['query_id', 'corpus_id', 'doc', 'code', 'cleaned_code'] + columns_list + cleaned_cols\n",
    "    df[final_cols].to_csv(output_path)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/output/CSN_deepseek_train.csv'\n",
    "output_path = '/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/postprocessing/output/CSN_deepseek_train_clean.csv'\n",
    "exp_cols = ['explanation_deepseek_1','explanation_deepseek_2','explanation_deepseek_3','explanation_deepseek_4','explanation_deepseek_5']\n",
    "df = pd.read_csv(input_path)\n",
    "postprocessing(df, exp_cols, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/postprocessing/output/CSN_deepseek_train_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>doc</th>\n",
       "      <th>code</th>\n",
       "      <th>explanation_deepseek_1</th>\n",
       "      <th>explanation_deepseek_2</th>\n",
       "      <th>explanation_deepseek_3</th>\n",
       "      <th>explanation_deepseek_4</th>\n",
       "      <th>explanation_deepseek_5</th>\n",
       "      <th>explanation_deepseek_1_cleaned</th>\n",
       "      <th>explanation_deepseek_2_cleaned</th>\n",
       "      <th>explanation_deepseek_3_cleaned</th>\n",
       "      <th>explanation_deepseek_4_cleaned</th>\n",
       "      <th>explanation_deepseek_5_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>q0</td>\n",
       "      <td>c0</td>\n",
       "      <td>Set the text for this element.\\n\\n        Argu...</td>\n",
       "      <td>def settext(self, text, cls='current'):\\n     ...</td>\n",
       "      <td>The code sets the value of a TextContent widge...</td>\n",
       "      <td>...\\n\\nAlright, so I have this code snippet to...</td>\n",
       "      <td>This code snippet is used to set the text of a...</td>\n",
       "      <td>The code snippet is a method defined in a clas...</td>\n",
       "      <td>The code snippet in entry['code'] implements t...</td>\n",
       "      <td>The code sets the value of a TextContent widge...</td>\n",
       "      <td>...Alright, so I have this code snippet to exp...</td>\n",
       "      <td>This code snippet is used to set the text of a...</td>\n",
       "      <td>The code snippet is a method defined in a clas...</td>\n",
       "      <td>The code snippet in entry['code'] implements t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>q1</td>\n",
       "      <td>c1</td>\n",
       "      <td>Associate a document with this element.\\n\\n   ...</td>\n",
       "      <td>def setdocument(self, doc):\\n        \"\"\"Associ...</td>\n",
       "      <td>The code sets the document for an element, ens...</td>\n",
       "      <td>Okay, so I'm trying to understand this Python ...</td>\n",
       "      <td>This code snippet is designed to manage docume...</td>\n",
       "      <td>def setdocument(self, doc):\\n\\n    assert isin...</td>\n",
       "      <td>Okay, so I've got this code snippet here that'...</td>\n",
       "      <td>The code sets the document for an element, ens...</td>\n",
       "      <td>Okay, so I'm trying to understand this Python ...</td>\n",
       "      <td>This code snippet is designed to manage docume...</td>\n",
       "      <td>def setdocument(self, doc):    assert isinstan...</td>\n",
       "      <td>Okay, so I've got this code snippet here that'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>q2</td>\n",
       "      <td>c2</td>\n",
       "      <td>Tests whether a new element of this class can ...</td>\n",
       "      <td>def addable(Class, parent, set=None, raiseexce...</td>\n",
       "      <td>&lt;/think&gt;\\n\\nThe code checks if a class is adda...</td>\n",
       "      <td>Alright, so I've got this Python function call...</td>\n",
       "      <td>&lt;/think&gt;\\n\\nThis code snippet is a function ca...</td>\n",
       "      <td>``&lt;think&gt;\\nOkay, so I need to explain this Pyt...</td>\n",
       "      <td>The code snippet is the addable method. The me...</td>\n",
       "      <td>The code checks if a class is addable based on...</td>\n",
       "      <td>Alright, so I've got this Python function call...</td>\n",
       "      <td>This code snippet is a function called addable...</td>\n",
       "      <td>``&lt;think&gt;Okay, so I need to explain this Pytho...</td>\n",
       "      <td>The code snippet is the addable method. The me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>q3</td>\n",
       "      <td>c3</td>\n",
       "      <td>This method will be called after an element is...</td>\n",
       "      <td>def postappend(self):\\n        \"\"\"This method ...</td>\n",
       "      <td>The code checks if the current document is not...</td>\n",
       "      <td>...\\nAlright, so I've got this Python code sni...</td>\n",
       "      <td>This code snippet is designed to modify a docu...</td>\n",
       "      <td>The code snippet defines a class called Postap...</td>\n",
       "      <td>&lt;/think&gt;\\n\\nThe code snippet in `entry['code']...</td>\n",
       "      <td>The code checks if the current document is not...</td>\n",
       "      <td>...Alright, so I've got this Python code snipp...</td>\n",
       "      <td>This code snippet is designed to modify a docu...</td>\n",
       "      <td>The code snippet defines a class called Postap...</td>\n",
       "      <td>The code snippet in `entry['code']` implements...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>q4</td>\n",
       "      <td>c4</td>\n",
       "      <td>Recompute textual value based on the text cont...</td>\n",
       "      <td>def updatetext(self):\\n        \"\"\"Recompute te...</td>\n",
       "      <td>The code updates the text of each child in sel...</td>\n",
       "      <td>Okay, so I'm trying to understand this code sn...</td>\n",
       "      <td>This code snippet is designed to update some t...</td>\n",
       "      <td>The code snippet is a method called updatetext...</td>\n",
       "      <td>The code snippet in entry['code'] is responsib...</td>\n",
       "      <td>The code updates the text of each child in sel...</td>\n",
       "      <td>Okay, so I'm trying to understand this code sn...</td>\n",
       "      <td>This code snippet is designed to update some t...</td>\n",
       "      <td>The code snippet is a method called updatetext...</td>\n",
       "      <td>The code snippet in entry['code'] is responsib...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 query_id corpus_id  \\\n",
       "0           0       q0        c0   \n",
       "1           1       q1        c1   \n",
       "2           2       q2        c2   \n",
       "3           3       q3        c3   \n",
       "4           4       q4        c4   \n",
       "\n",
       "                                                 doc  \\\n",
       "0  Set the text for this element.\\n\\n        Argu...   \n",
       "1  Associate a document with this element.\\n\\n   ...   \n",
       "2  Tests whether a new element of this class can ...   \n",
       "3  This method will be called after an element is...   \n",
       "4  Recompute textual value based on the text cont...   \n",
       "\n",
       "                                                code  \\\n",
       "0  def settext(self, text, cls='current'):\\n     ...   \n",
       "1  def setdocument(self, doc):\\n        \"\"\"Associ...   \n",
       "2  def addable(Class, parent, set=None, raiseexce...   \n",
       "3  def postappend(self):\\n        \"\"\"This method ...   \n",
       "4  def updatetext(self):\\n        \"\"\"Recompute te...   \n",
       "\n",
       "                              explanation_deepseek_1  \\\n",
       "0  The code sets the value of a TextContent widge...   \n",
       "1  The code sets the document for an element, ens...   \n",
       "2  </think>\\n\\nThe code checks if a class is adda...   \n",
       "3  The code checks if the current document is not...   \n",
       "4  The code updates the text of each child in sel...   \n",
       "\n",
       "                              explanation_deepseek_2  \\\n",
       "0  ...\\n\\nAlright, so I have this code snippet to...   \n",
       "1  Okay, so I'm trying to understand this Python ...   \n",
       "2  Alright, so I've got this Python function call...   \n",
       "3  ...\\nAlright, so I've got this Python code sni...   \n",
       "4  Okay, so I'm trying to understand this code sn...   \n",
       "\n",
       "                              explanation_deepseek_3  \\\n",
       "0  This code snippet is used to set the text of a...   \n",
       "1  This code snippet is designed to manage docume...   \n",
       "2  </think>\\n\\nThis code snippet is a function ca...   \n",
       "3  This code snippet is designed to modify a docu...   \n",
       "4  This code snippet is designed to update some t...   \n",
       "\n",
       "                              explanation_deepseek_4  \\\n",
       "0  The code snippet is a method defined in a clas...   \n",
       "1  def setdocument(self, doc):\\n\\n    assert isin...   \n",
       "2  ``<think>\\nOkay, so I need to explain this Pyt...   \n",
       "3  The code snippet defines a class called Postap...   \n",
       "4  The code snippet is a method called updatetext...   \n",
       "\n",
       "                              explanation_deepseek_5  \\\n",
       "0  The code snippet in entry['code'] implements t...   \n",
       "1  Okay, so I've got this code snippet here that'...   \n",
       "2  The code snippet is the addable method. The me...   \n",
       "3  </think>\\n\\nThe code snippet in `entry['code']...   \n",
       "4  The code snippet in entry['code'] is responsib...   \n",
       "\n",
       "                      explanation_deepseek_1_cleaned  \\\n",
       "0  The code sets the value of a TextContent widge...   \n",
       "1  The code sets the document for an element, ens...   \n",
       "2  The code checks if a class is addable based on...   \n",
       "3  The code checks if the current document is not...   \n",
       "4  The code updates the text of each child in sel...   \n",
       "\n",
       "                      explanation_deepseek_2_cleaned  \\\n",
       "0  ...Alright, so I have this code snippet to exp...   \n",
       "1  Okay, so I'm trying to understand this Python ...   \n",
       "2  Alright, so I've got this Python function call...   \n",
       "3  ...Alright, so I've got this Python code snipp...   \n",
       "4  Okay, so I'm trying to understand this code sn...   \n",
       "\n",
       "                      explanation_deepseek_3_cleaned  \\\n",
       "0  This code snippet is used to set the text of a...   \n",
       "1  This code snippet is designed to manage docume...   \n",
       "2  This code snippet is a function called addable...   \n",
       "3  This code snippet is designed to modify a docu...   \n",
       "4  This code snippet is designed to update some t...   \n",
       "\n",
       "                      explanation_deepseek_4_cleaned  \\\n",
       "0  The code snippet is a method defined in a clas...   \n",
       "1  def setdocument(self, doc):    assert isinstan...   \n",
       "2  ``<think>Okay, so I need to explain this Pytho...   \n",
       "3  The code snippet defines a class called Postap...   \n",
       "4  The code snippet is a method called updatetext...   \n",
       "\n",
       "                      explanation_deepseek_5_cleaned  \n",
       "0  The code snippet in entry['code'] implements t...  \n",
       "1  Okay, so I've got this code snippet here that'...  \n",
       "2  The code snippet is the addable method. The me...  \n",
       "3  The code snippet in `entry['code']` implements...  \n",
       "4  The code snippet in entry['code'] is responsib...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation - ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len_e1'] = df['explanation_deepseek_1_cleaned'].str.len()\n",
    "df['len_e2'] = df['explanation_deepseek_2_cleaned'].str.len()\n",
    "df['len_e3'] = df['explanation_deepseek_3_cleaned'].str.len()\n",
    "df['len_e4'] = df['explanation_deepseek_4_cleaned'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>code</th>\n",
       "      <th>explanation_deepseek_1</th>\n",
       "      <th>explanation_deepseek_1_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>Return a list of all non-overlapping matches in the string.\\n\\n    If one or more groups are present in the pattern, return a\\n    list of groups; this will be a list of tuples if the pattern\\n    has more than one group.\\n\\n    Empty matches are included in the result.</td>\n",
       "      <td>def findall(pattern, string, flags=0):\\n    \"\"\"Return a list of all non-overlapping matches in the string.\\n\\n    If one or more groups are present in the pattern, return a\\n    list of groups; this will be a list of tuples if the pattern\\n    has more than one group.\\n\\n    Empty matches are included in the result.\"\"\"\\n    return _compile(pattern, flags).findall(string)\\n\\n    # if sys.hexversion &gt;= 0x02020000:\\n    #     __all__.append(\"finditer\")\\n    def finditer(pattern, string, flags=0):\\n        \"\"\"Return an iterator over all non-overlapping matches in the\\n        string.  For each match, the iterator returns a match object.\\n\\n        Empty matches are included in the result.\"\"\"\\n        return _compile(pattern, flags).finditer(string)</td>\n",
       "      <td>&lt;/think&gt;\\n\\n```</td>\n",
       "      <td>```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>Find the position just after the end of current parenthesized expression.\\n\\n  Args:\\n    line: a CleansedLines line.\\n    startpos: start searching at this position.\\n    stack: nesting stack at startpos.\\n\\n  Returns:\\n    On finding matching end: (index just after matching end, None)\\n    On finding an unclosed expression: (-1, None)\\n    Otherwise: (-1, new stack at end of this line)</td>\n",
       "      <td>def FindEndOfExpressionInLine(line, startpos, stack):\\n  \"\"\"Find the position just after the end of current parenthesized expression.\\n\\n  Args:\\n    line: a CleansedLines line.\\n    startpos: start searching at this position.\\n    stack: nesting stack at startpos.\\n\\n  Returns:\\n    On finding matching end: (index just after matching end, None)\\n    On finding an unclosed expression: (-1, None)\\n    Otherwise: (-1, new stack at end of this line)\\n  \"\"\"\\n  for i in xrange(startpos, len(line)):\\n    char = line[i]\\n    if char in '([{':\\n      # Found start of parenthesized expression, push to expression stack\\n      stack.append(char)\\n    elif char == '&lt;':\\n      # Found potential start of template argument list\\n      if i &gt; 0 and line[i - 1] == '&lt;':\\n        # Left shift operator\\n        if stack and stack[-1] == '&lt;':\\n          stack.pop()\\n          if not stack:\\n            return (-1, None)\\n      elif i &gt; 0 and Search(r'\\boperator\\s*$', line[0:i]):\\n        # operator&lt;, d...</td>\n",
       "      <td>&lt;/think&gt;\\n\\n```</td>\n",
       "      <td>```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>Moves a scalar single-precision floating-point value\\n\\n        Moves a scalar single-precision floating-point value from the source operand (second operand)\\n        to the destination operand (first operand). The source and destination operands can be XMM\\n        registers or 32-bit memory locations. This instruction can be used to move a single-precision\\n        floating-point value to and from the low doubleword of an XMM register and a 32-bit memory\\n        location, or to move a single-precision floating-point value between the low doublewords of\\n        two XMM registers. The instruction cannot be used to transfer data between memory locations.\\n        When the source and destination operands are XMM registers, the three high-order doublewords of the\\n        destination operand remain unchanged. When the source operand is a memory location and destination\\n        operand is an XMM registers, the three high-order doublewords of the destination operand are cleared to al...</td>\n",
       "      <td>def MOVSS(cpu, dest, src):\\n        \"\"\"\\n        Moves a scalar single-precision floating-point value\\n\\n        Moves a scalar single-precision floating-point value from the source operand (second operand)\\n        to the destination operand (first operand). The source and destination operands can be XMM\\n        registers or 32-bit memory locations. This instruction can be used to move a single-precision\\n        floating-point value to and from the low doubleword of an XMM register and a 32-bit memory\\n        location, or to move a single-precision floating-point value between the low doublewords of\\n        two XMM registers. The instruction cannot be used to transfer data between memory locations.\\n        When the source and destination operands are XMM registers, the three high-order doublewords of the\\n        destination operand remain unchanged. When the source operand is a memory location and destination\\n        operand is an XMM registers, the three high-order doublew...</td>\n",
       "      <td>&lt;/think&gt;\\n\\n```</td>\n",
       "      <td>```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>strcmp symbolic model.\\n\\n    Algorithm: Walks from end of string (minimum offset to NULL in either string)\\n    to beginning building tree of ITEs each time either of the\\n    bytes at current offset is symbolic.\\n\\n    Points of Interest:\\n    - We've been building up a symbolic tree but then encounter two\\n      concrete bytes that differ. We can throw away the entire symbolic\\n      tree!\\n    - If we've been encountering concrete bytes that match\\n      at the end of the string as we walk forward, and then we encounter\\n      a pair where one is symbolic, we can forget about that 0 `ret` we've\\n      been tracking and just replace it with the symbolic subtraction of\\n      the two\\n\\n    :param State state: Current program state\\n    :param int s1: Address of string 1\\n    :param int s2: Address of string 2\\n    :return: Symbolic strcmp result\\n    :rtype: Expression or int</td>\n",
       "      <td>def strcmp(state, s1, s2):\\n    \"\"\"\\n    strcmp symbolic model.\\n\\n    Algorithm: Walks from end of string (minimum offset to NULL in either string)\\n    to beginning building tree of ITEs each time either of the\\n    bytes at current offset is symbolic.\\n\\n    Points of Interest:\\n    - We've been building up a symbolic tree but then encounter two\\n      concrete bytes that differ. We can throw away the entire symbolic\\n      tree!\\n    - If we've been encountering concrete bytes that match\\n      at the end of the string as we walk forward, and then we encounter\\n      a pair where one is symbolic, we can forget about that 0 `ret` we've\\n      been tracking and just replace it with the symbolic subtraction of\\n      the two\\n\\n    :param State state: Current program state\\n    :param int s1: Address of string 1\\n    :param int s2: Address of string 2\\n    :return: Symbolic strcmp result\\n    :rtype: Expression or int\\n    \"\"\"\\n\\n    cpu = state.cpu\\n\\n    if issymbolic(s1):\\n    ...</td>\n",
       "      <td>&lt;/think&gt;\\n\\n```</td>\n",
       "      <td>```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>Removes a file or recursively removes a directory.\\n    If a path does not exist, then this is does nothing.\\n\\n    Args:\\n        path (PathLike): file or directory to remove\\n        verbose (bool): if True prints what is being done\\n\\n    SeeAlso:\\n        send2trash - A cross-platform Python package for sending files\\n            to the trash instead of irreversibly deleting them.\\n            https://github.com/hsoft/send2trash\\n\\n    Doctest:\\n        &gt;&gt;&gt; import ubelt as ub\\n        &gt;&gt;&gt; base = ub.ensure_app_cache_dir('ubelt', 'delete_test')\\n        &gt;&gt;&gt; dpath1 = ub.ensuredir(join(base, 'dir'))\\n        &gt;&gt;&gt; ub.ensuredir(join(base, 'dir', 'subdir'))\\n        &gt;&gt;&gt; ub.touch(join(base, 'dir', 'to_remove1.txt'))\\n        &gt;&gt;&gt; fpath1 = join(base, 'dir', 'subdir', 'to_remove3.txt')\\n        &gt;&gt;&gt; fpath2 = join(base, 'dir', 'subdir', 'to_remove2.txt')\\n        &gt;&gt;&gt; ub.touch(fpath1)\\n        &gt;&gt;&gt; ub.touch(fpath2)\\n        &gt;&gt;&gt; assert all(map(exists, (dpath1, fpath1, fpath2)))\\n        &gt;&gt;&gt; ub....</td>\n",
       "      <td>def delete(path, verbose=False):\\n    \"\"\"\\n    Removes a file or recursively removes a directory.\\n    If a path does not exist, then this is does nothing.\\n\\n    Args:\\n        path (PathLike): file or directory to remove\\n        verbose (bool): if True prints what is being done\\n\\n    SeeAlso:\\n        send2trash - A cross-platform Python package for sending files\\n            to the trash instead of irreversibly deleting them.\\n            https://github.com/hsoft/send2trash\\n\\n    Doctest:\\n        &gt;&gt;&gt; import ubelt as ub\\n        &gt;&gt;&gt; base = ub.ensure_app_cache_dir('ubelt', 'delete_test')\\n        &gt;&gt;&gt; dpath1 = ub.ensuredir(join(base, 'dir'))\\n        &gt;&gt;&gt; ub.ensuredir(join(base, 'dir', 'subdir'))\\n        &gt;&gt;&gt; ub.touch(join(base, 'dir', 'to_remove1.txt'))\\n        &gt;&gt;&gt; fpath1 = join(base, 'dir', 'subdir', 'to_remove3.txt')\\n        &gt;&gt;&gt; fpath2 = join(base, 'dir', 'subdir', 'to_remove2.txt')\\n        &gt;&gt;&gt; ub.touch(fpath1)\\n        &gt;&gt;&gt; ub.touch(fpath2)\\n        &gt;&gt;&gt; assert all(map(exis...</td>\n",
       "      <td>&lt;/think&gt;\\n\\n```\\n\\n```</td>\n",
       "      <td>``````</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4512</th>\n",
       "      <td>Return true if this string or integer tuple appears in tables</td>\n",
       "      <td>def contains(x):\\n    \"\"\"Return true if this string or integer tuple appears in tables\"\"\"\\n    if isinstance(x, str):\\n        x = canonical_name(x)\\n        return x in _TO_COLOR_USER or x in _TO_COLOR\\n    else:\\n        x = tuple(x)\\n        return x in _TO_NAME_USER or x in _TO_NAME</td>\n",
       "      <td>&lt;/think&gt;\\n\\n```</td>\n",
       "      <td>```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5611</th>\n",
       "      <td>Break a shape into segments between stops using break_points.\\n\\n    This function can use the `break_points` outputs from\\n    `find_segments`, and cuts the shape-sequence into pieces\\n    corresponding to each stop.</td>\n",
       "      <td>def return_segments(shape, break_points):\\n    \"\"\"Break a shape into segments between stops using break_points.\\n\\n    This function can use the `break_points` outputs from\\n    `find_segments`, and cuts the shape-sequence into pieces\\n    corresponding to each stop.\\n    \"\"\"\\n    # print 'xxx'\\n    # print stops\\n    # print shape\\n    # print break_points\\n    # assert len(stops) == len(break_points)\\n    segs = []\\n    bp = 0 # not used\\n    bp2 = 0\\n    for i in range(len(break_points)-1):\\n        bp = break_points[i] if break_points[i] is not None else bp2\\n        bp2 = break_points[i+1] if break_points[i+1] is not None else bp\\n        segs.append(shape[bp:bp2+1])\\n    segs.append([])\\n    return segs</td>\n",
       "      <td>&lt;/think&gt;\\n\\n```</td>\n",
       "      <td>```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>For a 2D array and mask, map the values of all unmasked pixels to a 1D array.\\n\\n    The pixel coordinate origin is at the top left corner of the 2D array and goes right-wards and downwards, such\\n    that for an array of shape (3,3) where all pixels are unmasked:\\n\\n    - pixel [0,0] of the 2D array will correspond to index 0 of the 1D array.\\n    - pixel [0,1] of the 2D array will correspond to index 1 of the 1D array.\\n    - pixel [1,0] of the 2D array will correspond to index 4 of the 1D array.\\n\\n    Parameters\\n     ----------\\n    mask : ndarray\\n        A 2D array of bools, where *False* values mean unmasked and are included in the mapping.\\n    array_2d : ndarray\\n        The 2D array of values which are mapped to a 1D array.\\n\\n    Returns\\n    --------\\n    ndarray\\n        A 1D array of values mapped from the 2D array with dimensions (total_unmasked_pixels).\\n\\n    Examples\\n    --------\\n    mask = np.array([[True, False, True],\\n                     [False, False, Fal...</td>\n",
       "      <td>def map_2d_array_to_masked_1d_array_from_array_2d_and_mask(mask, array_2d):\\n    \"\"\"For a 2D array and mask, map the values of all unmasked pixels to a 1D array.\\n\\n    The pixel coordinate origin is at the top left corner of the 2D array and goes right-wards and downwards, such\\n    that for an array of shape (3,3) where all pixels are unmasked:\\n\\n    - pixel [0,0] of the 2D array will correspond to index 0 of the 1D array.\\n    - pixel [0,1] of the 2D array will correspond to index 1 of the 1D array.\\n    - pixel [1,0] of the 2D array will correspond to index 4 of the 1D array.\\n\\n    Parameters\\n     ----------\\n    mask : ndarray\\n        A 2D array of bools, where *False* values mean unmasked and are included in the mapping.\\n    array_2d : ndarray\\n        The 2D array of values which are mapped to a 1D array.\\n\\n    Returns\\n    --------\\n    ndarray\\n        A 1D array of values mapped from the 2D array with dimensions (total_unmasked_pixels).\\n\\n    Examples\\n    --------...</td>\n",
       "      <td>&lt;/think&gt;\\n\\n```\\n\\n```</td>\n",
       "      <td>``````</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6827</th>\n",
       "      <td>This applies EPD in parallel to all LCs in the input list.\\n\\n    Parameters\\n    ----------\\n\\n    lclist : list of str\\n        This is the list of light curve files to run EPD on.\\n\\n    externalparams : dict or None\\n        This is a dict that indicates which keys in the lcdict obtained from the\\n        lcfile correspond to the required external parameters. As with timecol,\\n        magcol, and errcol, these can be simple keys (e.g. 'rjd') or compound\\n        keys ('magaperture1.mags'). The dict should look something like::\\n\\n          {'fsv':'&lt;lcdict key&gt;' array: S values for each observation,\\n           'fdv':'&lt;lcdict key&gt;' array: D values for each observation,\\n           'fkv':'&lt;lcdict key&gt;' array: K values for each observation,\\n           'xcc':'&lt;lcdict key&gt;' array: x coords for each observation,\\n           'ycc':'&lt;lcdict key&gt;' array: y coords for each observation,\\n           'bgv':'&lt;lcdict key&gt;' array: sky background for each observation,\\n           'bge':'&lt;lcdic...</td>\n",
       "      <td>def parallel_epd_lclist(lclist,\\n                        externalparams,\\n                        timecols=None,\\n                        magcols=None,\\n                        errcols=None,\\n                        lcformat='hat-sql',\\n                        lcformatdir=None,\\n                        epdsmooth_sigclip=3.0,\\n                        epdsmooth_windowsize=21,\\n                        epdsmooth_func=smooth_magseries_savgol,\\n                        epdsmooth_extraparams=None,\\n                        nworkers=NCPUS,\\n                        maxworkertasks=1000):\\n    '''This applies EPD in parallel to all LCs in the input list.\\n\\n    Parameters\\n    ----------\\n\\n    lclist : list of str\\n        This is the list of light curve files to run EPD on.\\n\\n    externalparams : dict or None\\n        This is a dict that indicates which keys in the lcdict obtained from the\\n        lcfile correspond to the required external parameters. As with timecol,\\n        magcol, and e...</td>\n",
       "      <td>&lt;/think&gt;\\n\\n```</td>\n",
       "      <td>```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7120</th>\n",
       "      <td>Converts type comments in `node` to proper annotated assignments.</td>\n",
       "      <td>def fix_remaining_type_comments(node):\\n    \"\"\"Converts type comments in `node` to proper annotated assignments.\"\"\"\\n    assert node.type == syms.file_input\\n\\n    last_n = None\\n    for n in node.post_order():\\n        if last_n is not None:\\n            if n.type == token.NEWLINE and is_assignment(last_n):\\n                fix_variable_annotation_type_comment(n, last_n)\\n            elif n.type == syms.funcdef and last_n.type == syms.suite:\\n                fix_signature_annotation_type_comment(n, last_n, offset=1)\\n            elif n.type == syms.async_funcdef and last_n.type == syms.suite:\\n                fix_signature_annotation_type_comment(n, last_n, offset=2)\\n        last_n = n</td>\n",
       "      <td>&lt;/think&gt;\\n\\n```</td>\n",
       "      <td>```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9852</th>\n",
       "      <td>Create a child space from an Excel range.\\n\\n        To use this method, ``openpyxl`` package must be installed.\\n\\n        Args:\\n            book (str): Path to an Excel file.\\n            range_ (str): Range expression, such as \"A1\", \"$G4:$K10\",\\n                or named range \"NamedRange1\".\\n            sheet (str): Sheet name (case ignored).\\n            name (str, optional): Name of the space. Defaults to ``SpaceN``,\\n                where ``N`` is a number determined automatically.\\n            names_row (optional): an index number indicating\\n                what row contains the names of cells and parameters.\\n                Defaults to the top row (0).\\n            param_cols (optional): a sequence of index numbers\\n                indicating parameter columns.\\n                Defaults to only the leftmost column ([0]).\\n            names_col (optional): an index number, starting from 0,\\n                indicating what column contains additional parameters.\\n          ...</td>\n",
       "      <td>def new_space_from_excel(\\n        self,\\n        book,\\n        range_,\\n        sheet=None,\\n        name=None,\\n        names_row=None,\\n        param_cols=None,\\n        space_param_order=None,\\n        cells_param_order=None,\\n        transpose=False,\\n        names_col=None,\\n        param_rows=None,\\n    ):\\n        \"\"\"Create a child space from an Excel range.\\n\\n        To use this method, ``openpyxl`` package must be installed.\\n\\n        Args:\\n            book (str): Path to an Excel file.\\n            range_ (str): Range expression, such as \"A1\", \"$G4:$K10\",\\n                or named range \"NamedRange1\".\\n            sheet (str): Sheet name (case ignored).\\n            name (str, optional): Name of the space. Defaults to ``SpaceN``,\\n                where ``N`` is a number determined automatically.\\n            names_row (optional): an index number indicating\\n                what row contains the names of cells and parameters.\\n                Defaults to the top row (...</td>\n",
       "      <td>&lt;/think&gt;\\n\\n```</td>\n",
       "      <td>```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11946</th>\n",
       "      <td>given a path or list of files, return ABF IDs.</td>\n",
       "      <td>def getIDsFromFiles(files):\\n    \"\"\"given a path or list of files, return ABF IDs.\"\"\"\\n    if type(files) is str:\\n        files=glob.glob(files+\"/*.*\")\\n    IDs=[]\\n    for fname in files:\\n        if fname[-4:].lower()=='.abf':\\n            ext=fname.split('.')[-1]\\n            IDs.append(os.path.basename(fname).replace('.'+ext,''))\\n    return sorted(IDs)</td>\n",
       "      <td>&lt;/think&gt;\\n\\n``` \\n\\n```</td>\n",
       "      <td>``` ```</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12459</th>\n",
       "      <td>Store object in HDFStore\\n\\n        Parameters\\n        ----------\\n        key : str\\n\\n        value : {Series, DataFrame, Panel, Numpy ndarray}\\n\\n        format : 'fixed(f)|table(t)', default is 'fixed'\\n            fixed(f) : Fixed format\\n                Fast writing/reading. Not-appendable, nor searchable\\n\\n            table(t) : Table format\\n                Write as a PyTables Table structure which may perform worse but allow more flexible operations\\n                like searching/selecting subsets of the data\\n\\n        append : boolean, default False\\n            This will force Table format, append the input data to the\\n            existing.\\n\\n        encoding : default None, provide an encoding for strings</td>\n",
       "      <td>def put(self, key, value, attrs=None, format=None, append=False, **kwargs):\\n        \"\"\"\\n        Store object in HDFStore\\n\\n        Parameters\\n        ----------\\n        key : str\\n\\n        value : {Series, DataFrame, Panel, Numpy ndarray}\\n\\n        format : 'fixed(f)|table(t)', default is 'fixed'\\n            fixed(f) : Fixed format\\n                Fast writing/reading. Not-appendable, nor searchable\\n\\n            table(t) : Table format\\n                Write as a PyTables Table structure which may perform worse but allow more flexible operations\\n                like searching/selecting subsets of the data\\n\\n        append : boolean, default False\\n            This will force Table format, append the input data to the\\n            existing.\\n\\n        encoding : default None, provide an encoding for strings\\n        \"\"\"\\n        if not isinstance(value, np.ndarray):\\n            super(NumpyHDFStore, self).put(key, value, format, append, **kwargs)\\n        else:\\n       ...</td>\n",
       "      <td>```\\n\\n&lt;/think&gt;\\n\\n```</td>\n",
       "      <td>``````</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13305</th>\n",
       "      <td>The main method of this class and the essence of the package.\\n        It allows to \"map\" stuff.\\n\\n        Args:\\n\\n            ID_s: Nested lists with strings as leafs (plain strings also possible)\\n            FROM (str): Origin key for the mapping (default: main key)\\n            TO (str): Destination key for the mapping (default: main key)\\n            target_as_set (bool): Whether to summarize the output as a set (removes duplicates)\\n            no_match_sub: Object representing the status of an ID not being able to be matched\\n                          (default: None)\\n\\n        Returns:\\n\\n            Mapping: a mapping object capturing the result of the mapping request</td>\n",
       "      <td>def map(self, ID_s,\\n                  FROM=None,\\n                  TO=None,\\n                  target_as_set=False,\\n                  no_match_sub=None):\\n        '''\\n        The main method of this class and the essence of the package.\\n        It allows to \"map\" stuff.\\n\\n        Args:\\n\\n            ID_s: Nested lists with strings as leafs (plain strings also possible)\\n            FROM (str): Origin key for the mapping (default: main key)\\n            TO (str): Destination key for the mapping (default: main key)\\n            target_as_set (bool): Whether to summarize the output as a set (removes duplicates)\\n            no_match_sub: Object representing the status of an ID not being able to be matched\\n                          (default: None)\\n\\n        Returns:\\n\\n            Mapping: a mapping object capturing the result of the mapping request\\n        '''\\n        def io_mode(ID_s):\\n            '''\\n            Handles the input/output modalities of the mapping.\\n     ...</td>\n",
       "      <td>&lt;/think&gt;\\n\\n```</td>\n",
       "      <td>```</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           doc  \\\n",
       "1083                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Return a list of all non-overlapping matches in the string.\\n\\n    If one or more groups are present in the pattern, return a\\n    list of groups; this will be a list of tuples if the pattern\\n    has more than one group.\\n\\n    Empty matches are included in the result.   \n",
       "1605                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Find the position just after the end of current parenthesized expression.\\n\\n  Args:\\n    line: a CleansedLines line.\\n    startpos: start searching at this position.\\n    stack: nesting stack at startpos.\\n\\n  Returns:\\n    On finding matching end: (index just after matching end, None)\\n    On finding an unclosed expression: (-1, None)\\n    Otherwise: (-1, new stack at end of this line)   \n",
       "1852   Moves a scalar single-precision floating-point value\\n\\n        Moves a scalar single-precision floating-point value from the source operand (second operand)\\n        to the destination operand (first operand). The source and destination operands can be XMM\\n        registers or 32-bit memory locations. This instruction can be used to move a single-precision\\n        floating-point value to and from the low doubleword of an XMM register and a 32-bit memory\\n        location, or to move a single-precision floating-point value between the low doublewords of\\n        two XMM registers. The instruction cannot be used to transfer data between memory locations.\\n        When the source and destination operands are XMM registers, the three high-order doublewords of the\\n        destination operand remain unchanged. When the source operand is a memory location and destination\\n        operand is an XMM registers, the three high-order doublewords of the destination operand are cleared to al...   \n",
       "1879                                                                                                               strcmp symbolic model.\\n\\n    Algorithm: Walks from end of string (minimum offset to NULL in either string)\\n    to beginning building tree of ITEs each time either of the\\n    bytes at current offset is symbolic.\\n\\n    Points of Interest:\\n    - We've been building up a symbolic tree but then encounter two\\n      concrete bytes that differ. We can throw away the entire symbolic\\n      tree!\\n    - If we've been encountering concrete bytes that match\\n      at the end of the string as we walk forward, and then we encounter\\n      a pair where one is symbolic, we can forget about that 0 `ret` we've\\n      been tracking and just replace it with the symbolic subtraction of\\n      the two\\n\\n    :param State state: Current program state\\n    :param int s1: Address of string 1\\n    :param int s2: Address of string 2\\n    :return: Symbolic strcmp result\\n    :rtype: Expression or int   \n",
       "2187   Removes a file or recursively removes a directory.\\n    If a path does not exist, then this is does nothing.\\n\\n    Args:\\n        path (PathLike): file or directory to remove\\n        verbose (bool): if True prints what is being done\\n\\n    SeeAlso:\\n        send2trash - A cross-platform Python package for sending files\\n            to the trash instead of irreversibly deleting them.\\n            https://github.com/hsoft/send2trash\\n\\n    Doctest:\\n        >>> import ubelt as ub\\n        >>> base = ub.ensure_app_cache_dir('ubelt', 'delete_test')\\n        >>> dpath1 = ub.ensuredir(join(base, 'dir'))\\n        >>> ub.ensuredir(join(base, 'dir', 'subdir'))\\n        >>> ub.touch(join(base, 'dir', 'to_remove1.txt'))\\n        >>> fpath1 = join(base, 'dir', 'subdir', 'to_remove3.txt')\\n        >>> fpath2 = join(base, 'dir', 'subdir', 'to_remove2.txt')\\n        >>> ub.touch(fpath1)\\n        >>> ub.touch(fpath2)\\n        >>> assert all(map(exists, (dpath1, fpath1, fpath2)))\\n        >>> ub....   \n",
       "4512                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Return true if this string or integer tuple appears in tables   \n",
       "5611                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Break a shape into segments between stops using break_points.\\n\\n    This function can use the `break_points` outputs from\\n    `find_segments`, and cuts the shape-sequence into pieces\\n    corresponding to each stop.   \n",
       "5993   For a 2D array and mask, map the values of all unmasked pixels to a 1D array.\\n\\n    The pixel coordinate origin is at the top left corner of the 2D array and goes right-wards and downwards, such\\n    that for an array of shape (3,3) where all pixels are unmasked:\\n\\n    - pixel [0,0] of the 2D array will correspond to index 0 of the 1D array.\\n    - pixel [0,1] of the 2D array will correspond to index 1 of the 1D array.\\n    - pixel [1,0] of the 2D array will correspond to index 4 of the 1D array.\\n\\n    Parameters\\n     ----------\\n    mask : ndarray\\n        A 2D array of bools, where *False* values mean unmasked and are included in the mapping.\\n    array_2d : ndarray\\n        The 2D array of values which are mapped to a 1D array.\\n\\n    Returns\\n    --------\\n    ndarray\\n        A 1D array of values mapped from the 2D array with dimensions (total_unmasked_pixels).\\n\\n    Examples\\n    --------\\n    mask = np.array([[True, False, True],\\n                     [False, False, Fal...   \n",
       "6827   This applies EPD in parallel to all LCs in the input list.\\n\\n    Parameters\\n    ----------\\n\\n    lclist : list of str\\n        This is the list of light curve files to run EPD on.\\n\\n    externalparams : dict or None\\n        This is a dict that indicates which keys in the lcdict obtained from the\\n        lcfile correspond to the required external parameters. As with timecol,\\n        magcol, and errcol, these can be simple keys (e.g. 'rjd') or compound\\n        keys ('magaperture1.mags'). The dict should look something like::\\n\\n          {'fsv':'<lcdict key>' array: S values for each observation,\\n           'fdv':'<lcdict key>' array: D values for each observation,\\n           'fkv':'<lcdict key>' array: K values for each observation,\\n           'xcc':'<lcdict key>' array: x coords for each observation,\\n           'ycc':'<lcdict key>' array: y coords for each observation,\\n           'bgv':'<lcdict key>' array: sky background for each observation,\\n           'bge':'<lcdic...   \n",
       "7120                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Converts type comments in `node` to proper annotated assignments.   \n",
       "9852   Create a child space from an Excel range.\\n\\n        To use this method, ``openpyxl`` package must be installed.\\n\\n        Args:\\n            book (str): Path to an Excel file.\\n            range_ (str): Range expression, such as \"A1\", \"$G4:$K10\",\\n                or named range \"NamedRange1\".\\n            sheet (str): Sheet name (case ignored).\\n            name (str, optional): Name of the space. Defaults to ``SpaceN``,\\n                where ``N`` is a number determined automatically.\\n            names_row (optional): an index number indicating\\n                what row contains the names of cells and parameters.\\n                Defaults to the top row (0).\\n            param_cols (optional): a sequence of index numbers\\n                indicating parameter columns.\\n                Defaults to only the leftmost column ([0]).\\n            names_col (optional): an index number, starting from 0,\\n                indicating what column contains additional parameters.\\n          ...   \n",
       "11946                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           given a path or list of files, return ABF IDs.   \n",
       "12459                                                                                                                                                                                                                                                                             Store object in HDFStore\\n\\n        Parameters\\n        ----------\\n        key : str\\n\\n        value : {Series, DataFrame, Panel, Numpy ndarray}\\n\\n        format : 'fixed(f)|table(t)', default is 'fixed'\\n            fixed(f) : Fixed format\\n                Fast writing/reading. Not-appendable, nor searchable\\n\\n            table(t) : Table format\\n                Write as a PyTables Table structure which may perform worse but allow more flexible operations\\n                like searching/selecting subsets of the data\\n\\n        append : boolean, default False\\n            This will force Table format, append the input data to the\\n            existing.\\n\\n        encoding : default None, provide an encoding for strings   \n",
       "13305                                                                                                                                                                                                                                                                                                                          The main method of this class and the essence of the package.\\n        It allows to \"map\" stuff.\\n\\n        Args:\\n\\n            ID_s: Nested lists with strings as leafs (plain strings also possible)\\n            FROM (str): Origin key for the mapping (default: main key)\\n            TO (str): Destination key for the mapping (default: main key)\\n            target_as_set (bool): Whether to summarize the output as a set (removes duplicates)\\n            no_match_sub: Object representing the status of an ID not being able to be matched\\n                          (default: None)\\n\\n        Returns:\\n\\n            Mapping: a mapping object capturing the result of the mapping request   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          code  \\\n",
       "1083                                                                                                                                                                                                                                                        def findall(pattern, string, flags=0):\\n    \"\"\"Return a list of all non-overlapping matches in the string.\\n\\n    If one or more groups are present in the pattern, return a\\n    list of groups; this will be a list of tuples if the pattern\\n    has more than one group.\\n\\n    Empty matches are included in the result.\"\"\"\\n    return _compile(pattern, flags).findall(string)\\n\\n    # if sys.hexversion >= 0x02020000:\\n    #     __all__.append(\"finditer\")\\n    def finditer(pattern, string, flags=0):\\n        \"\"\"Return an iterator over all non-overlapping matches in the\\n        string.  For each match, the iterator returns a match object.\\n\\n        Empty matches are included in the result.\"\"\"\\n        return _compile(pattern, flags).finditer(string)   \n",
       "1605   def FindEndOfExpressionInLine(line, startpos, stack):\\n  \"\"\"Find the position just after the end of current parenthesized expression.\\n\\n  Args:\\n    line: a CleansedLines line.\\n    startpos: start searching at this position.\\n    stack: nesting stack at startpos.\\n\\n  Returns:\\n    On finding matching end: (index just after matching end, None)\\n    On finding an unclosed expression: (-1, None)\\n    Otherwise: (-1, new stack at end of this line)\\n  \"\"\"\\n  for i in xrange(startpos, len(line)):\\n    char = line[i]\\n    if char in '([{':\\n      # Found start of parenthesized expression, push to expression stack\\n      stack.append(char)\\n    elif char == '<':\\n      # Found potential start of template argument list\\n      if i > 0 and line[i - 1] == '<':\\n        # Left shift operator\\n        if stack and stack[-1] == '<':\\n          stack.pop()\\n          if not stack:\\n            return (-1, None)\\n      elif i > 0 and Search(r'\\boperator\\s*$', line[0:i]):\\n        # operator<, d...   \n",
       "1852   def MOVSS(cpu, dest, src):\\n        \"\"\"\\n        Moves a scalar single-precision floating-point value\\n\\n        Moves a scalar single-precision floating-point value from the source operand (second operand)\\n        to the destination operand (first operand). The source and destination operands can be XMM\\n        registers or 32-bit memory locations. This instruction can be used to move a single-precision\\n        floating-point value to and from the low doubleword of an XMM register and a 32-bit memory\\n        location, or to move a single-precision floating-point value between the low doublewords of\\n        two XMM registers. The instruction cannot be used to transfer data between memory locations.\\n        When the source and destination operands are XMM registers, the three high-order doublewords of the\\n        destination operand remain unchanged. When the source operand is a memory location and destination\\n        operand is an XMM registers, the three high-order doublew...   \n",
       "1879   def strcmp(state, s1, s2):\\n    \"\"\"\\n    strcmp symbolic model.\\n\\n    Algorithm: Walks from end of string (minimum offset to NULL in either string)\\n    to beginning building tree of ITEs each time either of the\\n    bytes at current offset is symbolic.\\n\\n    Points of Interest:\\n    - We've been building up a symbolic tree but then encounter two\\n      concrete bytes that differ. We can throw away the entire symbolic\\n      tree!\\n    - If we've been encountering concrete bytes that match\\n      at the end of the string as we walk forward, and then we encounter\\n      a pair where one is symbolic, we can forget about that 0 `ret` we've\\n      been tracking and just replace it with the symbolic subtraction of\\n      the two\\n\\n    :param State state: Current program state\\n    :param int s1: Address of string 1\\n    :param int s2: Address of string 2\\n    :return: Symbolic strcmp result\\n    :rtype: Expression or int\\n    \"\"\"\\n\\n    cpu = state.cpu\\n\\n    if issymbolic(s1):\\n    ...   \n",
       "2187   def delete(path, verbose=False):\\n    \"\"\"\\n    Removes a file or recursively removes a directory.\\n    If a path does not exist, then this is does nothing.\\n\\n    Args:\\n        path (PathLike): file or directory to remove\\n        verbose (bool): if True prints what is being done\\n\\n    SeeAlso:\\n        send2trash - A cross-platform Python package for sending files\\n            to the trash instead of irreversibly deleting them.\\n            https://github.com/hsoft/send2trash\\n\\n    Doctest:\\n        >>> import ubelt as ub\\n        >>> base = ub.ensure_app_cache_dir('ubelt', 'delete_test')\\n        >>> dpath1 = ub.ensuredir(join(base, 'dir'))\\n        >>> ub.ensuredir(join(base, 'dir', 'subdir'))\\n        >>> ub.touch(join(base, 'dir', 'to_remove1.txt'))\\n        >>> fpath1 = join(base, 'dir', 'subdir', 'to_remove3.txt')\\n        >>> fpath2 = join(base, 'dir', 'subdir', 'to_remove2.txt')\\n        >>> ub.touch(fpath1)\\n        >>> ub.touch(fpath2)\\n        >>> assert all(map(exis...   \n",
       "4512                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           def contains(x):\\n    \"\"\"Return true if this string or integer tuple appears in tables\"\"\"\\n    if isinstance(x, str):\\n        x = canonical_name(x)\\n        return x in _TO_COLOR_USER or x in _TO_COLOR\\n    else:\\n        x = tuple(x)\\n        return x in _TO_NAME_USER or x in _TO_NAME   \n",
       "5611                                                                                                                                                                                                                                                                                            def return_segments(shape, break_points):\\n    \"\"\"Break a shape into segments between stops using break_points.\\n\\n    This function can use the `break_points` outputs from\\n    `find_segments`, and cuts the shape-sequence into pieces\\n    corresponding to each stop.\\n    \"\"\"\\n    # print 'xxx'\\n    # print stops\\n    # print shape\\n    # print break_points\\n    # assert len(stops) == len(break_points)\\n    segs = []\\n    bp = 0 # not used\\n    bp2 = 0\\n    for i in range(len(break_points)-1):\\n        bp = break_points[i] if break_points[i] is not None else bp2\\n        bp2 = break_points[i+1] if break_points[i+1] is not None else bp\\n        segs.append(shape[bp:bp2+1])\\n    segs.append([])\\n    return segs   \n",
       "5993   def map_2d_array_to_masked_1d_array_from_array_2d_and_mask(mask, array_2d):\\n    \"\"\"For a 2D array and mask, map the values of all unmasked pixels to a 1D array.\\n\\n    The pixel coordinate origin is at the top left corner of the 2D array and goes right-wards and downwards, such\\n    that for an array of shape (3,3) where all pixels are unmasked:\\n\\n    - pixel [0,0] of the 2D array will correspond to index 0 of the 1D array.\\n    - pixel [0,1] of the 2D array will correspond to index 1 of the 1D array.\\n    - pixel [1,0] of the 2D array will correspond to index 4 of the 1D array.\\n\\n    Parameters\\n     ----------\\n    mask : ndarray\\n        A 2D array of bools, where *False* values mean unmasked and are included in the mapping.\\n    array_2d : ndarray\\n        The 2D array of values which are mapped to a 1D array.\\n\\n    Returns\\n    --------\\n    ndarray\\n        A 1D array of values mapped from the 2D array with dimensions (total_unmasked_pixels).\\n\\n    Examples\\n    --------...   \n",
       "6827   def parallel_epd_lclist(lclist,\\n                        externalparams,\\n                        timecols=None,\\n                        magcols=None,\\n                        errcols=None,\\n                        lcformat='hat-sql',\\n                        lcformatdir=None,\\n                        epdsmooth_sigclip=3.0,\\n                        epdsmooth_windowsize=21,\\n                        epdsmooth_func=smooth_magseries_savgol,\\n                        epdsmooth_extraparams=None,\\n                        nworkers=NCPUS,\\n                        maxworkertasks=1000):\\n    '''This applies EPD in parallel to all LCs in the input list.\\n\\n    Parameters\\n    ----------\\n\\n    lclist : list of str\\n        This is the list of light curve files to run EPD on.\\n\\n    externalparams : dict or None\\n        This is a dict that indicates which keys in the lcdict obtained from the\\n        lcfile correspond to the required external parameters. As with timecol,\\n        magcol, and e...   \n",
       "7120                                                                                                                                                                                                                                                                                                                  def fix_remaining_type_comments(node):\\n    \"\"\"Converts type comments in `node` to proper annotated assignments.\"\"\"\\n    assert node.type == syms.file_input\\n\\n    last_n = None\\n    for n in node.post_order():\\n        if last_n is not None:\\n            if n.type == token.NEWLINE and is_assignment(last_n):\\n                fix_variable_annotation_type_comment(n, last_n)\\n            elif n.type == syms.funcdef and last_n.type == syms.suite:\\n                fix_signature_annotation_type_comment(n, last_n, offset=1)\\n            elif n.type == syms.async_funcdef and last_n.type == syms.suite:\\n                fix_signature_annotation_type_comment(n, last_n, offset=2)\\n        last_n = n   \n",
       "9852   def new_space_from_excel(\\n        self,\\n        book,\\n        range_,\\n        sheet=None,\\n        name=None,\\n        names_row=None,\\n        param_cols=None,\\n        space_param_order=None,\\n        cells_param_order=None,\\n        transpose=False,\\n        names_col=None,\\n        param_rows=None,\\n    ):\\n        \"\"\"Create a child space from an Excel range.\\n\\n        To use this method, ``openpyxl`` package must be installed.\\n\\n        Args:\\n            book (str): Path to an Excel file.\\n            range_ (str): Range expression, such as \"A1\", \"$G4:$K10\",\\n                or named range \"NamedRange1\".\\n            sheet (str): Sheet name (case ignored).\\n            name (str, optional): Name of the space. Defaults to ``SpaceN``,\\n                where ``N`` is a number determined automatically.\\n            names_row (optional): an index number indicating\\n                what row contains the names of cells and parameters.\\n                Defaults to the top row (...   \n",
       "11946                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 def getIDsFromFiles(files):\\n    \"\"\"given a path or list of files, return ABF IDs.\"\"\"\\n    if type(files) is str:\\n        files=glob.glob(files+\"/*.*\")\\n    IDs=[]\\n    for fname in files:\\n        if fname[-4:].lower()=='.abf':\\n            ext=fname.split('.')[-1]\\n            IDs.append(os.path.basename(fname).replace('.'+ext,''))\\n    return sorted(IDs)   \n",
       "12459  def put(self, key, value, attrs=None, format=None, append=False, **kwargs):\\n        \"\"\"\\n        Store object in HDFStore\\n\\n        Parameters\\n        ----------\\n        key : str\\n\\n        value : {Series, DataFrame, Panel, Numpy ndarray}\\n\\n        format : 'fixed(f)|table(t)', default is 'fixed'\\n            fixed(f) : Fixed format\\n                Fast writing/reading. Not-appendable, nor searchable\\n\\n            table(t) : Table format\\n                Write as a PyTables Table structure which may perform worse but allow more flexible operations\\n                like searching/selecting subsets of the data\\n\\n        append : boolean, default False\\n            This will force Table format, append the input data to the\\n            existing.\\n\\n        encoding : default None, provide an encoding for strings\\n        \"\"\"\\n        if not isinstance(value, np.ndarray):\\n            super(NumpyHDFStore, self).put(key, value, format, append, **kwargs)\\n        else:\\n       ...   \n",
       "13305  def map(self, ID_s,\\n                  FROM=None,\\n                  TO=None,\\n                  target_as_set=False,\\n                  no_match_sub=None):\\n        '''\\n        The main method of this class and the essence of the package.\\n        It allows to \"map\" stuff.\\n\\n        Args:\\n\\n            ID_s: Nested lists with strings as leafs (plain strings also possible)\\n            FROM (str): Origin key for the mapping (default: main key)\\n            TO (str): Destination key for the mapping (default: main key)\\n            target_as_set (bool): Whether to summarize the output as a set (removes duplicates)\\n            no_match_sub: Object representing the status of an ID not being able to be matched\\n                          (default: None)\\n\\n        Returns:\\n\\n            Mapping: a mapping object capturing the result of the mapping request\\n        '''\\n        def io_mode(ID_s):\\n            '''\\n            Handles the input/output modalities of the mapping.\\n     ...   \n",
       "\n",
       "        explanation_deepseek_1 explanation_deepseek_1_cleaned  \n",
       "1083           </think>\\n\\n```                            ```  \n",
       "1605           </think>\\n\\n```                            ```  \n",
       "1852           </think>\\n\\n```                            ```  \n",
       "1879           </think>\\n\\n```                            ```  \n",
       "2187    </think>\\n\\n```\\n\\n```                         ``````  \n",
       "4512           </think>\\n\\n```                            ```  \n",
       "5611           </think>\\n\\n```                            ```  \n",
       "5993    </think>\\n\\n```\\n\\n```                         ``````  \n",
       "6827           </think>\\n\\n```                            ```  \n",
       "7120           </think>\\n\\n```                            ```  \n",
       "9852           </think>\\n\\n```                            ```  \n",
       "11946  </think>\\n\\n``` \\n\\n```                        ``` ```  \n",
       "12459   ```\\n\\n</think>\\n\\n```                         ``````  \n",
       "13305          </think>\\n\\n```                            ```  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)\n",
    "df[df['len_e1']<10][['doc','code','explanation_deepseek_1','explanation_deepseek_1_cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>score</th>\n",
       "      <th>doc</th>\n",
       "      <th>code</th>\n",
       "      <th>explanation_deepseek_1</th>\n",
       "      <th>explanation_deepseek_2</th>\n",
       "      <th>explanation_deepseek_3</th>\n",
       "      <th>explanation_deepseek_4</th>\n",
       "      <th>...</th>\n",
       "      <th>explanation_granite_5</th>\n",
       "      <th>explanation_deepseek_1_cleaned</th>\n",
       "      <th>explanation_deepseek_2_cleaned</th>\n",
       "      <th>explanation_deepseek_3_cleaned</th>\n",
       "      <th>explanation_deepseek_4_cleaned</th>\n",
       "      <th>explanation_deepseek_5_cleaned</th>\n",
       "      <th>len_e1</th>\n",
       "      <th>len_e2</th>\n",
       "      <th>len_e3</th>\n",
       "      <th>len_e4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>q251820</td>\n",
       "      <td>c251820</td>\n",
       "      <td>1</td>\n",
       "      <td>Save model to a pickle located at `path`</td>\n",
       "      <td>def save_act(self, path=None):\\n        \"\"\"Save model to a pickle located at `path`\"\"\"\\n        if path is None:\\n            path = os.path.join(logger.get_dir(), \"model.pkl\")\\n\\n        with tempfile.TemporaryDirectory() as td:\\n            save_variables(os.path.join(td, \"model\"))\\n            arc_name = os.path.join(td, \"packed.zip\")\\n            with zipfile.ZipFile(arc_name, 'w') as zipf:\\n                for root, dirs, files in os.walk(td):\\n                    for fname in files:\\n                        file_path = os.path.join(root, fname)\\n                        if file_path != arc_name:\\n                            zipf.write(file_path, os.path.relpath(file_path, td))\\n            with open(arc_name, \"rb\") as f:\\n                model_data = f.read()\\n        with open(path, \"wb\") as f:\\n            cloudpickle.dump((model_data, self._act_params), f)</td>\n",
       "      <td>``/path/to/model.pkl` is created by the code, so the correct answer is \"\\npath/to/model.pkl is created by the code.\"\\n&lt;/think&gt;\\n\\nThe code creates a pickle file at a specified path, using a temporary directory to save the model and parameters. The correct file path is `path/to/model.pkl`, so the explanation is \"\\path/to/model.pkl is created by the code.\"</td>\n",
       "      <td>Okay, so I'm trying to understand this code snippet that's supposed to save a model using pickle. Let me go through each part step by step.\\n\\nFirst, I see that the function is called save_act and it takes an argument path which is optional. So if path is None, it sets it to a specific location using logger.get_dir() and os.path.join. I remember that logger.get_dir() probably gives the directory of the logger, so this line is initializing the path variable correctly.\\n\\nNext, there's a tempfile.TemporaryDirectory() which is creating a temporary directory to avoid file persistence issues. That makes sense because saving to a file can cause issues if multiple functions are called in quick succession.\\n\\nThen, save_variables is called with the full path of the temporary directory and \"model\". I'm not exactly sure what save_variables does, but I assume it's saving some data into that directory. Maybe it's saving the model data and some parameters.\\n\\nAfter that, an arc_name is created ...</td>\n",
       "      <td>This code snippet is designed to save a model (a type of machine learning model) into a file format called pickle. The pickle format is a way to store objects in a compact and efficient manner, often used for later loading back the model's data. \\n\\nThe code does a few key things:\\n1. It creates a temporary directory to store the model and its serialized form.\\n2. It constructs the names of the model and its serialized pickle file (arc_name) using a common directory and the specified path.\\n3. It walks through all the files in the temporary directory and moves them into the pickle file, ensuring that each file is correctly placed.\\n4. Finally, it saves the model data and parameters to the pickle file using cloudpickle.dump, which is a common method for converting Python objects to pickle.\\n&lt;/think&gt;\\n\\nThis code snippet is designed to save a model into a pickle file located at a specified path. It creates a temporary directory, constructs the model and pickle file names, moves all f...</td>\n",
       "      <td>Okay, I'm looking at this code snippet, and I need to understand what it's doing. So, the class is named something like Model or something similar, and it's a PyTorch class, right? It has a method called save_act which takes an optional path parameter.\\n\\nFirst, I notice that the code checks if path is None. If it is, then it sets the path to the join of logger.get_dir() and \"model.pkl\". So, it's probably using the logger to get the current working directory where the model should be saved. If the path is provided, it uses that path instead.\\n\\nThen, it creates a temporary directory using a tempfile.TemporaryDirectory(), which is common to avoid holding onto files that might be deleted. Inside this temporary directory, it saves the model using save_variables, which I assume is a method that writes the model's data to the td directory.\\n\\nAfter saving the model, it creates an arc_name by joining the temporary directory with \"packed.zip\". This arc_name is used to create an zip file u...</td>\n",
       "      <td>...</td>\n",
       "      <td>\\nThe provided code snippet in entry['code'] defines a method called `save_act` for a class (not shown in the provided code). The method takes an optional `path` parameter, which is set to a default value of `\"model.pkl\"` if not provided. \\n\\nThe method first creates a temporary directory using `tempfile.TemporaryDirectory()` and saves the model variables to a file within that directory. It then creates a zip file of the temporary directory, excluding the zip file itself. \\n\\nNext, the method reads the contents of the zip file and writes it to a binary file specified by the `path` parameter. Finally, it uses the `cloudpickle.dump()` function to save the model data and any additional parameters (`self._act_params`) to the binary file. \\n\\nIn summary, the code snippet in entry['code'] implements the functionality described in the doc string by saving the model to a pickle located at the specified `path`. The temporary directory and zip file are used to ensure that the model data is p...</td>\n",
       "      <td>``/path/to/model.pkl` is created by the code, so the correct answer is \"\\npath/to/model.pkl is created by the code.\"The code creates a pickle file at a specified path, using a temporary directory to save the model and parameters. The correct file path is `path/to/model.pkl`, so the explanation is \"\\path/to/model.pkl is created by the code.\"</td>\n",
       "      <td>Okay, so I'm trying to understand this code snippet that's supposed to save a model using pickle. Let me go through each part step by step.First, I see that the function is called save_act and it takes an argument path which is optional. So if path is None, it sets it to a specific location using logger.get_dir() and os.path.join. I remember that logger.get_dir() probably gives the directory of the logger, so this line is initializing the path variable correctly.Next, there's a tempfile.TemporaryDirectory() which is creating a temporary directory to avoid file persistence issues. That makes sense because saving to a file can cause issues if multiple functions are called in quick succession.Then, save_variables is called with the full path of the temporary directory and \"model\". I'm not exactly sure what save_variables does, but I assume it's saving some data into that directory. Maybe it's saving the model data and some parameters.After that, an arc_name is created using os.path.jo...</td>\n",
       "      <td>This code snippet is designed to save a model (a type of machine learning model) into a file format called pickle. The pickle format is a way to store objects in a compact and efficient manner, often used for later loading back the model's data. The code does a few key things:1. It creates a temporary directory to store the model and its serialized form.2. It constructs the names of the model and its serialized pickle file (arc_name) using a common directory and the specified path.3. It walks through all the files in the temporary directory and moves them into the pickle file, ensuring that each file is correctly placed.4. Finally, it saves the model data and parameters to the pickle file using cloudpickle.dump, which is a common method for converting Python objects to pickle.This code snippet is designed to save a model into a pickle file located at a specified path. It creates a temporary directory, constructs the model and pickle file names, moves all files into the pickle file,...</td>\n",
       "      <td>Okay, I'm looking at this code snippet, and I need to understand what it's doing. So, the class is named something like Model or something similar, and it's a PyTorch class, right? It has a method called save_act which takes an optional path parameter.First, I notice that the code checks if path is None. If it is, then it sets the path to the join of logger.get_dir() and \"model.pkl\". So, it's probably using the logger to get the current working directory where the model should be saved. If the path is provided, it uses that path instead.Then, it creates a temporary directory using a tempfile.TemporaryDirectory(), which is common to avoid holding onto files that might be deleted. Inside this temporary directory, it saves the model using save_variables, which I assume is a method that writes the model's data to the td directory.After saving the model, it creates an arc_name by joining the temporary directory with \"packed.zip\". This arc_name is used to create an zip file using a ZipFi...</td>\n",
       "      <td>The code snippet defines the `save_act` method, which saves a model to a pickle file located at the specified path. Here's how it achieves this:1. **Handling the Path**: If the `path` parameter is `None`, it sets the target path to `logger.get_dir() + \"model.pkl\"`.2. **Temporary Directory Creation**: Uses `TempFile.TemporaryDirectory()` to create a new directory for saving variables and the zip file.3. **Zipfile Creation**: Constructs a zip file (`arc_name`) using `os.walk` to ensure all files are included except the zip itself.4. **Zipfile Population**: Populates the zip file with all entries from the directory, excluding the zip name.5. **Model Data Reading**: Reads the model data from the zip file and the parameters from the object.6. **Pickling the Data**: Uses `cloudpickle.dump` to serialize the tuple `(model_data, self._act_params)` into a pickle file.7. **Target Pickle File**: Opens and writes the pickle file at the specified `path` to the cloud.This approach ensures the mod...</td>\n",
       "      <td>342</td>\n",
       "      <td>2347</td>\n",
       "      <td>1157</td>\n",
       "      <td>2220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 query_id corpus_id  score  \\\n",
       "0           0  q251820   c251820      1   \n",
       "\n",
       "                                        doc  \\\n",
       "0  Save model to a pickle located at `path`   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           code  \\\n",
       "0  def save_act(self, path=None):\\n        \"\"\"Save model to a pickle located at `path`\"\"\"\\n        if path is None:\\n            path = os.path.join(logger.get_dir(), \"model.pkl\")\\n\\n        with tempfile.TemporaryDirectory() as td:\\n            save_variables(os.path.join(td, \"model\"))\\n            arc_name = os.path.join(td, \"packed.zip\")\\n            with zipfile.ZipFile(arc_name, 'w') as zipf:\\n                for root, dirs, files in os.walk(td):\\n                    for fname in files:\\n                        file_path = os.path.join(root, fname)\\n                        if file_path != arc_name:\\n                            zipf.write(file_path, os.path.relpath(file_path, td))\\n            with open(arc_name, \"rb\") as f:\\n                model_data = f.read()\\n        with open(path, \"wb\") as f:\\n            cloudpickle.dump((model_data, self._act_params), f)   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                 explanation_deepseek_1  \\\n",
       "0  ``/path/to/model.pkl` is created by the code, so the correct answer is \"\\npath/to/model.pkl is created by the code.\"\\n</think>\\n\\nThe code creates a pickle file at a specified path, using a temporary directory to save the model and parameters. The correct file path is `path/to/model.pkl`, so the explanation is \"\\path/to/model.pkl is created by the code.\"   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    explanation_deepseek_2  \\\n",
       "0  Okay, so I'm trying to understand this code snippet that's supposed to save a model using pickle. Let me go through each part step by step.\\n\\nFirst, I see that the function is called save_act and it takes an argument path which is optional. So if path is None, it sets it to a specific location using logger.get_dir() and os.path.join. I remember that logger.get_dir() probably gives the directory of the logger, so this line is initializing the path variable correctly.\\n\\nNext, there's a tempfile.TemporaryDirectory() which is creating a temporary directory to avoid file persistence issues. That makes sense because saving to a file can cause issues if multiple functions are called in quick succession.\\n\\nThen, save_variables is called with the full path of the temporary directory and \"model\". I'm not exactly sure what save_variables does, but I assume it's saving some data into that directory. Maybe it's saving the model data and some parameters.\\n\\nAfter that, an arc_name is created ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    explanation_deepseek_3  \\\n",
       "0  This code snippet is designed to save a model (a type of machine learning model) into a file format called pickle. The pickle format is a way to store objects in a compact and efficient manner, often used for later loading back the model's data. \\n\\nThe code does a few key things:\\n1. It creates a temporary directory to store the model and its serialized form.\\n2. It constructs the names of the model and its serialized pickle file (arc_name) using a common directory and the specified path.\\n3. It walks through all the files in the temporary directory and moves them into the pickle file, ensuring that each file is correctly placed.\\n4. Finally, it saves the model data and parameters to the pickle file using cloudpickle.dump, which is a common method for converting Python objects to pickle.\\n</think>\\n\\nThis code snippet is designed to save a model into a pickle file located at a specified path. It creates a temporary directory, constructs the model and pickle file names, moves all f...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    explanation_deepseek_4  \\\n",
       "0  Okay, I'm looking at this code snippet, and I need to understand what it's doing. So, the class is named something like Model or something similar, and it's a PyTorch class, right? It has a method called save_act which takes an optional path parameter.\\n\\nFirst, I notice that the code checks if path is None. If it is, then it sets the path to the join of logger.get_dir() and \"model.pkl\". So, it's probably using the logger to get the current working directory where the model should be saved. If the path is provided, it uses that path instead.\\n\\nThen, it creates a temporary directory using a tempfile.TemporaryDirectory(), which is common to avoid holding onto files that might be deleted. Inside this temporary directory, it saves the model using save_variables, which I assume is a method that writes the model's data to the td directory.\\n\\nAfter saving the model, it creates an arc_name by joining the temporary directory with \"packed.zip\". This arc_name is used to create an zip file u...   \n",
       "\n",
       "   ...  \\\n",
       "0  ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     explanation_granite_5  \\\n",
       "0  \\nThe provided code snippet in entry['code'] defines a method called `save_act` for a class (not shown in the provided code). The method takes an optional `path` parameter, which is set to a default value of `\"model.pkl\"` if not provided. \\n\\nThe method first creates a temporary directory using `tempfile.TemporaryDirectory()` and saves the model variables to a file within that directory. It then creates a zip file of the temporary directory, excluding the zip file itself. \\n\\nNext, the method reads the contents of the zip file and writes it to a binary file specified by the `path` parameter. Finally, it uses the `cloudpickle.dump()` function to save the model data and any additional parameters (`self._act_params`) to the binary file. \\n\\nIn summary, the code snippet in entry['code'] implements the functionality described in the doc string by saving the model to a pickle located at the specified `path`. The temporary directory and zip file are used to ensure that the model data is p...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                           explanation_deepseek_1_cleaned  \\\n",
       "0  ``/path/to/model.pkl` is created by the code, so the correct answer is \"\\npath/to/model.pkl is created by the code.\"The code creates a pickle file at a specified path, using a temporary directory to save the model and parameters. The correct file path is `path/to/model.pkl`, so the explanation is \"\\path/to/model.pkl is created by the code.\"   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            explanation_deepseek_2_cleaned  \\\n",
       "0  Okay, so I'm trying to understand this code snippet that's supposed to save a model using pickle. Let me go through each part step by step.First, I see that the function is called save_act and it takes an argument path which is optional. So if path is None, it sets it to a specific location using logger.get_dir() and os.path.join. I remember that logger.get_dir() probably gives the directory of the logger, so this line is initializing the path variable correctly.Next, there's a tempfile.TemporaryDirectory() which is creating a temporary directory to avoid file persistence issues. That makes sense because saving to a file can cause issues if multiple functions are called in quick succession.Then, save_variables is called with the full path of the temporary directory and \"model\". I'm not exactly sure what save_variables does, but I assume it's saving some data into that directory. Maybe it's saving the model data and some parameters.After that, an arc_name is created using os.path.jo...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            explanation_deepseek_3_cleaned  \\\n",
       "0  This code snippet is designed to save a model (a type of machine learning model) into a file format called pickle. The pickle format is a way to store objects in a compact and efficient manner, often used for later loading back the model's data. The code does a few key things:1. It creates a temporary directory to store the model and its serialized form.2. It constructs the names of the model and its serialized pickle file (arc_name) using a common directory and the specified path.3. It walks through all the files in the temporary directory and moves them into the pickle file, ensuring that each file is correctly placed.4. Finally, it saves the model data and parameters to the pickle file using cloudpickle.dump, which is a common method for converting Python objects to pickle.This code snippet is designed to save a model into a pickle file located at a specified path. It creates a temporary directory, constructs the model and pickle file names, moves all files into the pickle file,...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            explanation_deepseek_4_cleaned  \\\n",
       "0  Okay, I'm looking at this code snippet, and I need to understand what it's doing. So, the class is named something like Model or something similar, and it's a PyTorch class, right? It has a method called save_act which takes an optional path parameter.First, I notice that the code checks if path is None. If it is, then it sets the path to the join of logger.get_dir() and \"model.pkl\". So, it's probably using the logger to get the current working directory where the model should be saved. If the path is provided, it uses that path instead.Then, it creates a temporary directory using a tempfile.TemporaryDirectory(), which is common to avoid holding onto files that might be deleted. Inside this temporary directory, it saves the model using save_variables, which I assume is a method that writes the model's data to the td directory.After saving the model, it creates an arc_name by joining the temporary directory with \"packed.zip\". This arc_name is used to create an zip file using a ZipFi...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            explanation_deepseek_5_cleaned  \\\n",
       "0  The code snippet defines the `save_act` method, which saves a model to a pickle file located at the specified path. Here's how it achieves this:1. **Handling the Path**: If the `path` parameter is `None`, it sets the target path to `logger.get_dir() + \"model.pkl\"`.2. **Temporary Directory Creation**: Uses `TempFile.TemporaryDirectory()` to create a new directory for saving variables and the zip file.3. **Zipfile Creation**: Constructs a zip file (`arc_name`) using `os.walk` to ensure all files are included except the zip itself.4. **Zipfile Population**: Populates the zip file with all entries from the directory, excluding the zip name.5. **Model Data Reading**: Reads the model data from the zip file and the parameters from the object.6. **Pickling the Data**: Uses `cloudpickle.dump` to serialize the tuple `(model_data, self._act_params)` into a pickle file.7. **Target Pickle File**: Opens and writes the pickle file at the specified `path` to the cloud.This approach ensures the mod...   \n",
       "\n",
       "  len_e1 len_e2 len_e3 len_e4  \n",
       "0    342   2347   1157   2220  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = ['query_id', 'corpus_id', 'doc', 'code',\n",
    "       # 'explanation_granite_1',\n",
    "       # 'explanation_granite_2', 'explanation_granite_3',\n",
    "       # 'explanation_granite_4', 'explanation_granite_5',\n",
    "       'explanation_deepseek_1_cleaned', 'explanation_deepseek_2_cleaned',\n",
    "       'explanation_deepseek_3_cleaned', 'explanation_deepseek_4_cleaned',\n",
    "       'explanation_deepseek_5_cleaned']\n",
    "\n",
    "df[final_cols].to_csv('/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/postprocessing/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postprocessed=pd.read_csv('/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/postprocessing/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>doc</th>\n",
       "      <th>code</th>\n",
       "      <th>explanation_deepseek_1_cleaned</th>\n",
       "      <th>explanation_deepseek_2_cleaned</th>\n",
       "      <th>explanation_deepseek_3_cleaned</th>\n",
       "      <th>explanation_deepseek_4_cleaned</th>\n",
       "      <th>explanation_deepseek_5_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>q251820</td>\n",
       "      <td>c251820</td>\n",
       "      <td>Save model to a pickle located at `path`</td>\n",
       "      <td>def save_act(self, path=None):\\n        \"\"\"Save model to a pickle located at `path`\"\"\"\\n        if path is None:\\n            path = os.path.join(logger.get_dir(), \"model.pkl\")\\n\\n        with tempfile.TemporaryDirectory() as td:\\n            save_variables(os.path.join(td, \"model\"))\\n            arc_name = os.path.join(td, \"packed.zip\")\\n            with zipfile.ZipFile(arc_name, 'w') as zipf:\\n                for root, dirs, files in os.walk(td):\\n                    for fname in files:\\n                        file_path = os.path.join(root, fname)\\n                        if file_path != arc_name:\\n                            zipf.write(file_path, os.path.relpath(file_path, td))\\n            with open(arc_name, \"rb\") as f:\\n                model_data = f.read()\\n        with open(path, \"wb\") as f:\\n            cloudpickle.dump((model_data, self._act_params), f)</td>\n",
       "      <td>``/path/to/model.pkl` is created by the code, so the correct answer is \"\\npath/to/model.pkl is created by the code.\"The code creates a pickle file at a specified path, using a temporary directory to save the model and parameters. The correct file path is `path/to/model.pkl`, so the explanation is \"\\path/to/model.pkl is created by the code.\"</td>\n",
       "      <td>Okay, so I'm trying to understand this code snippet that's supposed to save a model using pickle. Let me go through each part step by step.First, I see that the function is called save_act and it takes an argument path which is optional. So if path is None, it sets it to a specific location using logger.get_dir() and os.path.join. I remember that logger.get_dir() probably gives the directory of the logger, so this line is initializing the path variable correctly.Next, there's a tempfile.TemporaryDirectory() which is creating a temporary directory to avoid file persistence issues. That makes sense because saving to a file can cause issues if multiple functions are called in quick succession.Then, save_variables is called with the full path of the temporary directory and \"model\". I'm not exactly sure what save_variables does, but I assume it's saving some data into that directory. Maybe it's saving the model data and some parameters.After that, an arc_name is created using os.path.jo...</td>\n",
       "      <td>This code snippet is designed to save a model (a type of machine learning model) into a file format called pickle. The pickle format is a way to store objects in a compact and efficient manner, often used for later loading back the model's data. The code does a few key things:1. It creates a temporary directory to store the model and its serialized form.2. It constructs the names of the model and its serialized pickle file (arc_name) using a common directory and the specified path.3. It walks through all the files in the temporary directory and moves them into the pickle file, ensuring that each file is correctly placed.4. Finally, it saves the model data and parameters to the pickle file using cloudpickle.dump, which is a common method for converting Python objects to pickle.This code snippet is designed to save a model into a pickle file located at a specified path. It creates a temporary directory, constructs the model and pickle file names, moves all files into the pickle file,...</td>\n",
       "      <td>Okay, I'm looking at this code snippet, and I need to understand what it's doing. So, the class is named something like Model or something similar, and it's a PyTorch class, right? It has a method called save_act which takes an optional path parameter.First, I notice that the code checks if path is None. If it is, then it sets the path to the join of logger.get_dir() and \"model.pkl\". So, it's probably using the logger to get the current working directory where the model should be saved. If the path is provided, it uses that path instead.Then, it creates a temporary directory using a tempfile.TemporaryDirectory(), which is common to avoid holding onto files that might be deleted. Inside this temporary directory, it saves the model using save_variables, which I assume is a method that writes the model's data to the td directory.After saving the model, it creates an arc_name by joining the temporary directory with \"packed.zip\". This arc_name is used to create an zip file using a ZipFi...</td>\n",
       "      <td>The code snippet defines the `save_act` method, which saves a model to a pickle file located at the specified path. Here's how it achieves this:1. **Handling the Path**: If the `path` parameter is `None`, it sets the target path to `logger.get_dir() + \"model.pkl\"`.2. **Temporary Directory Creation**: Uses `TempFile.TemporaryDirectory()` to create a new directory for saving variables and the zip file.3. **Zipfile Creation**: Constructs a zip file (`arc_name`) using `os.walk` to ensure all files are included except the zip itself.4. **Zipfile Population**: Populates the zip file with all entries from the directory, excluding the zip name.5. **Model Data Reading**: Reads the model data from the zip file and the parameters from the object.6. **Pickling the Data**: Uses `cloudpickle.dump` to serialize the tuple `(model_data, self._act_params)` into a pickle file.7. **Target Pickle File**: Opens and writes the pickle file at the specified `path` to the cloud.This approach ensures the mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>q251821</td>\n",
       "      <td>c251821</td>\n",
       "      <td>CNN from Nature paper.</td>\n",
       "      <td>def nature_cnn(unscaled_images, **conv_kwargs):\\n    \"\"\"\\n    CNN from Nature paper.\\n    \"\"\"\\n    scaled_images = tf.cast(unscaled_images, tf.float32) / 255.\\n    activ = tf.nn.relu\\n    h = activ(conv(scaled_images, 'c1', nf=32, rf=8, stride=4, init_scale=np.sqrt(2),\\n                   **conv_kwargs))\\n    h2 = activ(conv(h, 'c2', nf=64, rf=4, stride=2, init_scale=np.sqrt(2), **conv_kwargs))\\n    h3 = activ(conv(h2, 'c3', nf=64, rf=3, stride=1, init_scale=np.sqrt(2), **conv_kwargs))\\n    h3 = conv_to_fc(h3)\\n    return activ(fc(h3, 'fc1', nh=512, init_scale=np.sqrt(2)))</td>\n",
       "      <td>The code snippet implements a CNN from the Nature paper, processing input images through several convolutional and fully-connected layers. Each layer is defined with specific parameters, and the output is passed through a fully connected layer to produce the final result.The code snippet implements a CNN from the Nature paper, processing input images through several convolutional and fully-connected layers. Each layer is defined with specific parameters, and the output is passed through a fully connected layer to produce the final result.</td>\n",
       "      <td>1. **Line 1:** `scaled_images = tf.cast(unscaled_images, tf.float32) / 255.`     *Explanation:* This line converts the input images from their original data type to float32 and scales them between 0 and 1. This is a common preprocessing step for feeding images into neural networks.2. **Line 2:** `activ = tf.nn.relu`     *Explanation:* This line declares a variable `activ` that will hold the activation function of a neural layer. Here, we are using the ReLU (Rectified Linear Unit) activation function.3. **Line 3:** `h = activ(conv(scaled_images, 'c1', nf=32, rf=8, stride=4, init_scale=np.sqrt(2), **conv_kwargs))`     *Explanation:* This line applies a convolutional layer (`conv`) to the scaled images. The layer has the following parameters:       - `c1`: The first convolutional layer, with 32 feature maps (nf=32), 8 filters (rf=8), stride 4, and initialization scale sqrt(2).       - `**conv_kwargs`: Additional keyword arguments passed to the convolutional layer.  4. **Line 4:** `h2 ...</td>\n",
       "      <td>This code snippet is a function called `nature_cnn` that takes in some input images and processes them through a series of layers to produce an output. The function uses a type of neural network called a CNN (convolutional neural network) which is commonly used in image processing and computer vision tasks. The key operations include scaling the input images to fit the range of floating-point numbers, applying a type of activation function (reLU) to introduce non-linearity, and convolving the images with filters of different sizes and strides to extract features from the images. The final output is obtained by passing the convolved images through a fully connected layer, which produces a feature vector that can be used for tasks such as classification or regression.</td>\n",
       "      <td>Okay, I'm going to try to figure out what this code does based on the provided explanation. The code is a function called nature_cnn that takes unscaled_images and some convolutional keyword arguments.First, it scales the images and converts them to float32 type, dividing each pixel by 255. This is a common preprocessing step for image data to ensure it's in the correct format for subsequent operations.Next, it defines the activation function as tf.nn.relu. Then, it defines the convolution operations for each layer. The first convolution layer, 'c1', has a filter size of 8x8, 32 feature maps, and a stride of 4. The second layer, 'c2', uses a 4x4 filter, 64 feature maps, and stride 2. The third layer, 'c3', has a 3x3 filter, 64 feature maps, stride 1.After applying the activation function to each convolutional layer, it converts the output to a fully connected layer by calling conv_to_fc. Finally, it returns the activated result of a fully connected layer with 512 units and an initi...</td>\n",
       "      <td>The code snippet implements a CNN from the Nature paper by first scaling and normalizing the input images. It applies multiple convolutional layers with specified filters, strides, and initialization scales. Each layer uses the ReLU activation function. The final output is passed through a fully connected layer with a specified number of neurons and initialization scale. The code achieves the functionality described in the docstring by sequentially applying these layers to process the input images.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>q251822</td>\n",
       "      <td>c251822</td>\n",
       "      <td>convolutions-only net\\n\\n    Parameters:\\n    ----------\\n\\n    conv:       list of triples (filter_number, filter_size, stride) specifying parameters for each layer.\\n\\n    Returns:\\n\\n    function that takes tensorflow tensor as input and returns the output of the last convolutional layer</td>\n",
       "      <td>def conv_only(convs=[(32, 8, 4), (64, 4, 2), (64, 3, 1)], **conv_kwargs):\\n    '''\\n    convolutions-only net\\n\\n    Parameters:\\n    ----------\\n\\n    conv:       list of triples (filter_number, filter_size, stride) specifying parameters for each layer.\\n\\n    Returns:\\n\\n    function that takes tensorflow tensor as input and returns the output of the last convolutional layer\\n\\n    '''\\n\\n    def network_fn(X):\\n        out = tf.cast(X, tf.float32) / 255.\\n        with tf.variable_scope(\"convnet\"):\\n            for num_outputs, kernel_size, stride in convs:\\n                out = layers.convolution2d(out,\\n                                           num_outputs=num_outputs,\\n                                           kernel_size=kernel_size,\\n                                           stride=stride,\\n                                           activation_fn=tf.nn.relu,\\n                                           **conv_kwargs)\\n\\n        return out\\n    return network_fn</td>\n",
       "      <td>The code snippet defines a function `conv_only` that takes a list of convolutional layers' parameters and returns another function `network_fn`. This function processes an input tensor, applies each convolutional layer with specified parameters, and returns the output of the last convolutional layer. The layers use ReLU activation and are designed to be concise.</td>\n",
       "      <td>the code snippet defines a function `conv_only` that returns another function `network_fn`. this function processes an input tensor through a series of convolutional layers specified by `convs`. each layer applies a convolution with specified filter number, size, and stride, followed by activation function `tf.nn.relu`. the final output is the last convolutional layer's output.### line-by-line explanation1. **def conv_only(convs=[(32, 8, 4), (64, 4, 2), (64, 3, 1)], **conv_kwargs):**   - this line defines the `conv_only` function, which takes `convs` as a list of tuples and `**conv_kwargs` as keyword arguments.2. **'def network_fn(X):'**   - this line defines the inner function `network_fn`, which takes `X` as input.3. **'out = tf.cast(X, tf.float32) / 255.'**   - this line normalizes the input tensor `X` to the range [0, 1] by casting it to `tf.float32` and dividing by 255.4. **'with tf.variable_scope(\"convnet\"):'**   - this line starts a new variable scope named \"convnet\" to mana...</td>\n",
       "      <td>Okay, so I'm trying to understand what this code is doing. It looks like there are two functions here, conv_only and network_fn. Both of them are related to some kind of neural network, specifically a convolutional neural network because they involve layers like convolution2d.In the conv_only function, it takes a list of convs, which are parameters for each layer. The function network_fn is another function that does the main work. It takes an input tensor X, casts it to float32 and normalizes it between 0 and 1. Then it's wrapped in a variable scope called convnet.Inside this scope, there's a loop that iterates over each (num_outputs, kernel_size, stride) in the convs list. For each one, it applies a convolution2d layer. The convolution2d function takes the current output, the number of outputs (num_outputs), the kernel size, and the stride. It applies the ReLU activation function and uses some keyword arguments **conv_kwargs.After processing all the layers, it returns the output ...</td>\n",
       "      <td>The code snippet defines a function called conv_only which returns another function network_fn. The function takes a tensor as input and normalizes it. It uses variable_scope to name the graph. Then, it iterates over each (filter_number, filter_size, stride) in the list convs, applying convolution2d with ReLU activation, and returns the output of the last convolutional layer.The code is designed to process a tensor through a series of convolutional layers specified by convs, applying each filter with the given stride, and returns the output of the last convolutional layer.The code may have some issues, such as not resetting some variables or not properly handling the output dimensions across layers. For example, if the stride is larger than the filter size, the output height and width will decrease, which could lead to loss of spatial information. Additionally, the activation function might not be applied correctly if there are multiple layers or if the conv_kwargs are not properly...</td>\n",
       "      <td>The code snippet implements a convolutional neural network (CNN) that processes input images. It uses a list of convolutional layers, each defined by its filter size, stride, and number of filters. Each layer applies a set of filters to the input, performs a convolution, and applies activation functions like ReLU. The network processes the input through each convolutional layer and returns the output of the last convolutional layer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>q251823</td>\n",
       "      <td>c251823</td>\n",
       "      <td>Create a wrapped, monitored SubprocVecEnv for Atari and MuJoCo.</td>\n",
       "      <td>def make_vec_env(env_id, env_type, num_env, seed,\\n                 wrapper_kwargs=None,\\n                 start_index=0,\\n                 reward_scale=1.0,\\n                 flatten_dict_observations=True,\\n                 gamestate=None):\\n    \"\"\"\\n    Create a wrapped, monitored SubprocVecEnv for Atari and MuJoCo.\\n    \"\"\"\\n    wrapper_kwargs = wrapper_kwargs or {}\\n    mpi_rank = MPI.COMM_WORLD.Get_rank() if MPI else 0\\n    seed = seed + 10000 * mpi_rank if seed is not None else None\\n    logger_dir = logger.get_dir()\\n    def make_thunk(rank):\\n        return lambda: make_env(\\n            env_id=env_id,\\n            env_type=env_type,\\n            mpi_rank=mpi_rank,\\n            subrank=rank,\\n            seed=seed,\\n            reward_scale=reward_scale,\\n            gamestate=gamestate,\\n            flatten_dict_observations=flatten_dict_observations,\\n            wrapper_kwargs=wrapper_kwargs,\\n            logger_dir=logger_dir\\n        )\\n\\n    set_global_seeds(seed)\\n ...</td>\n",
       "      <td>This code is creating a wrapped environment for the SubprocVecEnv, which is used for parallel processing in reinforcement learning, particularly for Atari and MuJoCo environments. The wrapper monitors each process and ensures that all sub-processes are initialized correctly. It includes parameters like seed, reward_scale, flatten_dict_observations, and wrapper_kwargs, which are used during the environment setup. The code ensures proper distribution of tasks across multiple environments, enhancing efficiency in parallel RL setups.The code creates a wrapped environment for parallel sub-processes, ensuring each has the correct setup. Parameters like seed, reward_scale, and flatten_dict_observations are used for monitoring, and wrapper_kwargs for customizations. It returns an environment that either distributes tasks or uses a dummy, enhancing parallel RL efficiency.</td>\n",
       "      <td>```pythondef make_vec_env(env_id, env_type, num_env, seed,                wrapper_kwargs=None,                start_index=0,                reward_scale=1.0,                flatten_dict_observations=True,                gamestate=None):    \"\"\"    Create a wrapped, monitored SubprocVecEnv for Atari and MuJoCo.    Args:        env_id (int): The ID of the environment to wrap.        env_type (str): The type of the environment (e.g., 'atari' or 'muco').        num_env (int): The number of environments to create.        seed (int): The seed for the random number generator used by each environment.        wrapper_kwargs (dict, optional): Additional keyword arguments for the wrapper function.        start_index (int): The starting index for seeds in parallel environments.        reward_scale (float): The scale of the reward function.        flatten_dict_observations (bool): Whether to flatten dictionary observations.        gamestate (dict): The game state if the environment is a simulati...</td>\n",
       "      <td>This code creates a special environment that wraps and monitors another environment, likely for simulating Atari and MuJoCo games. It handles the setup of multiple environments (subenvs) for parallel processing and manages global seeds for randomness. It uses wrapper functions to customize the environment's behavior, and it sets up global seeds for reproducibility.</td>\n",
       "      <td>This code snippet is a Python implementation of a wrapped, monitored SubprocVecEnv for Atari and MuJoCo environments. The main function, make_vec_env, takes several parameters including env_id, env_type, num_env, seed, wrapper_kwargs, start_index, reward_scale, flatten_dict_observations, and gameState. The wrapper_kwargs is a keyword argument that is set to its default value if not provided. The seed is adjusted based on the MPI rank, which is obtained from the main program using the MPI.COMM_WORLD.Get_rank() or 0 if MPI is not present. The logger_dir is assigned from the logger module. Within make_thunk, a lambda function is defined to create a closure that references the make_env function. This closure captures the parameters such as env_id, env_type, mpi_rank, subrank, seed, reward_scale, gamestate, flatten_dict_observations, wrapper_kwargs, and logger_dir.The set_global_seeds method is called with the seed, which sets the global seed for the environment.If multiple environments...</td>\n",
       "      <td>The provided code snippet implements a wrapped, monitored SubprocVecEnv for Atari and MuJoCo environments. The code creates a function `make_vec_env` which sets global seeds based on the rank, returns a wrapped environment, and handles subranks. The function uses a lambda to wrap the environment, ensuring it's monitored and can be used in multi-environment setups.**Step-by-Step Explanation:**1. **Global Seed Setup:** The code initializes global seeds for each environment, adjusting them based on the rank ( MPI rank) using `seed = seed + 10000 * mpi_rank`.2. **Environment Wrapping:** The function returns a wrapped environment, which likely handles communication between multiple processes in a multi-environment scenario.3. **SubprocVecEnv Implementation:** The `make_vec_env` function creates an environment, sets up seeds, and handles subranks (process indices) to create a distributed environment.4. **Multi-Environment Support:** If multiple environments (`num_env &gt; 1`), a list of wra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>q251824</td>\n",
       "      <td>c251824</td>\n",
       "      <td>Parse arguments not consumed by arg parser into a dicitonary</td>\n",
       "      <td>def parse_unknown_args(args):\\n    \"\"\"\\n    Parse arguments not consumed by arg parser into a dicitonary\\n    \"\"\"\\n    retval = {}\\n    preceded_by_key = False\\n    for arg in args:\\n        if arg.startswith('--'):\\n            if '=' in arg:\\n                key = arg.split('=')[0][2:]\\n                value = arg.split('=')[1]\\n                retval[key] = value\\n            else:\\n                key = arg[2:]\\n                preceded_by_key = True\\n        elif preceded_by_key:\\n            retval[key] = arg\\n            preceded_by_key = False\\n\\n    return retval</td>\n",
       "      <td>The code is meant to parse arguments not consumed by an argument parser into a dictionary. It looks for arguments starting with '--' and extracts keys and values from them, storing them in a dictionary.The code is meant to parse arguments not consumed by an argument parser into a dictionary. It looks for arguments starting with '--' and extracts keys and values from them, storing them in a dictionary.</td>\n",
       "      <td>Alright, so I'm trying to understand this code snippet. It's a Python function called parse_unknown_args. The docstring says it parses arguments not consumed by an argparse parser into a dictionary. Hmm, okay. Let me break it down step by step.First, the function starts with retval = {}. So, retval is an empty dictionary that will store the parsed arguments. That makes sense.Next is preceded_by_key = False. This is a variable initialized to False. I think this variable is used to track whether we're expecting an argument that comes after another argument. It might be similar to some other parsing techniques where you remember whether the previous argument was something that should be followed by another.Then, there's a for loop over args: for arg in args: This iterates over each argument in the input.Inside the loop, there's an if statement checking if arg starts with '--'. So, any argument that starts with a hyphen is considered here. That could be for command line arguments, espe...</td>\n",
       "      <td>This code snippet defines a function called parse_unknown_args. It takes a list of arguments, called args, and returns a dictionary called retval. The purpose of this function is to parse the arguments and extract key-value pairs into a dictionary. The function uses a loop to iterate over each argument in args. For each argument, it checks if it starts with a '--' character. If it does, it then checks if there's an equals sign in the argument. If there is, it splits the argument into a key and a value. The key is everything after '--' and before '=', and the value is the part after '='. If there's no equals sign, it uses the rest of the string after '--' as the key, and sets preceded_by_key to True. If the argument doesn't start with '--', the function checks if preceded_by_key is True. If it is, it adds the argument as a key-value pair to the dictionary and resets preceded_by_key to False. This process continues for all arguments in args, building a dictionary of key-value pairs. ...</td>\n",
       "      <td>Okay, I've got this code snippet to explain. Let me read through it carefully. The function is called parse_unknown_args and it's supposed to parse arguments that aren't handled by the parser into a dictionary. So, the code starts by initializing a dictionary called retval. It also has two flags: preceded_by_key and preceded_by_key, which I think is a typo and should be preceded_by_key. Then there's a loop over each argument in args.Looking at each argument, the code checks if it starts with a '--'. If it does, it checks if there's an equals sign in the string. If there is, it splits the string at the equals sign. The part before the equals is the key, and the part after is the value. For example, if the argument is '--some_key=123', the key becomes 'some_key' and the value is 123.If there's no equals sign, the code sets the key to the substring starting from the index after the '--' symbol and takes everything until the end. This key is then set in the retval dictionary, and the f...</td>\n",
       "      <td>The code snippet provided implements the functionality described in the docstring. The function `parse_unknown_args` iterates over each argument, handling key-value pairs and other arguments to build a dictionary. Here's a step-by-step explanation:1. **Initialization**: `retval` is initialized as an empty dictionary, and `preceded_by_key` is set to `False` to track whether an argument is part of a key being set.2. **Loop through Arguments**: For each argument in the input list `args`, the function checks if the argument starts with `--`.3. **Handling Key-Value Pairs**:    - If an argument is a key-value pair (e.g., `--key-value`), it splits the string by `=`. The part after `=` is the value, and everything before `=` (excluding `--`) is the key.    - If the argument is a single key (e.g., `key`), it sets the key to the value.4. **Tracking Key Usage**: If an argument is part of a key (`preceded_by_key` is `True`), it sets the key-value pair in `retval` and resets `preceded_by_key` t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 query_id corpus_id  \\\n",
       "0           0  q251820   c251820   \n",
       "1           1  q251821   c251821   \n",
       "2           2  q251822   c251822   \n",
       "3           3  q251823   c251823   \n",
       "4           4  q251824   c251824   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                   doc  \\\n",
       "0                                                                                                                                                                                                                                                             Save model to a pickle located at `path`   \n",
       "1                                                                                                                                                                                                                                                                               CNN from Nature paper.   \n",
       "2  convolutions-only net\\n\\n    Parameters:\\n    ----------\\n\\n    conv:       list of triples (filter_number, filter_size, stride) specifying parameters for each layer.\\n\\n    Returns:\\n\\n    function that takes tensorflow tensor as input and returns the output of the last convolutional layer   \n",
       "3                                                                                                                                                                                                                                      Create a wrapped, monitored SubprocVecEnv for Atari and MuJoCo.   \n",
       "4                                                                                                                                                                                                                                         Parse arguments not consumed by arg parser into a dicitonary   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      code  \\\n",
       "0                                                                                                                             def save_act(self, path=None):\\n        \"\"\"Save model to a pickle located at `path`\"\"\"\\n        if path is None:\\n            path = os.path.join(logger.get_dir(), \"model.pkl\")\\n\\n        with tempfile.TemporaryDirectory() as td:\\n            save_variables(os.path.join(td, \"model\"))\\n            arc_name = os.path.join(td, \"packed.zip\")\\n            with zipfile.ZipFile(arc_name, 'w') as zipf:\\n                for root, dirs, files in os.walk(td):\\n                    for fname in files:\\n                        file_path = os.path.join(root, fname)\\n                        if file_path != arc_name:\\n                            zipf.write(file_path, os.path.relpath(file_path, td))\\n            with open(arc_name, \"rb\") as f:\\n                model_data = f.read()\\n        with open(path, \"wb\") as f:\\n            cloudpickle.dump((model_data, self._act_params), f)   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                      def nature_cnn(unscaled_images, **conv_kwargs):\\n    \"\"\"\\n    CNN from Nature paper.\\n    \"\"\"\\n    scaled_images = tf.cast(unscaled_images, tf.float32) / 255.\\n    activ = tf.nn.relu\\n    h = activ(conv(scaled_images, 'c1', nf=32, rf=8, stride=4, init_scale=np.sqrt(2),\\n                   **conv_kwargs))\\n    h2 = activ(conv(h, 'c2', nf=64, rf=4, stride=2, init_scale=np.sqrt(2), **conv_kwargs))\\n    h3 = activ(conv(h2, 'c3', nf=64, rf=3, stride=1, init_scale=np.sqrt(2), **conv_kwargs))\\n    h3 = conv_to_fc(h3)\\n    return activ(fc(h3, 'fc1', nh=512, init_scale=np.sqrt(2)))   \n",
       "2                def conv_only(convs=[(32, 8, 4), (64, 4, 2), (64, 3, 1)], **conv_kwargs):\\n    '''\\n    convolutions-only net\\n\\n    Parameters:\\n    ----------\\n\\n    conv:       list of triples (filter_number, filter_size, stride) specifying parameters for each layer.\\n\\n    Returns:\\n\\n    function that takes tensorflow tensor as input and returns the output of the last convolutional layer\\n\\n    '''\\n\\n    def network_fn(X):\\n        out = tf.cast(X, tf.float32) / 255.\\n        with tf.variable_scope(\"convnet\"):\\n            for num_outputs, kernel_size, stride in convs:\\n                out = layers.convolution2d(out,\\n                                           num_outputs=num_outputs,\\n                                           kernel_size=kernel_size,\\n                                           stride=stride,\\n                                           activation_fn=tf.nn.relu,\\n                                           **conv_kwargs)\\n\\n        return out\\n    return network_fn   \n",
       "3  def make_vec_env(env_id, env_type, num_env, seed,\\n                 wrapper_kwargs=None,\\n                 start_index=0,\\n                 reward_scale=1.0,\\n                 flatten_dict_observations=True,\\n                 gamestate=None):\\n    \"\"\"\\n    Create a wrapped, monitored SubprocVecEnv for Atari and MuJoCo.\\n    \"\"\"\\n    wrapper_kwargs = wrapper_kwargs or {}\\n    mpi_rank = MPI.COMM_WORLD.Get_rank() if MPI else 0\\n    seed = seed + 10000 * mpi_rank if seed is not None else None\\n    logger_dir = logger.get_dir()\\n    def make_thunk(rank):\\n        return lambda: make_env(\\n            env_id=env_id,\\n            env_type=env_type,\\n            mpi_rank=mpi_rank,\\n            subrank=rank,\\n            seed=seed,\\n            reward_scale=reward_scale,\\n            gamestate=gamestate,\\n            flatten_dict_observations=flatten_dict_observations,\\n            wrapper_kwargs=wrapper_kwargs,\\n            logger_dir=logger_dir\\n        )\\n\\n    set_global_seeds(seed)\\n ...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                       def parse_unknown_args(args):\\n    \"\"\"\\n    Parse arguments not consumed by arg parser into a dicitonary\\n    \"\"\"\\n    retval = {}\\n    preceded_by_key = False\\n    for arg in args:\\n        if arg.startswith('--'):\\n            if '=' in arg:\\n                key = arg.split('=')[0][2:]\\n                value = arg.split('=')[1]\\n                retval[key] = value\\n            else:\\n                key = arg[2:]\\n                preceded_by_key = True\\n        elif preceded_by_key:\\n            retval[key] = arg\\n            preceded_by_key = False\\n\\n    return retval   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                explanation_deepseek_1_cleaned  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ``/path/to/model.pkl` is created by the code, so the correct answer is \"\\npath/to/model.pkl is created by the code.\"The code creates a pickle file at a specified path, using a temporary directory to save the model and parameters. The correct file path is `path/to/model.pkl`, so the explanation is \"\\path/to/model.pkl is created by the code.\"   \n",
       "1                                                                                                                                                                                                                                                                                                                                             The code snippet implements a CNN from the Nature paper, processing input images through several convolutional and fully-connected layers. Each layer is defined with specific parameters, and the output is passed through a fully connected layer to produce the final result.The code snippet implements a CNN from the Nature paper, processing input images through several convolutional and fully-connected layers. Each layer is defined with specific parameters, and the output is passed through a fully connected layer to produce the final result.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 The code snippet defines a function `conv_only` that takes a list of convolutional layers' parameters and returns another function `network_fn`. This function processes an input tensor, applies each convolutional layer with specified parameters, and returns the output of the last convolutional layer. The layers use ReLU activation and are designed to be concise.   \n",
       "3  This code is creating a wrapped environment for the SubprocVecEnv, which is used for parallel processing in reinforcement learning, particularly for Atari and MuJoCo environments. The wrapper monitors each process and ensures that all sub-processes are initialized correctly. It includes parameters like seed, reward_scale, flatten_dict_observations, and wrapper_kwargs, which are used during the environment setup. The code ensures proper distribution of tasks across multiple environments, enhancing efficiency in parallel RL setups.The code creates a wrapped environment for parallel sub-processes, ensuring each has the correct setup. Parameters like seed, reward_scale, and flatten_dict_observations are used for monitoring, and wrapper_kwargs for customizations. It returns an environment that either distributes tasks or uses a dummy, enhancing parallel RL efficiency.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         The code is meant to parse arguments not consumed by an argument parser into a dictionary. It looks for arguments starting with '--' and extracts keys and values from them, storing them in a dictionary.The code is meant to parse arguments not consumed by an argument parser into a dictionary. It looks for arguments starting with '--' and extracts keys and values from them, storing them in a dictionary.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            explanation_deepseek_2_cleaned  \\\n",
       "0  Okay, so I'm trying to understand this code snippet that's supposed to save a model using pickle. Let me go through each part step by step.First, I see that the function is called save_act and it takes an argument path which is optional. So if path is None, it sets it to a specific location using logger.get_dir() and os.path.join. I remember that logger.get_dir() probably gives the directory of the logger, so this line is initializing the path variable correctly.Next, there's a tempfile.TemporaryDirectory() which is creating a temporary directory to avoid file persistence issues. That makes sense because saving to a file can cause issues if multiple functions are called in quick succession.Then, save_variables is called with the full path of the temporary directory and \"model\". I'm not exactly sure what save_variables does, but I assume it's saving some data into that directory. Maybe it's saving the model data and some parameters.After that, an arc_name is created using os.path.jo...   \n",
       "1  1. **Line 1:** `scaled_images = tf.cast(unscaled_images, tf.float32) / 255.`     *Explanation:* This line converts the input images from their original data type to float32 and scales them between 0 and 1. This is a common preprocessing step for feeding images into neural networks.2. **Line 2:** `activ = tf.nn.relu`     *Explanation:* This line declares a variable `activ` that will hold the activation function of a neural layer. Here, we are using the ReLU (Rectified Linear Unit) activation function.3. **Line 3:** `h = activ(conv(scaled_images, 'c1', nf=32, rf=8, stride=4, init_scale=np.sqrt(2), **conv_kwargs))`     *Explanation:* This line applies a convolutional layer (`conv`) to the scaled images. The layer has the following parameters:       - `c1`: The first convolutional layer, with 32 feature maps (nf=32), 8 filters (rf=8), stride 4, and initialization scale sqrt(2).       - `**conv_kwargs`: Additional keyword arguments passed to the convolutional layer.  4. **Line 4:** `h2 ...   \n",
       "2  the code snippet defines a function `conv_only` that returns another function `network_fn`. this function processes an input tensor through a series of convolutional layers specified by `convs`. each layer applies a convolution with specified filter number, size, and stride, followed by activation function `tf.nn.relu`. the final output is the last convolutional layer's output.### line-by-line explanation1. **def conv_only(convs=[(32, 8, 4), (64, 4, 2), (64, 3, 1)], **conv_kwargs):**   - this line defines the `conv_only` function, which takes `convs` as a list of tuples and `**conv_kwargs` as keyword arguments.2. **'def network_fn(X):'**   - this line defines the inner function `network_fn`, which takes `X` as input.3. **'out = tf.cast(X, tf.float32) / 255.'**   - this line normalizes the input tensor `X` to the range [0, 1] by casting it to `tf.float32` and dividing by 255.4. **'with tf.variable_scope(\"convnet\"):'**   - this line starts a new variable scope named \"convnet\" to mana...   \n",
       "3  ```pythondef make_vec_env(env_id, env_type, num_env, seed,                wrapper_kwargs=None,                start_index=0,                reward_scale=1.0,                flatten_dict_observations=True,                gamestate=None):    \"\"\"    Create a wrapped, monitored SubprocVecEnv for Atari and MuJoCo.    Args:        env_id (int): The ID of the environment to wrap.        env_type (str): The type of the environment (e.g., 'atari' or 'muco').        num_env (int): The number of environments to create.        seed (int): The seed for the random number generator used by each environment.        wrapper_kwargs (dict, optional): Additional keyword arguments for the wrapper function.        start_index (int): The starting index for seeds in parallel environments.        reward_scale (float): The scale of the reward function.        flatten_dict_observations (bool): Whether to flatten dictionary observations.        gamestate (dict): The game state if the environment is a simulati...   \n",
       "4  Alright, so I'm trying to understand this code snippet. It's a Python function called parse_unknown_args. The docstring says it parses arguments not consumed by an argparse parser into a dictionary. Hmm, okay. Let me break it down step by step.First, the function starts with retval = {}. So, retval is an empty dictionary that will store the parsed arguments. That makes sense.Next is preceded_by_key = False. This is a variable initialized to False. I think this variable is used to track whether we're expecting an argument that comes after another argument. It might be similar to some other parsing techniques where you remember whether the previous argument was something that should be followed by another.Then, there's a for loop over args: for arg in args: This iterates over each argument in the input.Inside the loop, there's an if statement checking if arg starts with '--'. So, any argument that starts with a hyphen is considered here. That could be for command line arguments, espe...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            explanation_deepseek_3_cleaned  \\\n",
       "0  This code snippet is designed to save a model (a type of machine learning model) into a file format called pickle. The pickle format is a way to store objects in a compact and efficient manner, often used for later loading back the model's data. The code does a few key things:1. It creates a temporary directory to store the model and its serialized form.2. It constructs the names of the model and its serialized pickle file (arc_name) using a common directory and the specified path.3. It walks through all the files in the temporary directory and moves them into the pickle file, ensuring that each file is correctly placed.4. Finally, it saves the model data and parameters to the pickle file using cloudpickle.dump, which is a common method for converting Python objects to pickle.This code snippet is designed to save a model into a pickle file located at a specified path. It creates a temporary directory, constructs the model and pickle file names, moves all files into the pickle file,...   \n",
       "1                                                                                                                                                                                                                                 This code snippet is a function called `nature_cnn` that takes in some input images and processes them through a series of layers to produce an output. The function uses a type of neural network called a CNN (convolutional neural network) which is commonly used in image processing and computer vision tasks. The key operations include scaling the input images to fit the range of floating-point numbers, applying a type of activation function (reLU) to introduce non-linearity, and convolving the images with filters of different sizes and strides to extract features from the images. The final output is obtained by passing the convolved images through a fully connected layer, which produces a feature vector that can be used for tasks such as classification or regression.   \n",
       "2  Okay, so I'm trying to understand what this code is doing. It looks like there are two functions here, conv_only and network_fn. Both of them are related to some kind of neural network, specifically a convolutional neural network because they involve layers like convolution2d.In the conv_only function, it takes a list of convs, which are parameters for each layer. The function network_fn is another function that does the main work. It takes an input tensor X, casts it to float32 and normalizes it between 0 and 1. Then it's wrapped in a variable scope called convnet.Inside this scope, there's a loop that iterates over each (num_outputs, kernel_size, stride) in the convs list. For each one, it applies a convolution2d layer. The convolution2d function takes the current output, the number of outputs (num_outputs), the kernel size, and the stride. It applies the ReLU activation function and uses some keyword arguments **conv_kwargs.After processing all the layers, it returns the output ...   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          This code creates a special environment that wraps and monitors another environment, likely for simulating Atari and MuJoCo games. It handles the setup of multiple environments (subenvs) for parallel processing and manages global seeds for randomness. It uses wrapper functions to customize the environment's behavior, and it sets up global seeds for reproducibility.   \n",
       "4  This code snippet defines a function called parse_unknown_args. It takes a list of arguments, called args, and returns a dictionary called retval. The purpose of this function is to parse the arguments and extract key-value pairs into a dictionary. The function uses a loop to iterate over each argument in args. For each argument, it checks if it starts with a '--' character. If it does, it then checks if there's an equals sign in the argument. If there is, it splits the argument into a key and a value. The key is everything after '--' and before '=', and the value is the part after '='. If there's no equals sign, it uses the rest of the string after '--' as the key, and sets preceded_by_key to True. If the argument doesn't start with '--', the function checks if preceded_by_key is True. If it is, it adds the argument as a key-value pair to the dictionary and resets preceded_by_key to False. This process continues for all arguments in args, building a dictionary of key-value pairs. ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            explanation_deepseek_4_cleaned  \\\n",
       "0  Okay, I'm looking at this code snippet, and I need to understand what it's doing. So, the class is named something like Model or something similar, and it's a PyTorch class, right? It has a method called save_act which takes an optional path parameter.First, I notice that the code checks if path is None. If it is, then it sets the path to the join of logger.get_dir() and \"model.pkl\". So, it's probably using the logger to get the current working directory where the model should be saved. If the path is provided, it uses that path instead.Then, it creates a temporary directory using a tempfile.TemporaryDirectory(), which is common to avoid holding onto files that might be deleted. Inside this temporary directory, it saves the model using save_variables, which I assume is a method that writes the model's data to the td directory.After saving the model, it creates an arc_name by joining the temporary directory with \"packed.zip\". This arc_name is used to create an zip file using a ZipFi...   \n",
       "1  Okay, I'm going to try to figure out what this code does based on the provided explanation. The code is a function called nature_cnn that takes unscaled_images and some convolutional keyword arguments.First, it scales the images and converts them to float32 type, dividing each pixel by 255. This is a common preprocessing step for image data to ensure it's in the correct format for subsequent operations.Next, it defines the activation function as tf.nn.relu. Then, it defines the convolution operations for each layer. The first convolution layer, 'c1', has a filter size of 8x8, 32 feature maps, and a stride of 4. The second layer, 'c2', uses a 4x4 filter, 64 feature maps, and stride 2. The third layer, 'c3', has a 3x3 filter, 64 feature maps, stride 1.After applying the activation function to each convolutional layer, it converts the output to a fully connected layer by calling conv_to_fc. Finally, it returns the activated result of a fully connected layer with 512 units and an initi...   \n",
       "2  The code snippet defines a function called conv_only which returns another function network_fn. The function takes a tensor as input and normalizes it. It uses variable_scope to name the graph. Then, it iterates over each (filter_number, filter_size, stride) in the list convs, applying convolution2d with ReLU activation, and returns the output of the last convolutional layer.The code is designed to process a tensor through a series of convolutional layers specified by convs, applying each filter with the given stride, and returns the output of the last convolutional layer.The code may have some issues, such as not resetting some variables or not properly handling the output dimensions across layers. For example, if the stride is larger than the filter size, the output height and width will decrease, which could lead to loss of spatial information. Additionally, the activation function might not be applied correctly if there are multiple layers or if the conv_kwargs are not properly...   \n",
       "3  This code snippet is a Python implementation of a wrapped, monitored SubprocVecEnv for Atari and MuJoCo environments. The main function, make_vec_env, takes several parameters including env_id, env_type, num_env, seed, wrapper_kwargs, start_index, reward_scale, flatten_dict_observations, and gameState. The wrapper_kwargs is a keyword argument that is set to its default value if not provided. The seed is adjusted based on the MPI rank, which is obtained from the main program using the MPI.COMM_WORLD.Get_rank() or 0 if MPI is not present. The logger_dir is assigned from the logger module. Within make_thunk, a lambda function is defined to create a closure that references the make_env function. This closure captures the parameters such as env_id, env_type, mpi_rank, subrank, seed, reward_scale, gamestate, flatten_dict_observations, wrapper_kwargs, and logger_dir.The set_global_seeds method is called with the seed, which sets the global seed for the environment.If multiple environments...   \n",
       "4  Okay, I've got this code snippet to explain. Let me read through it carefully. The function is called parse_unknown_args and it's supposed to parse arguments that aren't handled by the parser into a dictionary. So, the code starts by initializing a dictionary called retval. It also has two flags: preceded_by_key and preceded_by_key, which I think is a typo and should be preceded_by_key. Then there's a loop over each argument in args.Looking at each argument, the code checks if it starts with a '--'. If it does, it checks if there's an equals sign in the string. If there is, it splits the string at the equals sign. The part before the equals is the key, and the part after is the value. For example, if the argument is '--some_key=123', the key becomes 'some_key' and the value is 123.If there's no equals sign, the code sets the key to the substring starting from the index after the '--' symbol and takes everything until the end. This key is then set in the retval dictionary, and the f...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            explanation_deepseek_5_cleaned  \n",
       "0  The code snippet defines the `save_act` method, which saves a model to a pickle file located at the specified path. Here's how it achieves this:1. **Handling the Path**: If the `path` parameter is `None`, it sets the target path to `logger.get_dir() + \"model.pkl\"`.2. **Temporary Directory Creation**: Uses `TempFile.TemporaryDirectory()` to create a new directory for saving variables and the zip file.3. **Zipfile Creation**: Constructs a zip file (`arc_name`) using `os.walk` to ensure all files are included except the zip itself.4. **Zipfile Population**: Populates the zip file with all entries from the directory, excluding the zip name.5. **Model Data Reading**: Reads the model data from the zip file and the parameters from the object.6. **Pickling the Data**: Uses `cloudpickle.dump` to serialize the tuple `(model_data, self._act_params)` into a pickle file.7. **Target Pickle File**: Opens and writes the pickle file at the specified `path` to the cloud.This approach ensures the mod...  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The code snippet implements a CNN from the Nature paper by first scaling and normalizing the input images. It applies multiple convolutional layers with specified filters, strides, and initialization scales. Each layer uses the ReLU activation function. The final output is passed through a fully connected layer with a specified number of neurons and initialization scale. The code achieves the functionality described in the docstring by sequentially applying these layers to process the input images.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     The code snippet implements a convolutional neural network (CNN) that processes input images. It uses a list of convolutional layers, each defined by its filter size, stride, and number of filters. Each layer applies a set of filters to the input, performs a convolution, and applies activation functions like ReLU. The network processes the input through each convolutional layer and returns the output of the last convolutional layer.  \n",
       "3  The provided code snippet implements a wrapped, monitored SubprocVecEnv for Atari and MuJoCo environments. The code creates a function `make_vec_env` which sets global seeds based on the rank, returns a wrapped environment, and handles subranks. The function uses a lambda to wrap the environment, ensuring it's monitored and can be used in multi-environment setups.**Step-by-Step Explanation:**1. **Global Seed Setup:** The code initializes global seeds for each environment, adjusting them based on the rank ( MPI rank) using `seed = seed + 10000 * mpi_rank`.2. **Environment Wrapping:** The function returns a wrapped environment, which likely handles communication between multiple processes in a multi-environment scenario.3. **SubprocVecEnv Implementation:** The `make_vec_env` function creates an environment, sets up seeds, and handles subranks (process indices) to create a distributed environment.4. **Multi-Environment Support:** If multiple environments (`num_env > 1`), a list of wra...  \n",
       "4  The code snippet provided implements the functionality described in the docstring. The function `parse_unknown_args` iterates over each argument, handling key-value pairs and other arguments to build a dictionary. Here's a step-by-step explanation:1. **Initialization**: `retval` is initialized as an empty dictionary, and `preceded_by_key` is set to `False` to track whether an argument is part of a key being set.2. **Loop through Arguments**: For each argument in the input list `args`, the function checks if the argument starts with `--`.3. **Handling Key-Value Pairs**:    - If an argument is a key-value pair (e.g., `--key-value`), it splits the string by `=`. The part after `=` is the value, and everything before `=` (excluding `--`) is the key.    - If the argument is a single key (e.g., `key`), it sets the key to the value.4. **Tracking Key Usage**: If an argument is part of a key (`preceded_by_key` is `True`), it sets the key-value pair in `retval` and resets `preceded_by_key` t...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_postprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/pre_processing_CSN/CodeSearchNet_Python_train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251820, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'query_id', 'corpus_id', 'score', 'doc', 'code',\n",
       "       'cleaned_code', 'remove_all_comments_issue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>score</th>\n",
       "      <th>doc</th>\n",
       "      <th>code</th>\n",
       "      <th>cleaned_code</th>\n",
       "      <th>remove_all_comments_issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>q0</td>\n",
       "      <td>c0</td>\n",
       "      <td>1</td>\n",
       "      <td>Set the text for this element.\\n\\n        Argu...</td>\n",
       "      <td>def settext(self, text, cls='current'):\\n     ...</td>\n",
       "      <td>\\ndef settext(self, text, cls='current'):\\n\\n ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>q1</td>\n",
       "      <td>c1</td>\n",
       "      <td>1</td>\n",
       "      <td>Associate a document with this element.\\n\\n   ...</td>\n",
       "      <td>def setdocument(self, doc):\\n        \"\"\"Associ...</td>\n",
       "      <td>\\ndef setdocument(self, doc):\\n\\n    assert is...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>q2</td>\n",
       "      <td>c2</td>\n",
       "      <td>1</td>\n",
       "      <td>Tests whether a new element of this class can ...</td>\n",
       "      <td>def addable(Class, parent, set=None, raiseexce...</td>\n",
       "      <td>\\ndef addable(Class, parent, set=None, raiseex...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>q3</td>\n",
       "      <td>c3</td>\n",
       "      <td>1</td>\n",
       "      <td>This method will be called after an element is...</td>\n",
       "      <td>def postappend(self):\\n        \"\"\"This method ...</td>\n",
       "      <td>\\ndef postappend(self):\\n\\n    if not self.doc...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>q4</td>\n",
       "      <td>c4</td>\n",
       "      <td>1</td>\n",
       "      <td>Recompute textual value based on the text cont...</td>\n",
       "      <td>def updatetext(self):\\n        \"\"\"Recompute te...</td>\n",
       "      <td>\\ndef updatetext(self):\\n\\n    if self.TEXTCON...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 query_id corpus_id  score  \\\n",
       "0           0       q0        c0      1   \n",
       "1           1       q1        c1      1   \n",
       "2           2       q2        c2      1   \n",
       "3           3       q3        c3      1   \n",
       "4           4       q4        c4      1   \n",
       "\n",
       "                                                 doc  \\\n",
       "0  Set the text for this element.\\n\\n        Argu...   \n",
       "1  Associate a document with this element.\\n\\n   ...   \n",
       "2  Tests whether a new element of this class can ...   \n",
       "3  This method will be called after an element is...   \n",
       "4  Recompute textual value based on the text cont...   \n",
       "\n",
       "                                                code  \\\n",
       "0  def settext(self, text, cls='current'):\\n     ...   \n",
       "1  def setdocument(self, doc):\\n        \"\"\"Associ...   \n",
       "2  def addable(Class, parent, set=None, raiseexce...   \n",
       "3  def postappend(self):\\n        \"\"\"This method ...   \n",
       "4  def updatetext(self):\\n        \"\"\"Recompute te...   \n",
       "\n",
       "                                        cleaned_code  \\\n",
       "0  \\ndef settext(self, text, cls='current'):\\n\\n ...   \n",
       "1  \\ndef setdocument(self, doc):\\n\\n    assert is...   \n",
       "2  \\ndef addable(Class, parent, set=None, raiseex...   \n",
       "3  \\ndef postappend(self):\\n\\n    if not self.doc...   \n",
       "4  \\ndef updatetext(self):\\n\\n    if self.TEXTCON...   \n",
       "\n",
       "   remove_all_comments_issue  \n",
       "0                      False  \n",
       "1                      False  \n",
       "2                      False  \n",
       "3                      False  \n",
       "4                      False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['remove_all_comments_issue']==False].to_csv('/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/postprocessing/output', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/pre_processing_CSN/CodeSearchNet_Python_train_cleaned1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251817, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query_id</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>score</th>\n",
       "      <th>doc</th>\n",
       "      <th>code</th>\n",
       "      <th>cleaned_code</th>\n",
       "      <th>remove_all_comments_issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>q0</td>\n",
       "      <td>c0</td>\n",
       "      <td>1</td>\n",
       "      <td>Set the text for this element.\\n\\n        Argu...</td>\n",
       "      <td>def settext(self, text, cls='current'):\\n     ...</td>\n",
       "      <td>\\ndef settext(self, text, cls='current'):\\n\\n ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>q1</td>\n",
       "      <td>c1</td>\n",
       "      <td>1</td>\n",
       "      <td>Associate a document with this element.\\n\\n   ...</td>\n",
       "      <td>def setdocument(self, doc):\\n        \"\"\"Associ...</td>\n",
       "      <td>\\ndef setdocument(self, doc):\\n\\n    assert is...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>q2</td>\n",
       "      <td>c2</td>\n",
       "      <td>1</td>\n",
       "      <td>Tests whether a new element of this class can ...</td>\n",
       "      <td>def addable(Class, parent, set=None, raiseexce...</td>\n",
       "      <td>\\ndef addable(Class, parent, set=None, raiseex...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>q3</td>\n",
       "      <td>c3</td>\n",
       "      <td>1</td>\n",
       "      <td>This method will be called after an element is...</td>\n",
       "      <td>def postappend(self):\\n        \"\"\"This method ...</td>\n",
       "      <td>\\ndef postappend(self):\\n\\n    if not self.doc...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>q4</td>\n",
       "      <td>c4</td>\n",
       "      <td>1</td>\n",
       "      <td>Recompute textual value based on the text cont...</td>\n",
       "      <td>def updatetext(self):\\n        \"\"\"Recompute te...</td>\n",
       "      <td>\\ndef updatetext(self):\\n\\n    if self.TEXTCON...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 query_id corpus_id  score  \\\n",
       "0           0       q0        c0      1   \n",
       "1           1       q1        c1      1   \n",
       "2           2       q2        c2      1   \n",
       "3           3       q3        c3      1   \n",
       "4           4       q4        c4      1   \n",
       "\n",
       "                                                 doc  \\\n",
       "0  Set the text for this element.\\n\\n        Argu...   \n",
       "1  Associate a document with this element.\\n\\n   ...   \n",
       "2  Tests whether a new element of this class can ...   \n",
       "3  This method will be called after an element is...   \n",
       "4  Recompute textual value based on the text cont...   \n",
       "\n",
       "                                                code  \\\n",
       "0  def settext(self, text, cls='current'):\\n     ...   \n",
       "1  def setdocument(self, doc):\\n        \"\"\"Associ...   \n",
       "2  def addable(Class, parent, set=None, raiseexce...   \n",
       "3  def postappend(self):\\n        \"\"\"This method ...   \n",
       "4  def updatetext(self):\\n        \"\"\"Recompute te...   \n",
       "\n",
       "                                        cleaned_code  \\\n",
       "0  \\ndef settext(self, text, cls='current'):\\n\\n ...   \n",
       "1  \\ndef setdocument(self, doc):\\n\\n    assert is...   \n",
       "2  \\ndef addable(Class, parent, set=None, raiseex...   \n",
       "3  \\ndef postappend(self):\\n\\n    if not self.doc...   \n",
       "4  \\ndef updatetext(self):\\n\\n    if self.TEXTCON...   \n",
       "\n",
       "   remove_all_comments_issue  \n",
       "0                      False  \n",
       "1                      False  \n",
       "2                      False  \n",
       "3                      False  \n",
       "4                      False  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
