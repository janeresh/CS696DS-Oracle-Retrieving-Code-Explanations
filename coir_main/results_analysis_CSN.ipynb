{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "from coir.data_loader import get_tasks, load_data_from_hf\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "import html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in tasks \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetched data from hf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f8b7b067b74a74aa0f6093668df8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/280310 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5306e7a5d24244b777da5d15b20e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/280652 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loader init\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59a3bd342de45798a87e9cee037b5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0_deepseek', 'query_id', 'corpus_id', 'doc_deepseek',\n",
       "       'code_deepseek', 'cleaned_code_deepseek', 'explanation_deepseek_1',\n",
       "       'explanation_deepseek_2', 'explanation_deepseek_3',\n",
       "       'explanation_deepseek_4', 'explanation_deepseek_5',\n",
       "       'explanation_deepseek_1_cleaned', 'explanation_deepseek_2_cleaned',\n",
       "       'explanation_deepseek_3_cleaned', 'explanation_deepseek_4_cleaned',\n",
       "       'explanation_deepseek_5_cleaned', 'Unnamed: 0_granite', 'doc_granite',\n",
       "       'code_granite', 'cleaned_code_granite', 'explanation_granite_1',\n",
       "       'explanation_granite_2', 'explanation_granite_3',\n",
       "       'explanation_granite_4', 'explanation_granite_5',\n",
       "       'explanation_granite_1_cleaned', 'explanation_granite_2_cleaned',\n",
       "       'explanation_granite_3_cleaned', 'explanation_granite_4_cleaned',\n",
       "       'explanation_granite_5_cleaned'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csn_train_deepseek_path = \"/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/postprocessing/output/CSN_deepseek_train_clean.csv\"\n",
    "csn_valid_deepseek_path = \"/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/postprocessing/output/CSN_deepseek_valid_clean.csv\"\n",
    "csn_test_deepseek_path = \"/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/postprocessing/output/CSN_deepseek_test_clean.csv\"\n",
    "\n",
    "csn_valid_granite_path = \"/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/postprocessing/output/CSN_granite_train_clean.csv\"\n",
    "csn_train_granite_path = \"/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/postprocessing/output/CSN_granite_valid_clean.csv\"\n",
    "csn_test_granite_path = \"/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/postprocessing/output/CSN_granite_test_clean.csv\"\n",
    "\n",
    "\n",
    "tasks = get_tasks(tasks=[\"CodeSearchNet-python\"])\n",
    "corpus, queries, qrels = tasks[\"CodeSearchNet-python\"]\n",
    "\n",
    "# read them\n",
    "df_train = pd.read_csv(csn_train_deepseek_path)\n",
    "df_valid = pd.read_csv(csn_valid_deepseek_path)\n",
    "df_test  = pd.read_csv(csn_test_deepseek_path)\n",
    "\n",
    "# concatenate into one DataFrame\n",
    "deepseek_df = pd.concat([df_train, df_valid, df_test], ignore_index=True)\n",
    "\n",
    "df_train = pd.read_csv(csn_train_granite_path)\n",
    "df_valid = pd.read_csv(csn_valid_granite_path)\n",
    "df_test  = pd.read_csv(csn_test_granite_path)\n",
    "\n",
    "granite_df = pd.concat([df_train, df_valid, df_test], ignore_index=True)\n",
    "\n",
    "merged_df = pd.merge(\n",
    "    deepseek_df,\n",
    "    granite_df,\n",
    "    on=[\"query_id\", \"corpus_id\"],\n",
    "    how=\"outer\",\n",
    "    suffixes=(\"_deepseek\", \"_granite\")\n",
    ")\n",
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>original_query</th>\n",
       "      <th>mmr_rank</th>\n",
       "      <th>mmr_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>q1</td>\n",
       "      <td>python code to write bool value 1</td>\n",
       "      <td>1</td>\n",
       "      <td>Query:\\npython code to write bool value 1\\n\\nE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>q1</td>\n",
       "      <td>python code to write bool value 1</td>\n",
       "      <td>2</td>\n",
       "      <td>Query:\\npython code to write bool value 1\\n\\nE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>q1</td>\n",
       "      <td>python code to write bool value 1</td>\n",
       "      <td>3</td>\n",
       "      <td>Query:\\npython code to write bool value 1\\n\\nE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>q1</td>\n",
       "      <td>python code to write bool value 1</td>\n",
       "      <td>4</td>\n",
       "      <td>Query:\\npython code to write bool value 1\\n\\nE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>q1</td>\n",
       "      <td>python code to write bool value 1</td>\n",
       "      <td>5</td>\n",
       "      <td>Query:\\npython code to write bool value 1\\n\\nE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id                     original_query  mmr_rank  \\\n",
       "0           0  q1  python code to write bool value 1         1   \n",
       "1           1  q1  python code to write bool value 1         2   \n",
       "2           2  q1  python code to write bool value 1         3   \n",
       "3           3  q1  python code to write bool value 1         4   \n",
       "4           4  q1  python code to write bool value 1         5   \n",
       "\n",
       "                                     mmr_explanation  \n",
       "0  Query:\\npython code to write bool value 1\\n\\nE...  \n",
       "1  Query:\\npython code to write bool value 1\\n\\nE...  \n",
       "2  Query:\\npython code to write bool value 1\\n\\nE...  \n",
       "3  Query:\\npython code to write bool value 1\\n\\nE...  \n",
       "4  Query:\\npython code to write bool value 1\\n\\nE...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Query Expnansion\n",
    "qe_dataset = \"/work/pi_wenlongzhao_umass_edu/27/janet/query_expansion/results/cosqa/cosqa_queries_expanded_granite_temp_0.5_mmr_2.csv\"\n",
    "qe_df = pd.read_csv(qe_dataset)\n",
    "qe_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_good_queries(df, k=10):\n",
    "    \"\"\"\n",
    "    Given a retrieval DataFrame with columns:\n",
    "      [query_id, retrieved_doc_id, score, ground_truth_relevance],\n",
    "    returns a DataFrame with columns [query_id, is_good]\n",
    "    where is_good is True if there's at least 1 relevant doc in top K.\n",
    "    \"\"\"\n",
    "    df_sorted = df.sort_values([\"query_id\", \"score\"], ascending=[True, False])\n",
    "    \n",
    "    def top_k_has_relevant(subdf):\n",
    "        topk = subdf.head(k)\n",
    "        return int((topk[\"ground_truth_relevance\"] == 1).any())\n",
    "\n",
    "    query_good = df_sorted.groupby(\"query_id\").apply(top_k_has_relevant).reset_index()\n",
    "    query_good.columns = [\"query_id\", \"is_good\"]\n",
    "    \n",
    "    return query_good\n",
    "\n",
    "def first_relevant_rank(df):\n",
    "    df_sorted = df.sort_values([\"query_id\", \"score\"], ascending=[True, False])\n",
    "    def get_rank(subdf):\n",
    "        subdf = subdf.reset_index(drop=True)\n",
    "        rel = subdf[subdf[\"ground_truth_relevance\"] == 1]\n",
    "        return rel.index[0] + 1 if not rel.empty else None\n",
    "    rank_df = df_sorted.groupby(\"query_id\").apply(get_rank).reset_index()\n",
    "    rank_df.columns = [\"query_id\", \"first_rel_rank\"]\n",
    "    return rank_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of correct queries between methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD RESULTS FOR METHOD 1\n",
    "dataset_1 = \"csn\"\n",
    "type_1 = \"og\"\n",
    "method_1 = \"baseline\"\n",
    "retrieval_1 = \"dres\"\n",
    "encoder_1 = \"intfloat/e5-base-v2\"\n",
    "\n",
    "if retrieval_1 == \"bm25\":\n",
    "    results_path = f\"/work/pi_wenlongzhao_umass_edu/27/vaishnavisha/CS696DS-Oracle-Retrieving-Code-Explanations/coir-main/results/{dataset_1}/{type_1}/{method_1}/{retrieval_1}/retrieval_evaluation.csv\"\n",
    "else:\n",
    "    results_path = f\"/work/pi_wenlongzhao_umass_edu/27/vaishnavisha/CS696DS-Oracle-Retrieving-Code-Explanations/coir-main/results/{dataset_1}/{type_1}/{method_1}/{retrieval_1}/{encoder_1}/retrieval_evaluation.csv\"\n",
    "\n",
    "first_df = pd.read_csv(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD RESULTS FOR METHOD 2\n",
    "dataset_2 = \"csn\"\n",
    "type_2 = \"og\"\n",
    "method_2 = \"granite1\"\n",
    "retrieval_2 = \"dres\"\n",
    "encoder_2 = \"intfloat/e5-base-v2\"\n",
    "\n",
    "\n",
    "if retrieval_2 == \"bm25\":\n",
    "    results_path = f\"/work/pi_wenlongzhao_umass_edu/27/vaishnavisha/CS696DS-Oracle-Retrieving-Code-Explanations/coir-main/results/{dataset_2}/{type_2}/{method_2}/{retrieval_2}/retrieval_evaluation.csv\"\n",
    "else:\n",
    "    results_path = f\"/work/pi_wenlongzhao_umass_edu/27/vaishnavisha/CS696DS-Oracle-Retrieving-Code-Explanations/coir-main/results/{dataset_2}/{type_2}/{method_2}/{retrieval_2}/{encoder_2}/retrieval_evaluation.csv\"\n",
    "second_df = pd.read_csv(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>is_good_baseline</th>\n",
       "      <th>is_good_granite1</th>\n",
       "      <th>first_rel_rank_baseline</th>\n",
       "      <th>first_rel_rank_granite1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q265734</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q265735</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q265736</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q265737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q265738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id  is_good_baseline  is_good_granite1  first_rel_rank_baseline  \\\n",
       "0  q265734                 1                 1                      1.0   \n",
       "1  q265735                 1                 1                      1.0   \n",
       "2  q265736                 1                 1                      1.0   \n",
       "3  q265737                 0                 0                     15.0   \n",
       "4  q265738                 0                 0                    161.0   \n",
       "\n",
       "   first_rel_rank_granite1  \n",
       "0                      1.0  \n",
       "1                      1.0  \n",
       "2                      1.0  \n",
       "3                     99.0  \n",
       "4                    163.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10 # Hyper-param to select top k documents to classify a \"good\" retrieval\n",
    "first_good = mark_good_queries(first_df, k=k)\n",
    "second_good = mark_good_queries(second_df, k=k)\n",
    "\n",
    "first_ranks = first_relevant_rank(first_df)\n",
    "second_ranks = first_relevant_rank(second_df)\n",
    "\n",
    "compare_df = first_good.merge(second_good, on=\"query_id\", suffixes=(f\"_{method_1}\", f\"_{method_2}\"))\n",
    "compare_df = compare_df.merge(first_ranks, on=\"query_id\")\n",
    "compare_df = compare_df.merge(second_ranks, on=\"query_id\", suffixes=(f\"_{method_1}\", f\"_{method_2}\"))\n",
    "\n",
    "compare_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries where baseline is good, but granite1 is bad:\n",
      "      query_id  is_good_baseline  is_good_granite1  first_rel_rank_baseline  \\\n",
      "16     q265750                 1                 0                      6.0   \n",
      "28     q265762                 1                 0                      4.0   \n",
      "40     q265774                 1                 0                      1.0   \n",
      "41     q265775                 1                 0                      1.0   \n",
      "52     q265786                 1                 0                      3.0   \n",
      "...        ...               ...               ...                      ...   \n",
      "14881  q280615                 1                 0                      3.0   \n",
      "14883  q280617                 1                 0                      4.0   \n",
      "14885  q280619                 1                 0                      1.0   \n",
      "14901  q280635                 1                 0                      7.0   \n",
      "14912  q280646                 1                 0                      1.0   \n",
      "\n",
      "       first_rel_rank_granite1  \\\n",
      "16                        18.0   \n",
      "28                        39.0   \n",
      "40                        20.0   \n",
      "41                        21.0   \n",
      "52                        16.0   \n",
      "...                        ...   \n",
      "14881                      NaN   \n",
      "14883                     17.0   \n",
      "14885                     11.0   \n",
      "14901                     60.0   \n",
      "14912                     11.0   \n",
      "\n",
      "                                              query_text  \n",
      "16     Scans through a string for substrings matched ...  \n",
      "28     returns aws_access_key_id, aws_secret_access_k...  \n",
      "40     Creates a new Cloud SQL instance.\\n\\n        :...  \n",
      "41     Updates settings of a Cloud SQL instance.\\n\\n ...  \n",
      "52     Retrieves the dynamically created connection f...  \n",
      "...                                                  ...  \n",
      "14881  Write a summary report to `file`.\\n\\n        E...  \n",
      "14883  Generate an HTML report.\\n\\n        The HTML i...  \n",
      "14885  Display a Python object in all frontends.\\n\\n ...  \n",
      "14901          Start the app for the engines subcommand.  \n",
      "14912  Write text at x, y top left corner position.\\n...  \n",
      "\n",
      "[1277 rows x 6 columns]\n",
      "Queries where granite1 is good, but baseline is bad:\n",
      "      query_id  is_good_baseline  is_good_granite1  first_rel_rank_baseline  \\\n",
      "24     q265758                 0                 1                     69.0   \n",
      "59     q265793                 0                 1                     25.0   \n",
      "121    q265855                 0                 1                    109.0   \n",
      "125    q265859                 0                 1                     18.0   \n",
      "142    q265876                 0                 1                     12.0   \n",
      "...        ...               ...               ...                      ...   \n",
      "14790  q280524                 0                 1                     85.0   \n",
      "14791  q280525                 0                 1                     44.0   \n",
      "14862  q280596                 0                 1                     25.0   \n",
      "14870  q280604                 0                 1                    674.0   \n",
      "14871  q280605                 0                 1                    180.0   \n",
      "\n",
      "       first_rel_rank_granite1  \\\n",
      "24                         4.0   \n",
      "59                         2.0   \n",
      "121                        4.0   \n",
      "125                        8.0   \n",
      "142                        5.0   \n",
      "...                        ...   \n",
      "14790                      6.0   \n",
      "14791                      2.0   \n",
      "14862                      1.0   \n",
      "14870                      1.0   \n",
      "14871                      9.0   \n",
      "\n",
      "                                              query_text  \n",
      "24     int, int, int->None\\n    \\n    Download ONE PA...  \n",
      "59                 Extract error code from ftp exception  \n",
      "121    Update this with a new set of paths to DAG def...  \n",
      "125    Opens a ssh connection to the remote host.\\n\\n...  \n",
      "142    Commit a transaction, optionally creating, del...  \n",
      "...                                                  ...  \n",
      "14790  decompose a TaskRecord dict into subsection of...  \n",
      "14791              Get the result of 1 or more messages.  \n",
      "14862  check a result dict for errors, and raise Comp...  \n",
      "14870  Update the source_match matcher with latest im...  \n",
      "14871  Start measuring code coverage.\\n\\n        Cove...  \n",
      "\n",
      "[782 rows x 6 columns]\n",
      "Queries both missed:\n",
      "      query_id  is_good_baseline  is_good_granite1  first_rel_rank_baseline  \\\n",
      "3      q265737                 0                 0                     15.0   \n",
      "4      q265738                 0                 0                    161.0   \n",
      "5      q265739                 0                 0                    295.0   \n",
      "6      q265740                 0                 0                    304.0   \n",
      "8      q265742                 0                 0                      NaN   \n",
      "...        ...               ...               ...                      ...   \n",
      "14878  q280612                 0                 0                    216.0   \n",
      "14894  q280628                 0                 0                     18.0   \n",
      "14895  q280629                 0                 0                     17.0   \n",
      "14899  q280633                 0                 0                    569.0   \n",
      "14902  q280636                 0                 0                    701.0   \n",
      "\n",
      "       first_rel_rank_granite1  \\\n",
      "3                         99.0   \n",
      "4                        163.0   \n",
      "5                        952.0   \n",
      "6                        421.0   \n",
      "8                          NaN   \n",
      "...                        ...   \n",
      "14878                     16.0   \n",
      "14894                     74.0   \n",
      "14895                    351.0   \n",
      "14899                    760.0   \n",
      "14902                      NaN   \n",
      "\n",
      "                                              query_text  \n",
      "3      Format text with color or other effects into A...  \n",
      "4                 Print a log message to standard error.  \n",
      "5                            Print an error log message.  \n",
      "6                               What a Terrible Failure!  \n",
      "8                                              str->None  \n",
      "...                                                  ...  \n",
      "14878  Like `analysis2` but doesn't return excluded l...  \n",
      "14894       Find the full path to a command using which.  \n",
      "14895  Execute a command in a subshell.\\n\\n        Pa...  \n",
      "14899             Start the app for the stop subcommand.  \n",
      "14902            Start the app for the start subcommand.  \n",
      "\n",
      "[2804 rows x 6 columns]\n",
      "Queries both got:\n",
      "      query_id  is_good_baseline  is_good_granite1  first_rel_rank_baseline  \\\n",
      "0      q265734                 1                 1                      1.0   \n",
      "1      q265735                 1                 1                      1.0   \n",
      "2      q265736                 1                 1                      1.0   \n",
      "7      q265741                 1                 1                      1.0   \n",
      "9      q265743                 1                 1                      1.0   \n",
      "...        ...               ...               ...                      ...   \n",
      "14913  q280647                 1                 1                      1.0   \n",
      "14914  q280648                 1                 1                      2.0   \n",
      "14915  q280649                 1                 1                      1.0   \n",
      "14916  q280650                 1                 1                      2.0   \n",
      "14917  q280651                 1                 1                      5.0   \n",
      "\n",
      "       first_rel_rank_granite1  \\\n",
      "0                          1.0   \n",
      "1                          1.0   \n",
      "2                          1.0   \n",
      "7                          2.0   \n",
      "9                          1.0   \n",
      "...                        ...   \n",
      "14913                      1.0   \n",
      "14914                      2.0   \n",
      "14915                      5.0   \n",
      "14916                      2.0   \n",
      "14917                      7.0   \n",
      "\n",
      "                                              query_text  \n",
      "0      str->list\\n    Convert XML to URL List.\\n    F...  \n",
      "1                   Downloads Dailymotion videos by URL.  \n",
      "2                          Downloads Sina videos by URL.  \n",
      "7                               Detect operating system.  \n",
      "9      str->dict\\n    Information for CKPlayer API co...  \n",
      "...                                                  ...  \n",
      "14913  Return a canvas from a grayscale image.\\n\\n   ...  \n",
      "14914  Returns a unique ID of a given length.\\n    Us...  \n",
      "14915                   Build a unique key from get data  \n",
      "14916               Returns domain name portion of a URL  \n",
      "14917             Returns a dictionary from a URL params  \n",
      "\n",
      "[10055 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "compare_df[\"query_text\"] = compare_df[\"query_id\"].map(queries)\n",
    "\n",
    "bad_method_1 = compare_df[\n",
    "    (compare_df[f\"is_good_{method_1}\"] == 1) &\n",
    "    (compare_df[f\"is_good_{method_2}\"] == 0)\n",
    "]\n",
    "print(f\"Queries where {method_1} is good, but {method_2} is bad:\")\n",
    "print(bad_method_1)\n",
    "\n",
    "bad_method_2 = compare_df[\n",
    "    (compare_df[f\"is_good_{method_1}\"] == 0) &\n",
    "    (compare_df[f\"is_good_{method_2}\"] == 1)\n",
    "]\n",
    "print(f\"Queries where {method_2} is good, but {method_1} is bad:\")\n",
    "print(bad_method_2)\n",
    "\n",
    "# Queries both missed\n",
    "both_missed = compare_df[\n",
    "    (compare_df[f\"is_good_{method_1}\"] == 0) &\n",
    "    (compare_df[f\"is_good_{method_2}\"] == 0)\n",
    "]\n",
    "print(\"Queries both missed:\")\n",
    "print(both_missed)\n",
    "\n",
    "# Queries both got\n",
    "both_got = compare_df[\n",
    "    (compare_df[f\"is_good_{method_1}\"] == 1) &\n",
    "    (compare_df[f\"is_good_{method_2}\"] == 1)\n",
    "]\n",
    "print(\"Queries both got:\")\n",
    "print(both_got)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total queries: 14918\n",
      "Baseline good queries: 11332\n",
      "Baseline bad queries: 3586\n",
      "Granite1 good queries: 10837\n",
      "Granite1 bad queries: 4081\n",
      "\n",
      "Baseline good but Granite1 bad queries count: 1277\n",
      "\n",
      "Granite1 good but Baseline bad queries count: 782\n",
      "\n",
      "Queries both missed: 2804\n",
      "\n",
      "Queries both got: 10055\n"
     ]
    }
   ],
   "source": [
    "good_method_1_count = compare_df[f\"is_good_{method_1}\"].sum()\n",
    "good_method_2_count = compare_df[f\"is_good_{method_2}\"].sum()\n",
    "bad_method_1_count = len(compare_df) - good_method_1_count\n",
    "bad_method_2_count = len(compare_df) - good_method_2_count\n",
    "\n",
    "print(\"Total queries:\", len(compare_df))\n",
    "print(f\"{method_1.capitalize()} good queries:\", good_method_1_count)\n",
    "print(f\"{method_1.capitalize()} bad queries:\", bad_method_1_count)\n",
    "print(f\"{method_2.capitalize()} good queries:\", good_method_2_count)\n",
    "print(f\"{method_2.capitalize()} bad queries:\", bad_method_2_count)\n",
    "\n",
    "\n",
    "# Queries where method_1 is good but method_2 is bad\n",
    "bad_method_2_subset = compare_df[\n",
    "    (compare_df[f\"is_good_{method_1}\"] == 1) &\n",
    "    (compare_df[f\"is_good_{method_2}\"] == 0)\n",
    "]\n",
    "avg_rank_bad_method_2 = bad_method_2_subset[f\"first_rel_rank_{method_2}\"].mean()\n",
    "print(f\"\\n{method_1.capitalize()} good but {method_2.capitalize()} bad queries count:\", len(bad_method_2_subset))\n",
    "#print(f\"Average first relevant doc rank ({method_2.capitalize()}) for these queries:\", avg_rank_bad_method_2)\n",
    "\n",
    "# Queries where method_2 is good but method_1 is bad\n",
    "bad_method_1_subset = compare_df[\n",
    "    (compare_df[f\"is_good_{method_1}\"] == 0) &\n",
    "    (compare_df[f\"is_good_{method_2}\"] == 1)\n",
    "]\n",
    "avg_rank_bad_method_1 = bad_method_1_subset[f\"first_rel_rank_{method_1}\"].mean()\n",
    "print(f\"\\n{method_2.capitalize()} good but {method_1.capitalize()} bad queries count:\", len(bad_method_1_subset))\n",
    "#print(f\"Average first relevant doc rank ({method_1.capitalize()}) for these queries:\", avg_rank_bad_method_1)\n",
    "\n",
    "# Queries both missed\n",
    "print(f\"\\nQueries both missed: {len(both_missed)}\")\n",
    "\n",
    "# Queries both got\n",
    "avg_rank_method_1_both = both_got[f\"first_rel_rank_{method_1}\"].mean()\n",
    "avg_rank_method_2_both = both_got[f\"first_rel_rank_{method_2}\"].mean()\n",
    "print(f\"\\nQueries both got: {len(both_got)}\")\n",
    "#print(f\"Average first relevant doc rank ({method_1.capitalize()}) for these queries:\", avg_rank_method_1_both)\n",
    "#print(f\"Average first relevant doc rank ({method_2.capitalize()}) for these queries:\", avg_rank_method_2_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_group_table(df, title):\n",
    "    display_df = df[[\"query_id\", \"query_text\"]].copy()\n",
    "    html = f\"<h3>{title} (n={len(display_df)})</h3>\"\n",
    "    html += display_df.to_html(index=False, escape=False)\n",
    "    return html\n",
    "\n",
    "html_out = \"\"\n",
    "html_out += make_group_table(bad_method_1, f\"Queries where {method_1} is good, but {method_2} is bad\")\n",
    "html_out += make_group_table(bad_method_2, f\"Queries where {method_2} is good, but {method_1} is bad\")\n",
    "html_out += make_group_table(both_missed, \"Queries both missed\")\n",
    "html_out += make_group_table(both_got, \"Queries both got\")\n",
    "\n",
    "#display(HTML(html_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_method_1_merge = pd.merge(bad_method_1, merged_df, on=\"query_id\", how=\"left\")\n",
    "bad_method_2_merge = pd.merge(bad_method_2, merged_df, on=\"query_id\", how=\"left\")\n",
    "both_missed_merge = pd.merge(both_missed, merged_df, on=\"query_id\", how=\"left\")\n",
    "both_got_merge = pd.merge(both_got, merged_df, on=\"query_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available columns for explanations and code.\n",
    "for df in (merged_df, bad_method_1_merge, bad_method_2_merge, both_missed_merge, both_got_merge):\n",
    "    # create a new 'code' column that’s a copy of 'code_deepseek'\n",
    "    df['code'] = df['cleaned_code_deepseek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Queries where baseline is good, but granite1 is bad\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3a8240ca584667b02b91a2825a02f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='page', max=256, min=1), Dropdown(description='Code', opt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Queries where granite1 is good, but baseline is bad\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4491b9e5314185a30de90d3e0f2536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='page', max=157, min=1), Dropdown(description='Code', opt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Queries both missed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77adf4bfd8d84ea6a77bf3a00bd41b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='page', max=561, min=1), Dropdown(description='Code', opt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Queries both got\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d8ba6580304379b4e79bb828997f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='page', max=2012, min=1), Dropdown(description='Code', op…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(page, code, expl)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "available_explanation_columns = [\n",
    "'explanation_granite_1_cleaned', 'explanation_granite_2_cleaned',\n",
    "'explanation_granite_3_cleaned', 'explanation_granite_4_cleaned',\n",
    "'explanation_granite_5_cleaned',\n",
    "\"explanation_deepseek_1_cleaned\", \"explanation_deepseek_2_cleaned\", \n",
    "\"explanation_deepseek_3_cleaned\", \"explanation_deepseek_4_cleaned\", \n",
    "\"explanation_deepseek_5_cleaned\"\n",
    "]\n",
    "\n",
    "available_code_columns = [\n",
    "    \"code\",\n",
    "    \"cleaned_code_deepseek\",\n",
    "    \"explanation_deepseek_1_cleaned\", \"explanation_deepseek_2_cleaned\", \n",
    "    \"explanation_deepseek_3_cleaned\", \"explanation_deepseek_4_cleaned\", \n",
    "    \"explanation_deepseek_5_cleaned\"\n",
    "]\n",
    "\n",
    "def make_html_block(text):\n",
    "    \"\"\"Wrap the given text in a <div> that preserves whitespace and left-aligns the text.\"\"\"\n",
    "    return f\"<div style='white-space: pre-wrap; text-align: left; font-family: monospace;'>{text}</div>\"\n",
    "\n",
    "def show_page(df, code_col, expl_col, page=1, page_size=5):\n",
    "    \"\"\"\n",
    "    Display a subset of rows from the DataFrame using the selected\n",
    "    code column (for code) and explanation column (for explanation).\n",
    "    The resulting table will have headers that exactly match the dropdown selections.\n",
    "    \"\"\"\n",
    "    # Select the desired columns; keep original names.\n",
    "    display_df = df[[\"query_id\", \"query_text\", code_col, expl_col]].copy()\n",
    "    \n",
    "    # Apply HTML formatting to the code column.\n",
    "    display_df[code_col] = display_df[code_col].apply(make_html_block)\n",
    "    \n",
    "    # Paginate.\n",
    "    start = (page - 1) * page_size\n",
    "    end = start + page_size\n",
    "    sub_df = display_df.iloc[start:end]\n",
    "    \n",
    "    # Use the Styler to render HTML.\n",
    "    styled = sub_df.style.format({code_col: lambda s: s})\n",
    "    styled = styled.set_table_styles([\n",
    "    {'selector': 'th', \n",
    "        'props': [('border', '1px solid black'),\n",
    "                ('padding', '5px'),\n",
    "                ('background-color', '#f0f0f0')]},\n",
    "    {'selector': 'td', \n",
    "        'props': [('border', '1px solid black'),\n",
    "                ('padding', '5px')]},\n",
    "    # This applies alternating background colors to rows.\n",
    "    {'selector': 'tr:nth-child(even)', \n",
    "        'props': [('background-color', '#f9f9f9')]}\n",
    "])\n",
    "    html = styled.to_html()\n",
    "    display(HTML(html))\n",
    "\n",
    "# Example interactive calls:\n",
    "# (Replace the DataFrame variables below with your actual DataFrames,\n",
    "# e.g. bad_method_1_merge, bad_method_2_merge, both_missed_merge, both_got_merge.)\n",
    "print(f\"Group: Queries where {method_1} is good, but {method_2} is bad\")\n",
    "widgets.interact(lambda page, code, expl: show_page(bad_method_1_merge, code, expl, page=page),\n",
    "                 page=widgets.IntSlider(min=1, max=(len(bad_method_2_subset) // 5) + 1, step=1, value=1),\n",
    "                 code=widgets.Dropdown(options=available_code_columns, value=available_code_columns[0], description=\"Code\"),\n",
    "                 expl=widgets.Dropdown(options=available_explanation_columns, value=available_explanation_columns[0], description=\"Explanation\"))\n",
    "\n",
    "print(f\"Group: Queries where {method_2} is good, but {method_1} is bad\")\n",
    "widgets.interact(lambda page, code, expl: show_page(bad_method_2_merge, code, expl, page=page),\n",
    "                 page=widgets.IntSlider(min=1, max=(len(bad_method_1_subset) // 5) + 1, step=1, value=1),\n",
    "                 code=widgets.Dropdown(options=available_code_columns, value=available_code_columns[0], description=\"Code\"),\n",
    "                 expl=widgets.Dropdown(options=available_explanation_columns, value=available_explanation_columns[0], description=\"Explanation\"))\n",
    "\n",
    "print(\"Group: Queries both missed\")\n",
    "widgets.interact(lambda page, code, expl: show_page(both_missed_merge, code, expl, page=page),\n",
    "                 page=widgets.IntSlider(min=1, max=(len(both_missed) // 5) + 1, step=1, value=1),\n",
    "                 code=widgets.Dropdown(options=available_code_columns, value=available_code_columns[0], description=\"Code\"),\n",
    "                 expl=widgets.Dropdown(options=available_explanation_columns, value=available_explanation_columns[0], description=\"Explanation\"))\n",
    "\n",
    "print(\"Group: Queries both got\")\n",
    "widgets.interact(lambda page, code, expl: show_page(both_got_merge, code, expl, page=page),\n",
    "                 page=widgets.IntSlider(min=1, max=(len(both_got) // 5) + 1, step=1, value=1),\n",
    "                 code=widgets.Dropdown(options=available_code_columns, value=available_code_columns[0], description=\"Code\"),\n",
    "                 expl=widgets.Dropdown(options=available_explanation_columns, value=available_explanation_columns[0], description=\"Explanation\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_disp_df1 = first_df.merge(\n",
    "    merged_df,\n",
    "    left_on=['retrieved_doc_id'],\n",
    "    right_on=['corpus_id'],\n",
    "    how='left'\n",
    ")\n",
    "query_disp_df2 = second_df.merge(\n",
    "    merged_df,\n",
    "    left_on=['retrieved_doc_id'],\n",
    "    right_on=['corpus_id'],\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METHOD 1 QUERY FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  table.dataframe {\n",
       "    border-collapse: collapse;           /* collapse cell borders into single lines */\n",
       "  }\n",
       "  table.dataframe th,\n",
       "  table.dataframe td {\n",
       "    border: 1px solid #999;              /* 1px border around every cell */\n",
       "    padding: 4px 8px;                    /* consistent padding */\n",
       "    white-space: normal !important;      /* wrap long text */\n",
       "    max-width: 250px;                    /* cap width */\n",
       "    overflow-wrap: break-word;\n",
       "    vertical-align: top;\n",
       "  }\n",
       "  /* monospace font & pre-wrap only for code cell content */\n",
       "  table.dataframe td.code-cell div {\n",
       "    font-family: monospace;\n",
       "    white-space: pre-wrap;\n",
       "  }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9585314828784ffabcb56579bf920d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='', description='Query ID:', placeholder='e.g. q20105'), Button(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── 1) Prevent pandas from truncating long text ─\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# ── 2) Inject CSS for borders, wrapping, and monospace code ─\n",
    "display(HTML('''\n",
    "<style>\n",
    "  table.dataframe {\n",
    "    border-collapse: collapse;           /* collapse cell borders into single lines */\n",
    "  }\n",
    "  table.dataframe th,\n",
    "  table.dataframe td {\n",
    "    border: 1px solid #999;              /* 1px border around every cell */\n",
    "    padding: 4px 8px;                    /* consistent padding */\n",
    "    white-space: normal !important;      /* wrap long text */\n",
    "    max-width: 250px;                    /* cap width */\n",
    "    overflow-wrap: break-word;\n",
    "    vertical-align: top;\n",
    "  }\n",
    "  /* monospace font & pre-wrap only for code cell content */\n",
    "  table.dataframe td.code-cell div {\n",
    "    font-family: monospace;\n",
    "    white-space: pre-wrap;\n",
    "  }\n",
    "</style>\n",
    "'''))\n",
    "\n",
    "# ── helper to wrap code in a <div> for monospace & pre-wrap ─\n",
    "def make_html_block(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    return f\"<div style='white-space: pre-wrap; font-family: monospace;'>{text}</div>\"\n",
    "\n",
    "# ── 3) Columns you actually want to see ─\n",
    "display_cols = [\n",
    "    'retrieved_doc_id',\n",
    "    'score',\n",
    "    'ground_truth_relevance',\n",
    "    'code',\n",
    "    'explanation_granite_1_cleaned',\n",
    "]\n",
    "\n",
    "# ── 4) Build the widgets ─\n",
    "qid_text     = widgets.Text(description='Query ID:', placeholder='e.g. q20105')\n",
    "show_btn     = widgets.Button(description='Show')\n",
    "page_slider  = widgets.IntSlider(value=1, min=1, max=1, step=1,\n",
    "                                 description='Page:', continuous_update=False)\n",
    "out          = widgets.Output()\n",
    "\n",
    "# ── 5) App state and settings ─\n",
    "state     = { 'df': pd.DataFrame(), 'query_text': '' }\n",
    "PAGE_SIZE = 10\n",
    "\n",
    "def refresh(page_num):\n",
    "    \"\"\"Show page `page_num` (1-based) in the `out` widget only.\"\"\"\n",
    "    out.clear_output(wait=True)\n",
    "    df = state['df']\n",
    "    if df.empty:\n",
    "        with out:\n",
    "            print(\"No results for that query.\")\n",
    "        return\n",
    "\n",
    "    # Show the searched query above the table\n",
    "    with out:\n",
    "        display(HTML(f\"<div style='font-weight:bold; margin-bottom:8px;'>🔍 Query: {state['query_text']}</div>\"))\n",
    "\n",
    "    start = (page_num - 1) * PAGE_SIZE\n",
    "    end   = start + PAGE_SIZE\n",
    "    total = len(df)\n",
    "\n",
    "    # slice rows & columns, then format the code column\n",
    "    sub = df.iloc[start:end][display_cols].copy()\n",
    "    sub['code'] = sub['code'].apply(make_html_block)\n",
    "\n",
    "    styled = (\n",
    "        sub\n",
    "        .style\n",
    "        .set_td_classes(pd.DataFrame(\n",
    "            [['code-cell' if col=='code' else '' for col in sub.columns]]\n",
    "            * len(sub),\n",
    "            columns=sub.columns\n",
    "        ))\n",
    "    )\n",
    "\n",
    "    html = styled.to_html(escape=False)\n",
    "    with out:\n",
    "        display(HTML(html))\n",
    "        print(f\"Showing {start+1}–{min(end, total)} of {total}\")\n",
    "\n",
    "def on_show_clicked(_):\n",
    "    qid = qid_text.value.strip()\n",
    "    df_q = (\n",
    "        query_disp_df1\n",
    "        .query(\"query_id_x == @qid\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    # create 'code' alias from 'code_deepseek'\n",
    "    if not df_q.empty and 'code_deepseek' in df_q.columns:\n",
    "        df_q['code'] = df_q['code_deepseek']\n",
    "    else:\n",
    "        df_q['code'] = \"\"\n",
    "\n",
    "    state['df'] = df_q\n",
    "    # store actual query text\n",
    "    state['query_text'] = df_q.loc[df_q['query_id_y'] == qid, 'doc_deepseek'].iloc[0] if not df_q.empty and 'doc_deepseek' in df_q.columns else ''\n",
    "\n",
    "    # configure slider for how many pages we need\n",
    "    n_pages = math.ceil(len(df_q) / PAGE_SIZE) if not df_q.empty else 1\n",
    "    page_slider.max   = max(1, n_pages)\n",
    "    page_slider.value = 1\n",
    "\n",
    "    refresh(1)\n",
    "\n",
    "def on_page_changed(change):\n",
    "    if change['name']=='value' and change['new']!=change['old']:\n",
    "        refresh(change['new'])\n",
    "\n",
    "# ── 6) Wire up callbacks ─\n",
    "show_btn.on_click(on_show_clicked)\n",
    "page_slider.observe(on_page_changed, names='value')\n",
    "\n",
    "# ── 7) Layout & display the UI once ─\n",
    "ui = widgets.VBox([\n",
    "    widgets.HBox([qid_text, show_btn]),\n",
    "    page_slider,\n",
    "    out\n",
    "])\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METHOD 2 QUERY FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  table.dataframe {\n",
       "    border-collapse: collapse;           /* collapse cell borders into single lines */\n",
       "  }\n",
       "  table.dataframe th,\n",
       "  table.dataframe td {\n",
       "    border: 1px solid #999;              /* 1px border around every cell */\n",
       "    padding: 4px 8px;                    /* consistent padding */\n",
       "    white-space: normal !important;      /* wrap long text */\n",
       "    max-width: 250px;                    /* cap width */\n",
       "    overflow-wrap: break-word;\n",
       "    vertical-align: top;\n",
       "  }\n",
       "  /* monospace font & pre-wrap only for code cell content */\n",
       "  table.dataframe td.code-cell div {\n",
       "    font-family: monospace;\n",
       "    white-space: pre-wrap;\n",
       "  }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39dbac49e3e49919995cc34469772d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='', description='Query ID:', placeholder='e.g. q20105'), Button(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── 1) Prevent pandas from truncating long text ─\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# ── 2) Inject CSS for borders, wrapping, and monospace code ─\n",
    "display(HTML('''\n",
    "<style>\n",
    "  table.dataframe {\n",
    "    border-collapse: collapse;           /* collapse cell borders into single lines */\n",
    "  }\n",
    "  table.dataframe th,\n",
    "  table.dataframe td {\n",
    "    border: 1px solid #999;              /* 1px border around every cell */\n",
    "    padding: 4px 8px;                    /* consistent padding */\n",
    "    white-space: normal !important;      /* wrap long text */\n",
    "    max-width: 250px;                    /* cap width */\n",
    "    overflow-wrap: break-word;\n",
    "    vertical-align: top;\n",
    "  }\n",
    "  /* monospace font & pre-wrap only for code cell content */\n",
    "  table.dataframe td.code-cell div {\n",
    "    font-family: monospace;\n",
    "    white-space: pre-wrap;\n",
    "  }\n",
    "</style>\n",
    "'''))\n",
    "\n",
    "# ── helper to wrap code in a <div> for monospace & pre-wrap ─\n",
    "def make_html_block(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    return f\"<div style='white-space: pre-wrap; font-family: monospace;'>{text}</div>\"\n",
    "\n",
    "# ── 3) Columns you actually want to see ─\n",
    "display_cols = [\n",
    "    'retrieved_doc_id',\n",
    "    'score',\n",
    "    'ground_truth_relevance',\n",
    "    'code',\n",
    "    'explanation_granite_1_cleaned',\n",
    "]\n",
    "\n",
    "# ── 4) Build the widgets ─\n",
    "qid_text     = widgets.Text(description='Query ID:', placeholder='e.g. q20105')\n",
    "show_btn     = widgets.Button(description='Show')\n",
    "page_slider  = widgets.IntSlider(value=1, min=1, max=1, step=1,\n",
    "                                 description='Page:', continuous_update=False)\n",
    "out          = widgets.Output()\n",
    "\n",
    "# ── 5) App state and settings ─\n",
    "state     = { 'df': pd.DataFrame(), 'query_text': '' }\n",
    "PAGE_SIZE = 10\n",
    "\n",
    "def refresh(page_num):\n",
    "    \"\"\"Show page `page_num` (1-based) in the `out` widget only.\"\"\"\n",
    "    out.clear_output(wait=True)\n",
    "    df = state['df']\n",
    "    if df.empty:\n",
    "        with out:\n",
    "            print(\"No results for that query.\")\n",
    "        return\n",
    "\n",
    "    # Show the searched query above the table\n",
    "    with out:\n",
    "        display(HTML(f\"<div style='font-weight:bold; margin-bottom:8px;'>🔍 Query: {state['query_text']}</div>\"))\n",
    "\n",
    "    start = (page_num - 1) * PAGE_SIZE\n",
    "    end   = start + PAGE_SIZE\n",
    "    total = len(df)\n",
    "\n",
    "    # slice rows & columns, then format the code column\n",
    "    sub = df.iloc[start:end][display_cols].copy()\n",
    "    sub['code'] = sub['code'].apply(make_html_block)\n",
    "\n",
    "    styled = (\n",
    "        sub\n",
    "        .style\n",
    "        .set_td_classes(pd.DataFrame(\n",
    "            [['code-cell' if col=='code' else '' for col in sub.columns]]\n",
    "            * len(sub),\n",
    "            columns=sub.columns\n",
    "        ))\n",
    "    )\n",
    "\n",
    "    html = styled.to_html(escape=False)\n",
    "    with out:\n",
    "        display(HTML(html))\n",
    "        print(f\"Showing {start+1}–{min(end, total)} of {total}\")\n",
    "\n",
    "def on_show_clicked(_):\n",
    "    qid = qid_text.value.strip()\n",
    "    df_q = (\n",
    "        query_disp_df2\n",
    "        .query(\"query_id_x == @qid\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    # create 'code' alias from 'code_deepseek'\n",
    "    if not df_q.empty and 'code_deepseek' in df_q.columns:\n",
    "        df_q['code'] = df_q['code_deepseek']\n",
    "    else:\n",
    "        df_q['code'] = \"\"\n",
    "\n",
    "    state['df'] = df_q\n",
    "    # store actual query text\n",
    "    state['query_text'] = df_q.loc[df_q['query_id_y'] == qid, 'doc_deepseek'].iloc[0] if not df_q.empty and 'doc_deepseek' in df_q.columns else ''\n",
    "\n",
    "    # configure slider for how many pages we need\n",
    "    n_pages = math.ceil(len(df_q) / PAGE_SIZE) if not df_q.empty else 1\n",
    "    page_slider.max   = max(1, n_pages)\n",
    "    page_slider.value = 1\n",
    "\n",
    "    refresh(1)\n",
    "\n",
    "def on_page_changed(change):\n",
    "    if change['name']=='value' and change['new']!=change['old']:\n",
    "        refresh(change['new'])\n",
    "\n",
    "# ── 6) Wire up callbacks ─\n",
    "show_btn.on_click(on_show_clicked)\n",
    "page_slider.observe(on_page_changed, names='value')\n",
    "\n",
    "# ── 7) Layout & display the UI once ─\n",
    "ui = widgets.VBox([\n",
    "    widgets.HBox([qid_text, show_btn]),\n",
    "    page_slider,\n",
    "    out\n",
    "])\n",
    "display(ui)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
