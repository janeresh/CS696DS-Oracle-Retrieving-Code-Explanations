{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "from coir.data_loader import get_tasks, load_data_from_hf\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "import html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6613d34d6246628cd0c42acfda2be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cosqa_deepseek_path='/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/Cosqa/postprocessing/output/COSQA_deepseek_explanations_clean.csv'\n",
    "cosqa_granite_path = '/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/Cosqa/postprocessing/output/COSQA_granite_explanations_clean.csv'\n",
    "\n",
    "tasks = get_tasks(tasks=[\"cosqa\"])\n",
    "corpus, queries, qrels = tasks['cosqa']\n",
    "deepseek_df = pd.read_csv(cosqa_deepseek_path)\n",
    "granite_df = pd.read_csv(cosqa_granite_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(\n",
    "    deepseek_df,\n",
    "    granite_df,\n",
    "    on=[\"query_id\", \"corpus_id\"],\n",
    "    how=\"outer\",\n",
    "    suffixes=(\"_deepseek\", \"_granite\")\n",
    ")\n",
    "# merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_good_queries(df, k=10):\n",
    "    \"\"\"\n",
    "    Given a retrieval DataFrame with columns:\n",
    "      [query_id, retrieved_doc_id, score, ground_truth_relevance],\n",
    "    returns a DataFrame with columns [query_id, is_good]\n",
    "    where is_good is True if there's at least 1 relevant doc in top K.\n",
    "    \"\"\"\n",
    "    df_sorted = df.sort_values([\"query_id\", \"score\"], ascending=[True, False])\n",
    "    \n",
    "    def top_k_has_relevant(subdf):\n",
    "        topk = subdf.head(k)\n",
    "        return int((topk[\"ground_truth_relevance\"] == 1).any())\n",
    "\n",
    "    query_good = df_sorted.groupby(\"query_id\").apply(top_k_has_relevant).reset_index()\n",
    "    query_good.columns = [\"query_id\", \"is_good\"]\n",
    "    \n",
    "    return query_good\n",
    "\n",
    "def first_relevant_rank(df):\n",
    "    df_sorted = df.sort_values([\"query_id\", \"score\"], ascending=[True, False])\n",
    "    def get_rank(subdf):\n",
    "        subdf = subdf.reset_index(drop=True)\n",
    "        rel = subdf[subdf[\"ground_truth_relevance\"] == 1]\n",
    "        return rel.index[0] + 1 if not rel.empty else None\n",
    "    rank_df = df_sorted.groupby(\"query_id\").apply(get_rank).reset_index()\n",
    "    rank_df.columns = [\"query_id\", \"first_rel_rank\"]\n",
    "    return rank_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of correct queries between methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD RESULTS FOR METHOD 1\n",
    "dataset_1 = \"cosqa\"\n",
    "method_1 = \"baseline\"\n",
    "retrieval_1 = \"dres\"\n",
    "encoder_1 = \"BAAI_bge-base-en\"\n",
    "\n",
    "if retrieval_1 == \"bm25\":\n",
    "    results_path = f\"/work/pi_wenlongzhao_umass_edu/27/vaishnavisha/CS696DS-Oracle-Retrieving-Code-Explanations/coir-main/results/{dataset_1}/{method_1}/{retrieval_1}/retrieval_evaluation.csv\"\n",
    "else:\n",
    "    results_path = f\"/work/pi_wenlongzhao_umass_edu/27/vaishnavisha/CS696DS-Oracle-Retrieving-Code-Explanations/coir-main/results/{dataset_1}/{method_1}/{retrieval_1}/{encoder_1}/retrieval_evaluation.csv\"\n",
    "\n",
    "first_df = pd.read_csv(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD RESULTS FOR METHOD 2\n",
    "dataset_2 = \"cosqa\"\n",
    "method_2 = \"granite1\"\n",
    "retrieval_2 = \"dres\"\n",
    "encoder_2 = \"intfloat_e5-base-v2\"\n",
    "\n",
    "if retrieval_2 == \"bm25\":\n",
    "    results_path = f\"/work/pi_wenlongzhao_umass_edu/27/vaishnavisha/CS696DS-Oracle-Retrieving-Code-Explanations/coir-main/results/{dataset_2}/{method_2}/{retrieval_2}/retrieval_evaluation.csv\"\n",
    "else:\n",
    "    results_path = f\"/work/pi_wenlongzhao_umass_edu/27/vaishnavisha/CS696DS-Oracle-Retrieving-Code-Explanations/coir-main/results/{dataset_2}/{method_2}/{retrieval_2}/{encoder_2}/retrieval_evaluation.csv\"\n",
    "second_df = pd.read_csv(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>is_good_baseline</th>\n",
       "      <th>is_good_granite1</th>\n",
       "      <th>first_rel_rank_baseline</th>\n",
       "      <th>first_rel_rank_granite1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q20105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q20106</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q20107</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q20108</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q20109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id  is_good_baseline  is_good_granite1  first_rel_rank_baseline  \\\n",
       "0   q20105                 1                 1                      1.0   \n",
       "1   q20106                 1                 1                      1.0   \n",
       "2   q20107                 1                 1                      6.0   \n",
       "3   q20108                 1                 0                      2.0   \n",
       "4   q20109                 1                 1                      1.0   \n",
       "\n",
       "   first_rel_rank_granite1  \n",
       "0                      1.0  \n",
       "1                      3.0  \n",
       "2                      1.0  \n",
       "3                     37.0  \n",
       "4                      1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10 # Hyper-param to select top k documents to classify a \"good\" retrieval\n",
    "first_good = mark_good_queries(first_df, k=k)\n",
    "second_good = mark_good_queries(second_df, k=k)\n",
    "\n",
    "first_ranks = first_relevant_rank(first_df)\n",
    "second_ranks = first_relevant_rank(second_df)\n",
    "\n",
    "compare_df = first_good.merge(second_good, on=\"query_id\", suffixes=(f\"_{method_1}\", f\"_{method_2}\"))\n",
    "compare_df = compare_df.merge(first_ranks, on=\"query_id\")\n",
    "compare_df = compare_df.merge(second_ranks, on=\"query_id\", suffixes=(f\"_{method_1}\", f\"_{method_2}\"))\n",
    "\n",
    "compare_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries where baseline is good, but granite1 is bad:\n",
      "    query_id  is_good_baseline  is_good_granite1  first_rel_rank_baseline  \\\n",
      "3     q20108                 1                 0                      2.0   \n",
      "20    q20125                 1                 0                      7.0   \n",
      "27    q20132                 1                 0                      4.0   \n",
      "75    q20180                 1                 0                      9.0   \n",
      "85    q20190                 1                 0                     10.0   \n",
      "96    q20201                 1                 0                      6.0   \n",
      "103   q20208                 1                 0                     10.0   \n",
      "106   q20211                 1                 0                      4.0   \n",
      "109   q20214                 1                 0                      1.0   \n",
      "114   q20219                 1                 0                      8.0   \n",
      "118   q20223                 1                 0                      8.0   \n",
      "122   q20227                 1                 0                      3.0   \n",
      "123   q20228                 1                 0                      1.0   \n",
      "124   q20229                 1                 0                      9.0   \n",
      "150   q20255                 1                 0                      2.0   \n",
      "152   q20257                 1                 0                      9.0   \n",
      "160   q20265                 1                 0                      3.0   \n",
      "163   q20268                 1                 0                      2.0   \n",
      "165   q20270                 1                 0                      1.0   \n",
      "166   q20271                 1                 0                     10.0   \n",
      "199   q20304                 1                 0                      5.0   \n",
      "201   q20306                 1                 0                      8.0   \n",
      "227   q20332                 1                 0                      1.0   \n",
      "260   q20365                 1                 0                      6.0   \n",
      "280   q20385                 1                 0                      2.0   \n",
      "281   q20386                 1                 0                     10.0   \n",
      "289   q20394                 1                 0                      6.0   \n",
      "291   q20396                 1                 0                      2.0   \n",
      "301   q20406                 1                 0                      1.0   \n",
      "312   q20417                 1                 0                      8.0   \n",
      "313   q20418                 1                 0                      9.0   \n",
      "320   q20425                 1                 0                      1.0   \n",
      "330   q20435                 1                 0                      7.0   \n",
      "337   q20442                 1                 0                      7.0   \n",
      "344   q20449                 1                 0                      8.0   \n",
      "361   q20466                 1                 0                      7.0   \n",
      "382   q20487                 1                 0                      4.0   \n",
      "390   q20495                 1                 0                      2.0   \n",
      "409   q20514                 1                 0                      5.0   \n",
      "426   q20531                 1                 0                      7.0   \n",
      "440   q20545                 1                 0                      7.0   \n",
      "454   q20559                 1                 0                      8.0   \n",
      "464   q20569                 1                 0                      9.0   \n",
      "466   q20571                 1                 0                      6.0   \n",
      "481   q20586                 1                 0                      4.0   \n",
      "492   q20597                 1                 0                      1.0   \n",
      "494   q20599                 1                 0                      8.0   \n",
      "\n",
      "     first_rel_rank_granite1  \\\n",
      "3                       37.0   \n",
      "20                      44.0   \n",
      "27                      23.0   \n",
      "75                      25.0   \n",
      "85                      11.0   \n",
      "96                      48.0   \n",
      "103                     18.0   \n",
      "106                     11.0   \n",
      "109                     13.0   \n",
      "114                     17.0   \n",
      "118                    179.0   \n",
      "122                     19.0   \n",
      "123                     20.0   \n",
      "124                     27.0   \n",
      "150                    143.0   \n",
      "152                     34.0   \n",
      "160                     50.0   \n",
      "163                     61.0   \n",
      "165                     72.0   \n",
      "166                     19.0   \n",
      "199                     42.0   \n",
      "201                     62.0   \n",
      "227                     22.0   \n",
      "260                     25.0   \n",
      "280                     12.0   \n",
      "281                     32.0   \n",
      "289                     13.0   \n",
      "291                     11.0   \n",
      "301                     29.0   \n",
      "312                     14.0   \n",
      "313                     11.0   \n",
      "320                     12.0   \n",
      "330                     45.0   \n",
      "337                     16.0   \n",
      "344                     29.0   \n",
      "361                     15.0   \n",
      "382                     31.0   \n",
      "390                     18.0   \n",
      "409                     14.0   \n",
      "426                     54.0   \n",
      "440                     11.0   \n",
      "454                     44.0   \n",
      "464                     14.0   \n",
      "466                     11.0   \n",
      "481                     35.0   \n",
      "492                     28.0   \n",
      "494                     13.0   \n",
      "\n",
      "                                            query_text  \n",
      "3                test for iterable is string in python  \n",
      "20              python mysql get list of table columns  \n",
      "27                 how to check python object iterable  \n",
      "75                      python print nodes binary tree  \n",
      "85                  python elasticsearch limit results  \n",
      "96           have python line continue on to next line  \n",
      "103        python forcible close socket before opening  \n",
      "106         python unit test and coverage at same time  \n",
      "109  how to make a function in python to take the a...  \n",
      "114                            python lock no blocking  \n",
      "118        python sanic change all object id to string  \n",
      "122                       python subplot second y axis  \n",
      "123    python function to detect first element of list  \n",
      "124                     how to flip a matrix in python  \n",
      "150                  python apply function to iterator  \n",
      "152  how to print all the variables in an object py...  \n",
      "160                     best way to read xml in python  \n",
      "163                                 token to id python  \n",
      "165                 python turn a string into a number  \n",
      "166    python check if all are type string in a column  \n",
      "199              python random selection from function  \n",
      "201  running a def a specified amount of time python 3  \n",
      "227        python print string with visible ansi codes  \n",
      "260                    pickle python read entiere file  \n",
      "280             discord python get user from id string  \n",
      "281      list of arbitrary objects to counts in python  \n",
      "289                      python detect key press linux  \n",
      "291               python get epoch milis from datetime  \n",
      "301              python 3 a build string from iterable  \n",
      "312  python get index of element each time it appea...  \n",
      "313                   python how to make dot character  \n",
      "320                       python sort data by variable  \n",
      "330                     python default menuitem select  \n",
      "337                        python check if interactive  \n",
      "344             extract integers from string in python  \n",
      "361                   python check if object is a char  \n",
      "382                    python how to match dictionarys  \n",
      "390  read json file and turn into dictionary using ...  \n",
      "409  remove special characters from column names in...  \n",
      "426              how to check if object defined python  \n",
      "440          how to get the parent directory in python  \n",
      "454                    new line statemnt pythong write  \n",
      "464                            python wrap (s,w) print  \n",
      "466             python to get the indices of bin edges  \n",
      "481               how to print generic error in python  \n",
      "492                         python create enum by name  \n",
      "494                       python function default args  \n",
      "Queries where granite1 is good, but baseline is bad:\n",
      "    query_id  is_good_baseline  is_good_granite1  first_rel_rank_baseline  \\\n",
      "9     q20114                 0                 1                     51.0   \n",
      "11    q20116                 0                 1                    154.0   \n",
      "13    q20118                 0                 1                    118.0   \n",
      "15    q20120                 0                 1                     15.0   \n",
      "16    q20121                 0                 1                     22.0   \n",
      "..       ...               ...               ...                      ...   \n",
      "446   q20551                 0                 1                     36.0   \n",
      "455   q20560                 0                 1                     77.0   \n",
      "456   q20561                 0                 1                     26.0   \n",
      "485   q20590                 0                 1                     12.0   \n",
      "486   q20591                 0                 1                     48.0   \n",
      "\n",
      "     first_rel_rank_granite1                                  query_text  \n",
      "9                        8.0     python check all items in list are ints  \n",
      "11                       7.0   how to skip an index in a for loop python  \n",
      "13                       3.0            python raise without parentheses  \n",
      "15                       1.0    python asynchronous function call return  \n",
      "16                       3.0     how to make a seconds to time in python  \n",
      "..                       ...                                         ...  \n",
      "446                      8.0                      python change to bytes  \n",
      "455                      1.0  python view as series column format string  \n",
      "456                      5.0        python select not null column values  \n",
      "485                      5.0          python set contains multiple items  \n",
      "486                      6.0             python protobyf parse from byte  \n",
      "\n",
      "[86 rows x 6 columns]\n",
      "Queries both missed:\n",
      "    query_id  is_good_baseline  is_good_granite1  first_rel_rank_baseline  \\\n",
      "7     q20112                 0                 0                     24.0   \n",
      "8     q20113                 0                 0                     51.0   \n",
      "12    q20117                 0                 0                     34.0   \n",
      "14    q20119                 0                 0                     14.0   \n",
      "17    q20122                 0                 0                    431.0   \n",
      "..       ...               ...               ...                      ...   \n",
      "474   q20579                 0                 0                     70.0   \n",
      "476   q20581                 0                 0                    319.0   \n",
      "495   q20600                 0                 0                     31.0   \n",
      "496   q20601                 0                 0                     24.0   \n",
      "497   q20602                 0                 0                     14.0   \n",
      "\n",
      "     first_rel_rank_granite1  \\\n",
      "7                       13.0   \n",
      "8                       37.0   \n",
      "12                      13.0   \n",
      "14                      33.0   \n",
      "17                     435.0   \n",
      "..                       ...   \n",
      "474                    128.0   \n",
      "476                    180.0   \n",
      "495                     60.0   \n",
      "496                     20.0   \n",
      "497                     30.0   \n",
      "\n",
      "                                            query_text  \n",
      "7                          python numpy array as float  \n",
      "8         input string that replaces occurences python  \n",
      "12         how to create a tokenization code in python  \n",
      "14             how to seperate list with commas python  \n",
      "17                python cast true or false as numbers  \n",
      "..                                                 ...  \n",
      "474  is there any python function to check for nan ...  \n",
      "476                               python is list no na  \n",
      "495                python how to select first 100 rows  \n",
      "496            removing columnsns in data frame python  \n",
      "497                       python array to torch tensor  \n",
      "\n",
      "[150 rows x 6 columns]\n",
      "Queries both got:\n",
      "    query_id  is_good_baseline  is_good_granite1  first_rel_rank_baseline  \\\n",
      "0     q20105                 1                 1                      1.0   \n",
      "1     q20106                 1                 1                      1.0   \n",
      "2     q20107                 1                 1                      6.0   \n",
      "4     q20109                 1                 1                      1.0   \n",
      "5     q20110                 1                 1                      6.0   \n",
      "..       ...               ...               ...                      ...   \n",
      "490   q20595                 1                 1                      1.0   \n",
      "491   q20596                 1                 1                      2.0   \n",
      "493   q20598                 1                 1                      6.0   \n",
      "498   q20603                 1                 1                      9.0   \n",
      "499   q20604                 1                 1                      5.0   \n",
      "\n",
      "     first_rel_rank_granite1                                        query_text  \n",
      "0                        1.0                  sort by a token in string python  \n",
      "1                        3.0                     python check file is readonly  \n",
      "2                        1.0             declaring empty numpy array in python  \n",
      "4                        1.0                python print results of query loop  \n",
      "5                        5.0  how to save header of fits file to export python  \n",
      "..                       ...                                               ...  \n",
      "490                      4.0              python hash table check if key exist  \n",
      "491                      1.0                     take all points in box python  \n",
      "493                      2.0               python matplotlib use arrow markers  \n",
      "498                      1.0              how to turn a list into a csv python  \n",
      "499                      5.0                     how do i unzip file in python  \n",
      "\n",
      "[217 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "if \"codesearchnet\" in dataset_1 or \"codesearchnet\" in dataset_2:\n",
    "    tasks = load_data_from_hf(\"CodeSearchNet-python\")\n",
    "    corpus, queries, qrels = tasks\n",
    "compare_df[\"query_text\"] = compare_df[\"query_id\"].map(queries)\n",
    "\n",
    "bad_method_1 = compare_df[\n",
    "    (compare_df[f\"is_good_{method_1}\"] == 1) &\n",
    "    (compare_df[f\"is_good_{method_2}\"] == 0)\n",
    "]\n",
    "print(f\"Queries where {method_1} is good, but {method_2} is bad:\")\n",
    "print(bad_method_1)\n",
    "\n",
    "bad_method_2 = compare_df[\n",
    "    (compare_df[f\"is_good_{method_1}\"] == 0) &\n",
    "    (compare_df[f\"is_good_{method_2}\"] == 1)\n",
    "]\n",
    "print(f\"Queries where {method_2} is good, but {method_1} is bad:\")\n",
    "print(bad_method_2)\n",
    "\n",
    "# Queries both missed\n",
    "both_missed = compare_df[\n",
    "    (compare_df[f\"is_good_{method_1}\"] == 0) &\n",
    "    (compare_df[f\"is_good_{method_2}\"] == 0)\n",
    "]\n",
    "print(\"Queries both missed:\")\n",
    "print(both_missed)\n",
    "\n",
    "# Queries both got\n",
    "both_got = compare_df[\n",
    "    (compare_df[f\"is_good_{method_1}\"] == 1) &\n",
    "    (compare_df[f\"is_good_{method_2}\"] == 1)\n",
    "]\n",
    "print(\"Queries both got:\")\n",
    "print(both_got)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total queries: 500\n",
      "Baseline good queries: 264\n",
      "Baseline bad queries: 236\n",
      "Granite1 good queries: 303\n",
      "Granite1 bad queries: 197\n",
      "\n",
      "Baseline good but Granite1 bad queries count: 47\n",
      "\n",
      "Granite1 good but Baseline bad queries count: 86\n",
      "\n",
      "Queries both missed: 150\n",
      "\n",
      "Queries both got: 217\n"
     ]
    }
   ],
   "source": [
    "good_method_1_count = compare_df[f\"is_good_{method_1}\"].sum()\n",
    "good_method_2_count = compare_df[f\"is_good_{method_2}\"].sum()\n",
    "bad_method_1_count = len(compare_df) - good_method_1_count\n",
    "bad_method_2_count = len(compare_df) - good_method_2_count\n",
    "\n",
    "print(\"Total queries:\", len(compare_df))\n",
    "print(f\"{method_1.capitalize()} good queries:\", good_method_1_count)\n",
    "print(f\"{method_1.capitalize()} bad queries:\", bad_method_1_count)\n",
    "print(f\"{method_2.capitalize()} good queries:\", good_method_2_count)\n",
    "print(f\"{method_2.capitalize()} bad queries:\", bad_method_2_count)\n",
    "\n",
    "\n",
    "# Queries where method_1 is good but method_2 is bad\n",
    "bad_method_2_subset = compare_df[\n",
    "    (compare_df[f\"is_good_{method_1}\"] == 1) &\n",
    "    (compare_df[f\"is_good_{method_2}\"] == 0)\n",
    "]\n",
    "avg_rank_bad_method_2 = bad_method_2_subset[f\"first_rel_rank_{method_2}\"].mean()\n",
    "print(f\"\\n{method_1.capitalize()} good but {method_2.capitalize()} bad queries count:\", len(bad_method_2_subset))\n",
    "#print(f\"Average first relevant doc rank ({method_2.capitalize()}) for these queries:\", avg_rank_bad_method_2)\n",
    "\n",
    "# Queries where method_2 is good but method_1 is bad\n",
    "bad_method_1_subset = compare_df[\n",
    "    (compare_df[f\"is_good_{method_1}\"] == 0) &\n",
    "    (compare_df[f\"is_good_{method_2}\"] == 1)\n",
    "]\n",
    "avg_rank_bad_method_1 = bad_method_1_subset[f\"first_rel_rank_{method_1}\"].mean()\n",
    "print(f\"\\n{method_2.capitalize()} good but {method_1.capitalize()} bad queries count:\", len(bad_method_1_subset))\n",
    "#print(f\"Average first relevant doc rank ({method_1.capitalize()}) for these queries:\", avg_rank_bad_method_1)\n",
    "\n",
    "# Queries both missed\n",
    "print(f\"\\nQueries both missed: {len(both_missed)}\")\n",
    "\n",
    "# Queries both got\n",
    "avg_rank_method_1_both = both_got[f\"first_rel_rank_{method_1}\"].mean()\n",
    "avg_rank_method_2_both = both_got[f\"first_rel_rank_{method_2}\"].mean()\n",
    "print(f\"\\nQueries both got: {len(both_got)}\")\n",
    "#print(f\"Average first relevant doc rank ({method_1.capitalize()}) for these queries:\", avg_rank_method_1_both)\n",
    "#print(f\"Average first relevant doc rank ({method_2.capitalize()}) for these queries:\", avg_rank_method_2_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_group_table(df, title):\n",
    "    display_df = df[[\"query_id\", \"query_text\"]].copy()\n",
    "    html = f\"<h3>{title} (n={len(display_df)})</h3>\"\n",
    "    html += display_df.to_html(index=False, escape=False)\n",
    "    return html\n",
    "\n",
    "html_out = \"\"\n",
    "html_out += make_group_table(bad_method_1, f\"Queries where {method_1} is good, but {method_2} is bad\")\n",
    "html_out += make_group_table(bad_method_2, f\"Queries where {method_2} is good, but {method_1} is bad\")\n",
    "html_out += make_group_table(both_missed, \"Queries both missed\")\n",
    "html_out += make_group_table(both_got, \"Queries both got\")\n",
    "\n",
    "#display(HTML(html_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"codesearchnet\" in dataset_1 or \"codesearchnet\" in dataset_2:\n",
    "    csn_expl_path = '/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/explanations/CodeSearchNet_Python_deepseek_allSplits.csv'\n",
    "    merged_df = pd.read_csv(csn_expl_path)\n",
    "    bad_method_1_merge = pd.merge(bad_method_1, merged_df, on=\"query_id\", how=\"left\")\n",
    "    bad_method_2_merge = pd.merge(bad_method_2, merged_df, on=\"query_id\", how=\"left\")\n",
    "    both_missed_merge = pd.merge(both_missed, merged_df, on=\"query_id\", how=\"left\")\n",
    "    both_got_merge = pd.merge(both_got, merged_df, on=\"query_id\", how=\"left\")\n",
    "else:\n",
    "    bad_method_1_merge = pd.merge(bad_method_1, merged_df, on=\"query_id\", how=\"left\")\n",
    "    bad_method_2_merge = pd.merge(bad_method_2, merged_df, on=\"query_id\", how=\"left\")\n",
    "    both_missed_merge = pd.merge(both_missed, merged_df, on=\"query_id\", how=\"left\")\n",
    "    both_got_merge = pd.merge(both_got, merged_df, on=\"query_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Queries where baseline is good, but granite1 is bad\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9311fd83424053b27f42d547d4b5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='page', max=10, min=1), Dropdown(description='Code', opti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Queries where granite1 is good, but baseline is bad\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35141af303349b392f804a0a4def1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='page', max=18, min=1), Dropdown(description='Code', opti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Queries both missed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0cfc25394b49ffa7dcb78634ac2ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='page', max=31, min=1), Dropdown(description='Code', opti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: Queries both got\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e1f647fadd4f0fb8e14e8ec6151708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='page', max=44, min=1), Dropdown(description='Code', opti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(page, code, expl)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Available columns for explanations and code.\n",
    "if \"codesearchnet\" in dataset_1 or \"codesearchnet\" in dataset_2:\n",
    "    available_explanation_columns = [\n",
    "    \"explanation_deepseek_1_cleaned\", \"explanation_deepseek_2_cleaned\", \n",
    "    \"explanation_deepseek_3_cleaned\", \"explanation_deepseek_4_cleaned\", \n",
    "    \"explanation_deepseek_5_cleaned\"\n",
    "]\n",
    "\n",
    "    available_code_columns = [\n",
    "        \"code\",\n",
    "        \"explanation_deepseek_1_cleaned\", \"explanation_deepseek_2_cleaned\", \n",
    "        \"explanation_deepseek_3_cleaned\", \"explanation_deepseek_4_cleaned\", \n",
    "        \"explanation_deepseek_5_cleaned\"\n",
    "    ]\n",
    "\n",
    "else:\n",
    "    available_explanation_columns = [\n",
    "        \"explanation_deepseek_1\", \"explanation_deepseek_2\", \"explanation_deepseek_3\", \n",
    "        \"explanation_deepseek_4\", \"explanation_deepseek_5\", \n",
    "        \"explanation_deepseek_1_cleaned\", \"explanation_deepseek_2_cleaned\", \n",
    "        \"explanation_deepseek_3_cleaned\", \"explanation_deepseek_4_cleaned\", \n",
    "        \"explanation_deepseek_5_cleaned\", \n",
    "        \"explanation_granite_1\", \"explanation_granite_2\", \"explanation_granite_3\", \n",
    "        \"explanation_granite_4\", \"explanation_granite_5\", \n",
    "        \"explanation_granite_1_cleaned\", \"explanation_granite_2_cleaned\", \n",
    "        \"explanation_granite_3_cleaned\", \"explanation_granite_4_cleaned\", \n",
    "        \"explanation_granite_5_cleaned\"\n",
    "    ]\n",
    "\n",
    "    available_code_columns = [\n",
    "        \"code_deepseek\", \"cleaned_code_deepseek\",\n",
    "        \"explanation_deepseek_1\", \"explanation_deepseek_2\", \"explanation_deepseek_3\", \n",
    "        \"explanation_deepseek_4\", \"explanation_deepseek_5\", \n",
    "        \"explanation_deepseek_1_cleaned\", \"explanation_deepseek_2_cleaned\", \n",
    "        \"explanation_deepseek_3_cleaned\", \"explanation_deepseek_4_cleaned\", \n",
    "        \"explanation_deepseek_5_cleaned\", \n",
    "        \"explanation_granite_1\", \"explanation_granite_2\", \"explanation_granite_3\", \n",
    "        \"explanation_granite_4\", \"explanation_granite_5\", \n",
    "        \"explanation_granite_1_cleaned\", \"explanation_granite_2_cleaned\", \n",
    "        \"explanation_granite_3_cleaned\", \"explanation_granite_4_cleaned\", \n",
    "        \"explanation_granite_5_cleaned\"\n",
    "    ]\n",
    "\n",
    "def make_html_block(text):\n",
    "    \"\"\"Wrap the given text in a <div> that preserves whitespace and left-aligns the text.\"\"\"\n",
    "    return f\"<div style='white-space: pre-wrap; text-align: left; font-family: monospace;'>{text}</div>\"\n",
    "\n",
    "def show_page(df, code_col, expl_col, page=1, page_size=5):\n",
    "    \"\"\"\n",
    "    Display a subset of rows from the DataFrame using the selected\n",
    "    code column (for code) and explanation column (for explanation).\n",
    "    The resulting table will have headers that exactly match the dropdown selections.\n",
    "    \"\"\"\n",
    "    # Select the desired columns; keep original names.\n",
    "    display_df = df[[\"query_id\", \"query_text\", code_col, expl_col]].copy()\n",
    "    \n",
    "    # Apply HTML formatting to the code column.\n",
    "    display_df[code_col] = display_df[code_col].apply(make_html_block)\n",
    "    \n",
    "    # Paginate.\n",
    "    start = (page - 1) * page_size\n",
    "    end = start + page_size\n",
    "    sub_df = display_df.iloc[start:end]\n",
    "    \n",
    "    # Use the Styler to render HTML.\n",
    "    styled = sub_df.style.format({code_col: lambda s: s})\n",
    "    html = styled.to_html()\n",
    "    display(HTML(html))\n",
    "\n",
    "# Example interactive calls:\n",
    "# (Replace the DataFrame variables below with your actual DataFrames,\n",
    "# e.g. bad_method_1_merge, bad_method_2_merge, both_missed_merge, both_got_merge.)\n",
    "print(f\"Group: Queries where {method_1} is good, but {method_2} is bad\")\n",
    "widgets.interact(lambda page, code, expl: show_page(bad_method_1_merge, code, expl, page=page),\n",
    "                 page=widgets.IntSlider(min=1, max=(len(bad_method_2_subset) // 5) + 1, step=1, value=1),\n",
    "                 code=widgets.Dropdown(options=available_code_columns, value=available_code_columns[0], description=\"Code\"),\n",
    "                 expl=widgets.Dropdown(options=available_explanation_columns, value=available_explanation_columns[0], description=\"Explanation\"))\n",
    "\n",
    "print(f\"Group: Queries where {method_2} is good, but {method_1} is bad\")\n",
    "widgets.interact(lambda page, code, expl: show_page(bad_method_2_merge, code, expl, page=page),\n",
    "                 page=widgets.IntSlider(min=1, max=(len(bad_method_1_subset) // 5) + 1, step=1, value=1),\n",
    "                 code=widgets.Dropdown(options=available_code_columns, value=available_code_columns[0], description=\"Code\"),\n",
    "                 expl=widgets.Dropdown(options=available_explanation_columns, value=available_explanation_columns[0], description=\"Explanation\"))\n",
    "\n",
    "print(\"Group: Queries both missed\")\n",
    "widgets.interact(lambda page, code, expl: show_page(both_missed_merge, code, expl, page=page),\n",
    "                 page=widgets.IntSlider(min=1, max=(len(both_missed) // 5) + 1, step=1, value=1),\n",
    "                 code=widgets.Dropdown(options=available_code_columns, value=available_code_columns[0], description=\"Code\"),\n",
    "                 expl=widgets.Dropdown(options=available_explanation_columns, value=available_explanation_columns[0], description=\"Explanation\"))\n",
    "\n",
    "print(\"Group: Queries both got\")\n",
    "widgets.interact(lambda page, code, expl: show_page(both_got_merge, code, expl, page=page),\n",
    "                 page=widgets.IntSlider(min=1, max=(len(both_got) // 5) + 1, step=1, value=1),\n",
    "                 code=widgets.Dropdown(options=available_code_columns, value=available_code_columns[0], description=\"Code\"),\n",
    "                 expl=widgets.Dropdown(options=available_explanation_columns, value=available_explanation_columns[0], description=\"Explanation\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
