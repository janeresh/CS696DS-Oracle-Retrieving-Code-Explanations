{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coir.data_loader import get_tasks\n",
    "from coir.evaluation import COIR\n",
    "from coir.models import YourCustomDEModel\n",
    "from coir.beir.retrieval.train import TrainRetriever\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "from torch.utils.data import DataLoader\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_corpus_dataset = load_dataset(f\"CoIR-Retrieval/cosqa-queries-corpus\")\n",
    "qrels_dataset = load_dataset(f\"CoIR-Retrieval/cosqa-qrels\")\n",
    "cosqa_granite_updated_path='/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/Cosqa/postprocessing/output/COSQA_granite_explanations_clean.csv'\n",
    "df= pd.read_csv(cosqa_granite_updated_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_data = queries_corpus_dataset['corpus']\n",
    "query_data = queries_corpus_dataset['queries']\n",
    "qrels_data_test = qrels_dataset['test']\n",
    "qrels_df_test = qrels_data_test.to_pandas()\n",
    "qrels_data_train = qrels_dataset['train']\n",
    "qrels_data_valid = qrels_dataset['valid']\n",
    "qrels_data = concatenate_datasets([qrels_data_train, qrels_data_valid, qrels_data_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_query_ids = qrels_df_test['query_id'].to_list()\n",
    "len(test_query_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['_id', 'partition', 'text', 'title', 'language', 'meta_information'],\n",
       "    num_rows: 20604\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['_id', 'partition', 'text', 'title', 'language', 'meta_information'],\n",
       "    num_rows: 20604\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['query_id', 'corpus_id', 'score'],\n",
       "    num_rows: 20604\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_df = qrels_data.to_pandas()\n",
    "# qrels_df = qrels_df[qrels_df[\"score\"] == 1] # keeping only score 1\n",
    "query_df = query_data.to_pandas()\n",
    "corpus_df = corpus_data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = query_df.rename(columns={\"_id\": \"query_id\", \"partition\":\"query_partition\", \"text\": \"query_text\", \"title\": \"query_title\",  \"language\": \"query_language\", \"meta_information\": \"query_meta_information\"})\n",
    "corpus_df = corpus_df.rename(columns={\"_id\": \"corpus_id\", \"partition\":\"corpus_partition\", \"text\": \"corpus_text\", \"title\": \"corpus_title\", \"language\": \"corpus_language\", \"meta_information\": \"corpus_meta_information\"})\n",
    "merged = qrels_df.merge(query_df[[\"query_id\", \"query_partition\", \"query_text\", \"query_title\", \"query_language\", \"query_meta_information\"]], on=\"query_id\", how=\"left\")\n",
    "\n",
    "merged = merged.merge(corpus_df[[\"corpus_id\", \"corpus_partition\",\"corpus_text\", \"corpus_title\", \"corpus_language\", \"corpus_meta_information\"]], on=\"corpus_id\", how=\"left\")\n",
    "merged = merged.sort_values(by=\"query_id\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_corpus_ids = (\n",
    "    merged\n",
    "    .drop_duplicates(subset=[\"corpus_text\"], keep=\"last\")\n",
    "    .set_index(\"corpus_text\")[\"corpus_id\"]\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "merged[\"corpus_id\"] = merged[\"corpus_text\"].map(last_corpus_ids)\n",
    "\n",
    "merged = merged.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = merged[[\n",
    "    \"query_id\", \"query_partition\", \"query_text\", \"query_title\", \"query_language\", \"query_meta_information\"\n",
    "]].rename(columns={\n",
    "    \"query_id\": \"_id\", \"query_partition\": \"partition\", \"query_text\": \"text\", \n",
    "    \"query_title\": \"title\", \"query_language\": \"language\", \"query_meta_information\": \"meta_information\"\n",
    "})\n",
    "query_data = Dataset.from_pandas(query_df.reset_index(drop=True))\n",
    "\n",
    "# Corpus Data\n",
    "corpus_df = merged[[\n",
    "    \"corpus_id\", \"corpus_partition\", \"corpus_text\", \"corpus_title\", \"corpus_language\", \"corpus_meta_information\"\n",
    "]].rename(columns={\n",
    "    \"corpus_id\": \"_id\", \"corpus_partition\": \"partition\", \"corpus_text\": \"text\", \n",
    "    \"corpus_title\": \"title\", \"corpus_language\": \"language\", \"corpus_meta_information\": \"meta_information\"\n",
    "})\n",
    "corpus_data = Dataset.from_pandas(corpus_df.reset_index(drop=True))\n",
    "\n",
    "# Qrels Data\n",
    "qrels_df = merged[[\"query_id\", \"corpus_id\", \"score\"]].drop_duplicates()\n",
    "qrels_df_test = qrels_df[qrels_df[\"query_id\"].isin(test_query_ids)]\n",
    "qrels_data = Dataset.from_pandas(qrels_df.reset_index(drop=True))\n",
    "qrels_data_test = Dataset.from_pandas(qrels_df_test.reset_index(drop=True))\n",
    "\n",
    "corpus_df = corpus_df.drop_duplicates(subset=\"_id\", keep=\"first\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['_id', 'partition', 'text', 'title', 'language', 'meta_information'],\n",
       "    num_rows: 20604\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['_id', 'partition', 'text', 'title', 'language', 'meta_information'], dtype='object')\n",
      "Index(['_id', 'partition', 'text', 'title', 'language', 'meta_information'], dtype='object')\n",
      "Index(['query_id', 'corpus_id', 'score'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(corpus_df.columns)\n",
    "print(query_df.columns)\n",
    "print(qrels_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume corpus_df, query_df, qrels_df are already loaded\n",
    "\n",
    "# 1) Split each DataFrame\n",
    "train_corpus_df = corpus_df[corpus_df['partition']=='train']\n",
    "dev_corpus_df   = corpus_df[corpus_df['partition']=='valid']\n",
    "test_corpus_df  = corpus_df[corpus_df['partition']=='test']\n",
    "\n",
    "train_query_df = query_df[query_df['partition']=='train']\n",
    "dev_query_df   = query_df[query_df['partition']=='valid']\n",
    "test_query_df  = query_df[query_df['partition']=='test']\n",
    "\n",
    "train_qrels_df = qrels_df[qrels_df['query_id'].isin(train_query_df['_id'])]\n",
    "dev_qrels_df   = qrels_df[qrels_df['query_id'].isin(dev_query_df['_id'])]\n",
    "test_qrels_df  = qrels_df[qrels_df['query_id'].isin(test_query_df['_id'])]\n",
    "\n",
    "\n",
    "# 2) Build dicts for each split\n",
    "\n",
    "def make_corpus(df):\n",
    "    return (df\n",
    "            .set_index('_id')[['title','text']]\n",
    "            .fillna('')\n",
    "            .to_dict(orient='index'))\n",
    "\n",
    "def make_queries(df):\n",
    "    return df.set_index('_id')['text'].to_dict()\n",
    "\n",
    "def make_qrels(df):\n",
    "    return (df\n",
    "            .groupby('query_id')\n",
    "            .apply(lambda d: dict(zip(d['corpus_id'], d['score'])))\n",
    "            .to_dict())\n",
    "\n",
    "# train split\n",
    "train_corpus = make_corpus(train_corpus_df)\n",
    "train_queries = make_queries(train_query_df)\n",
    "train_qrels = make_qrels(train_qrels_df)\n",
    "\n",
    "# dev split\n",
    "dev_corpus = make_corpus(dev_corpus_df)\n",
    "dev_queries = make_queries(dev_query_df)\n",
    "dev_qrels = make_qrels(dev_qrels_df)\n",
    "\n",
    "# test split\n",
    "test_corpus = make_corpus(test_corpus_df)\n",
    "test_queries = make_queries(test_query_df)\n",
    "test_qrels = make_qrels(test_qrels_df)\n",
    "\n",
    "# Build the full corpus dict once\n",
    "full_corpus = (\n",
    "    corpus_df\n",
    "    .set_index('_id')[['title','text']]\n",
    "    .fillna('')\n",
    "    .to_dict(orient='index')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD EXPLANATIONS\n",
    "\n",
    "expl_df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CS696DS-Oracle-Retrieving-Code-Explanations/Explanation_Generation/Cosqa/postprocessing/output/COSQA_granite_explanations_clean.csv\")\n",
    "expl_df.rename(columns={\"query_id\": \"query-id\", \"corpus_id\": \"corpus-id\"}, inplace=True)\n",
    "for _, row in expl_df.iterrows():\n",
    "    corpus_id = row['corpus-id']\n",
    "    explanation = row['explanation_granite_1_cleaned']\n",
    "\n",
    "    if corpus_id in full_corpus and explanation and explanation.strip():\n",
    "        full_corpus[corpus_id]['text'] = explanation  \n",
    "\n",
    "    if corpus_id in train_corpus and explanation and explanation.strip():\n",
    "        train_corpus[corpus_id]['text'] = explanation \n",
    "    if corpus_id in dev_corpus and explanation and explanation.strip():\n",
    "        dev_corpus[corpus_id]['text'] = explanation\n",
    "    if corpus_id in test_corpus and explanation and explanation.strip():\n",
    "        test_corpus[corpus_id]['text'] = explanation  \n",
    "\n",
    "full_corpus = {doc_id: doc for doc_id, doc in full_corpus.items() if 'text' in doc and doc['text'].strip()}\n",
    "train_corpus = {doc_id: doc for doc_id, doc in train_corpus.items() if 'text' in doc and doc['text'].strip()}\n",
    "dev_corpus = {doc_id: doc for doc_id, doc in dev_corpus.items() if 'text' in doc and doc['text'].strip()}\n",
    "test_corpus = {doc_id: doc for doc_id, doc in test_corpus.items() if 'text' in doc and doc['text'].strip()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring modified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd746de4d0a4976ae73a5565ab80bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding Input Examples:   0%|          | 0/613 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aabedeen_umass_edu/.local/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1839' max='1839' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1839/1839 12:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Dev Cosine Accuracy@1</th>\n",
       "      <th>Dev Cosine Accuracy@3</th>\n",
       "      <th>Dev Cosine Accuracy@5</th>\n",
       "      <th>Dev Cosine Accuracy@10</th>\n",
       "      <th>Dev Cosine Precision@1</th>\n",
       "      <th>Dev Cosine Precision@3</th>\n",
       "      <th>Dev Cosine Precision@5</th>\n",
       "      <th>Dev Cosine Precision@10</th>\n",
       "      <th>Dev Cosine Recall@1</th>\n",
       "      <th>Dev Cosine Recall@3</th>\n",
       "      <th>Dev Cosine Recall@5</th>\n",
       "      <th>Dev Cosine Recall@10</th>\n",
       "      <th>Dev Cosine Ndcg@10</th>\n",
       "      <th>Dev Cosine Mrr@10</th>\n",
       "      <th>Dev Cosine Map@100</th>\n",
       "      <th>Dev Dot Accuracy@1</th>\n",
       "      <th>Dev Dot Accuracy@3</th>\n",
       "      <th>Dev Dot Accuracy@5</th>\n",
       "      <th>Dev Dot Accuracy@10</th>\n",
       "      <th>Dev Dot Precision@1</th>\n",
       "      <th>Dev Dot Precision@3</th>\n",
       "      <th>Dev Dot Precision@5</th>\n",
       "      <th>Dev Dot Precision@10</th>\n",
       "      <th>Dev Dot Recall@1</th>\n",
       "      <th>Dev Dot Recall@3</th>\n",
       "      <th>Dev Dot Recall@5</th>\n",
       "      <th>Dev Dot Recall@10</th>\n",
       "      <th>Dev Dot Ndcg@10</th>\n",
       "      <th>Dev Dot Mrr@10</th>\n",
       "      <th>Dev Dot Map@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.264100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.041194</td>\n",
       "      <td>0.028168</td>\n",
       "      <td>0.035990</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.041194</td>\n",
       "      <td>0.028168</td>\n",
       "      <td>0.035990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>613</td>\n",
       "      <td>0.264100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.068021</td>\n",
       "      <td>0.052616</td>\n",
       "      <td>0.061871</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.068021</td>\n",
       "      <td>0.052616</td>\n",
       "      <td>0.061871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.244700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.206437</td>\n",
       "      <td>0.168199</td>\n",
       "      <td>0.179450</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.206437</td>\n",
       "      <td>0.168199</td>\n",
       "      <td>0.179450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1226</td>\n",
       "      <td>0.244700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.190364</td>\n",
       "      <td>0.151734</td>\n",
       "      <td>0.161469</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.190364</td>\n",
       "      <td>0.151734</td>\n",
       "      <td>0.161469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.079333</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.235365</td>\n",
       "      <td>0.196316</td>\n",
       "      <td>0.207344</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.079333</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.235365</td>\n",
       "      <td>0.196316</td>\n",
       "      <td>0.207344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1839</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.082667</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.244841</td>\n",
       "      <td>0.202894</td>\n",
       "      <td>0.213403</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.082667</td>\n",
       "      <td>0.060800</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.244841</td>\n",
       "      <td>0.202894</td>\n",
       "      <td>0.213403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d601b97c6841cf957f50c163aa3f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) Instantiate model & retriever\n",
    "model_name = \"intfloat/e5-base-v2\"\n",
    "model      = SentenceTransformer(model_name)\n",
    "tr         = TrainRetriever(model, batch_size=32)\n",
    "\n",
    "# 2) Prepare train‐loader\n",
    "train_examples   = tr.load_train(full_corpus, train_queries, train_qrels)\n",
    "train_dataloader = tr.prepare_train(train_examples, shuffle=True)\n",
    "\n",
    "# 3) Dev evaluator over full corpus\n",
    "dev_evaluator = tr.load_ir_evaluator(\n",
    "    full_corpus,      # ← full retrieval pool\n",
    "    dev_queries,\n",
    "    dev_qrels,\n",
    "    max_corpus_size=None,\n",
    "    name=\"dev\"\n",
    ")\n",
    "\n",
    "# 4) Define objective + fine‐tune\n",
    "train_objectives = [(train_dataloader, CosineSimilarityLoss(model))]\n",
    "\n",
    "tr.fit(\n",
    "    train_objectives=train_objectives,\n",
    "    evaluator=dev_evaluator,\n",
    "    epochs=3,\n",
    "    evaluation_steps=500,\n",
    "    warmup_steps=200,\n",
    "    output_path=\"outputs/encoder_finetuned\",\n",
    "    weight_decay=0.01,\n",
    "    optimizer_params={'lr': 2e-5},\n",
    "    save_best_model=True\n",
    ")\n",
    "\n",
    "# 5) Final test evaluation also over full corpus\n",
    "best_model = SentenceTransformer(\"outputs/encoder_finetuned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YourCustomDEModel init → loaded from hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91788a0c6b8e41d0a730dde60410839b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding batches:   0%|          | 0/2 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b97fc2f71d4e919d99266ea60042c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding batches:   0%|          | 0/25 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cosqa': {'NDCG': {'NDCG@1': 0.348, 'NDCG@3': 0.46424, 'NDCG@5': 0.50193, 'NDCG@10': 0.53837, 'NDCG@100': 0.58366, 'NDCG@1000': 0.58867}, 'MAP': {'MAP@1': 0.348, 'MAP@3': 0.43533, 'MAP@5': 0.45613, 'MAP@10': 0.4713, 'MAP@100': 0.48119, 'MAP@1000': 0.4814}, 'Recall': {'Recall@1': 0.348, 'Recall@3': 0.548, 'Recall@5': 0.64, 'Recall@10': 0.752, 'Recall@100': 0.958, 'Recall@1000': 0.996}, 'Precision': {'P@1': 0.348, 'P@3': 0.18267, 'P@5': 0.128, 'P@10': 0.0752, 'P@100': 0.00958, 'P@1000': 0.001}}}\n"
     ]
    }
   ],
   "source": [
    "tasks = {}\n",
    "tasks[\"cosqa\"] = (full_corpus, test_queries, test_qrels)\n",
    "evaluation = COIR(tasks=tasks,batch_size=256)\n",
    "dataset_name = \"cosqa/trained_encoders\"\n",
    "llm_name= \"granite1\"\n",
    "retrieval_name=\"dres\"\n",
    "model_name=\"intfloat/e5-base-v2\"\n",
    "loacl_path = \"/work/pi_wenlongzhao_umass_edu/27/atifabedeen/pipeline/coir_main/outputs/encoder_finetuned\"\n",
    "model = YourCustomDEModel(model_name=model_name)\n",
    "\n",
    "results = evaluation.run(model, output_folder=f\"results/{dataset_name}/{llm_name}/{retrieval_name}/{model_name}\")\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
