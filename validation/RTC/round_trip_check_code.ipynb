{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import difflib\n",
    "import code_bert_score\n",
    "import ast\n",
    "import pandas as pd\n",
    "import sys\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from codebleu import calc_codebleu\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "MODEL_NAME = \"/datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    torch_dtype=torch.float16,  \n",
    "    device_map=\"auto\"\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepseek_generate(prompt, max_tokens=500, temperature=0.8):\n",
    "    \"\"\"\n",
    "    Generates text using DeepSeek Coder with token length handling.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2000, padding=True).to(device)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=max_tokens,  # ✅ Fixing the argument name\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1,\n",
    "        )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Forward Pass: Code → 3 Natural Language Descriptions\n",
    "def code_to_explanations(doc, code_snippet):\n",
    "    \"\"\"\n",
    "    Generates 3 natural language explanations from a given code snippet.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        f\"Doc string: {doc}\\n\"\n",
    "        f\"Code snippet: {code_snippet}\\n\"\n",
    "        \"Instruction: Provide a concise explanation of what the above doc and code mean. \"\n",
    "        \"Generate strictly less than 100 words in total.\\n\"\n",
    "        \"Answer:\\n\"\n",
    "    )\n",
    "    generated_exp = deepseek_generate(prompt, max_tokens=128, temperature=0.8)\n",
    "    cleaned_exp = generated_exp.strip().replace(prompt, \"\").strip()\n",
    "    cleaned_exp = clean_output(cleaned_exp,\"Answer:\")\n",
    "    cleaned_exp = clean_output(cleaned_exp,\"</think>\")\n",
    "    return cleaned_exp\n",
    "\n",
    "# Backward Pass: Each Explanation → Code\n",
    "def explanation_to_code(description):\n",
    "    \"\"\"\n",
    "    Generates Python code from a cleaned natural language description.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"Write only the Python function corresponding to the following description. \"\n",
    "        \"Do not provide explanations, comments, markdown, parameter descriptions, or return values. \"\n",
    "        \"Ensure that the function name and structure exactly match the description.\\n\\n\"\n",
    "        f\"Description:\\n{description}\\n\\nPython Code:\\n\"\n",
    "    )\n",
    "    cleaned_code = description.strip().replace(prompt, \"\").strip()\n",
    "    generated_code = deepseek_generate(prompt, max_tokens=512, temperature=0.8)\n",
    "    cleaned_code = generated_code.strip().replace(prompt, \"\").strip()\n",
    "    cleaned_code = clean_output(cleaned_code,\"Answer:\")\n",
    "    cleaned_code = clean_output(cleaned_code,\"</think>\")\n",
    "    return cleaned_code\n",
    " \n",
    "def clean_output(text,keyword):\n",
    "    # keyword = \"Answer:\"\n",
    "    index = text.rfind(keyword) \n",
    "    if index != -1:\n",
    "        return text[index + len(keyword):].strip()  \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing Code for Better Comparison\n",
    "def normalize_code(code):\n",
    "    \"\"\"\n",
    "    Normalize Python code by parsing it into an AST and standardizing the format.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return ast.dump(ast.parse(code))\n",
    "    except SyntaxError:\n",
    "        return None\n",
    "\n",
    "# Compute Correct Generation Count\n",
    "def correct_generation(sim_scores):\n",
    "    return sum(1 for score in sim_scores if score > 0.7)\n",
    "\n",
    "# Evaluate Metrics\n",
    "def evaluate_metrics(original_code, generated_code):\n",
    "    \"\"\"\n",
    "    Evaluates RTC correctness using similarity metrics.\n",
    "    \"\"\"\n",
    "    exact_match = original_code.strip() == generated_code.strip()\n",
    "    similarity = code_bert_score_func(original_code, generated_code)\n",
    "    \n",
    "    return exact_match, similarity\n",
    "\n",
    "# Pass@1 Computation\n",
    "def pass_at_1(n: int, c: int, k: int) -> float:\n",
    "    if n - c < k:\n",
    "        return 1.0\n",
    "    return 1.0 - np.prod(1.0 - k / np.arange(n - c + 1, n + 1))\n",
    "\n",
    "# CodeBERT Similarity Score\n",
    "def code_bert_score_func(x: str, x_hat: str) -> float:\n",
    "    P, R, F1, _ = code_bert_score.score(cands=[x_hat], refs=[x], lang='python')\n",
    "    return F1.mean().item()\n",
    "\n",
    "# CodeBLEU Similarity Score\n",
    "def codebleu_func(x: str, x_hat: str) -> float:\n",
    "    return calc_codebleu([x], [x_hat], lang=\"python\", weights=(0.25, 0.25, 0.25, 0.25), tokenizer=None)\n",
    "\n",
    "# Compute RTC\n",
    "def compute_rtc(sim_scores):\n",
    "    if not sim_scores:\n",
    "        return 0.0\n",
    "    return sum(sim_scores) / len(sim_scores)\n",
    "\n",
    "# Compute LPass\n",
    "def evaluate_lpass(codes, original_code):\n",
    "    return 1 if any(code_bert_score_func(original_code, code) > 0.75 for code in codes) else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating for one code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv = \"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/data/deepseek_single_exp_split/split_part_0.csv\"\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Select Only First Row\n",
    "row = df.iloc[0]  # Only one row is selected\n",
    "results = []\n",
    "original_code = str(row[\"code\"]).strip()\n",
    "doc = str(row[\"doc\"]).strip()\n",
    "\n",
    "codes, sim_scores, explanations, matches = [], [], [], []\n",
    "\n",
    "for _ in range(3):\n",
    "    explanation = code_to_explanations(doc, original_code)\n",
    "    generated_code = explanation_to_code(explanation)\n",
    "    exact_match, similarity_score = evaluate_metrics(original_code, generated_code)\n",
    "\n",
    "    codes.append(generated_code)\n",
    "    sim_scores.append(similarity_score)\n",
    "    explanations.append(explanation)\n",
    "    matches.append(exact_match)\n",
    "\n",
    "true_count = correct_generation(sim_scores)\n",
    "final_rtcpass = compute_rtc(sim_scores)\n",
    "pass_score = pass_at_1(3, true_count, 1)\n",
    "\n",
    "results.append({\n",
    "    \"Original Code\": original_code,\n",
    "    \"Generated Code1\": codes[0],\n",
    "    \"Generated Code2\": codes[1],\n",
    "    \"Generated Code3\": codes[2],\n",
    "    \"Explanation1\": explanations[0],\n",
    "    \"Explanation2\": explanations[1],\n",
    "    \"Explanation3\": explanations[2],\n",
    "    \"Exact Match\": matches,\n",
    "    \"CodeBERTScore\": sim_scores,\n",
    "    \"RTCPass\": final_rtcpass,\n",
    "    \"Pass@1\": pass_score\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Code</th>\n",
       "      <th>Generated Code1</th>\n",
       "      <th>Generated Code2</th>\n",
       "      <th>Generated Code3</th>\n",
       "      <th>Explanation1</th>\n",
       "      <th>Explanation2</th>\n",
       "      <th>Explanation3</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>CodeBERTScore</th>\n",
       "      <th>RTCPass</th>\n",
       "      <th>Pass@1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def writeBoolean(self, n):\\n        \"\"\"\\n     ...</td>\n",
       "      <td>def convert_to_one(data):\\n    if isinstance(d...</td>\n",
       "      <td>def write_bool(bool_value):\\n    # TODO: Write...</td>\n",
       "      <td>def write_to_stream():\\n    # Write code here\\...</td>\n",
       "      <td>The doc and code are meant to write a boolean ...</td>\n",
       "      <td>The doc and code are meant to write a boolean ...</td>\n",
       "      <td>The code is designed to write a boolean value ...</td>\n",
       "      <td>[False, False, False]</td>\n",
       "      <td>[0.6500335931777954, 0.707127034664154, 0.6961...</td>\n",
       "      <td>0.684427</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Original Code  \\\n",
       "0  def writeBoolean(self, n):\\n        \"\"\"\\n     ...   \n",
       "\n",
       "                                     Generated Code1  \\\n",
       "0  def convert_to_one(data):\\n    if isinstance(d...   \n",
       "\n",
       "                                     Generated Code2  \\\n",
       "0  def write_bool(bool_value):\\n    # TODO: Write...   \n",
       "\n",
       "                                     Generated Code3  \\\n",
       "0  def write_to_stream():\\n    # Write code here\\...   \n",
       "\n",
       "                                        Explanation1  \\\n",
       "0  The doc and code are meant to write a boolean ...   \n",
       "\n",
       "                                        Explanation2  \\\n",
       "0  The doc and code are meant to write a boolean ...   \n",
       "\n",
       "                                        Explanation3            Exact Match  \\\n",
       "0  The code is designed to write a boolean value ...  [False, False, False]   \n",
       "\n",
       "                                       CodeBERTScore   RTCPass    Pass@1  \n",
       "0  [0.6500335931777954, 0.707127034664154, 0.6961...  0.684427  0.333333  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Result with 10 Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10rows= pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/results/deepseek_sample.csv\")\n",
    "r1 = df_10rows.iloc[0]\n",
    "r2 = df_10rows.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Row 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Code: \n",
      " def writeBoolean(self, n):\n",
      "        \"\"\"\n",
      "        Writes a Boolean to the stream.\n",
      "        \"\"\"\n",
      "        t = TYPE_BOOL_TRUE\n",
      "\n",
      "        if n is False:\n",
      "            t = TYPE_BOOL_FALSE\n",
      "\n",
      "        self.stream.write(t)\n",
      "\n",
      "Generated Code1: \n",
      " ```python\n",
      "import socket\n",
      "import threading\n",
      "\n",
      "def write_to_stream(n, stream):\n",
      "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
      "        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
      "        s.bind(('localhost', '60') if socket.gethostname() == 'localhost' else ('localhost', '63'))\n",
      "        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
      "        s.bind(('localhost', '60') if socket.gethostname() == 'localhost' else ('localhost', '63'))\n",
      "        s.listen(5)\n",
      "        print(\"Listening on port\", stream)\n",
      "\n",
      "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
      "        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
      "        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
      "        s.bind(('localhost', '60') if socket.gethostname() == 'localhost' else ('localhost', '63'))\n",
      "        s.listen(5)\n",
      "        print(\"Listening on port\", stream)\n",
      "    print(\"Waiting for a connection...\")\n",
      "    conn, addr = s.accept()\n",
      "    print(\"Connected by\", addr)\n",
      "    conn.write(f\"{t}\\n\".encode())\n",
      "    s.close()\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOriginal Code: \\n\",r1[\"Original Code\"])\n",
    "print(\"\\nGenerated Code1: \\n\",r1[\"Generated Code1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Code: \n",
      " def writeBoolean(self, n):\n",
      "        \"\"\"\n",
      "        Writes a Boolean to the stream.\n",
      "        \"\"\"\n",
      "        t = TYPE_BOOL_TRUE\n",
      "\n",
      "        if n is False:\n",
      "            t = TYPE_BOOL_FALSE\n",
      "\n",
      "        self.stream.write(t)\n",
      "\n",
      "Generated Code2: \n",
      " ```python\n",
      "def set_stream_value(value):\n",
      "    if value is False:\n",
      "        return True\n",
      "    else:\n",
      "        return False\n",
      "```\n",
      "\n",
      "The function `set_stream_value` takes a boolean input. If the input is `False`, it returns `True`, otherwise it returns `False`. This ensures that the stream is set to write `True` when the input is `False`, and `False` otherwise.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOriginal Code: \\n\",r1[\"Original Code\"])\n",
    "print(\"\\nGenerated Code2: \\n\",r1[\"Generated Code2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Code: \n",
      " def writeBoolean(self, n):\n",
      "        \"\"\"\n",
      "        Writes a Boolean to the stream.\n",
      "        \"\"\"\n",
      "        t = TYPE_BOOL_TRUE\n",
      "\n",
      "        if n is False:\n",
      "            t = TYPE_BOOL_FALSE\n",
      "\n",
      "        self.stream.write(t)\n",
      "\n",
      "Generated Code3: \n",
      " ```python\n",
      "def write_bool(n):\n",
      "    if n:\n",
      "        return \"TYPE_BOOL_TRUE\"\n",
      "    else:\n",
      "        return \"TYPE_BOOL_FALSE\"\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOriginal Code: \\n\",r1[\"Original Code\"])\n",
    "print(\"\\nGenerated Code3: \\n\",r1[\"Generated Code3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Code: \n",
      " def paste(xsel=False):\n",
      "    \"\"\"Returns system clipboard contents.\"\"\"\n",
      "    selection = \"primary\" if xsel else \"clipboard\"\n",
      "    try:\n",
      "        return subprocess.Popen([\"xclip\", \"-selection\", selection, \"-o\"], stdout=subprocess.PIPE).communicate()[0].decode(\"utf-8\")\n",
      "    except OSError as why:\n",
      "        raise XclipNotFound\n",
      "\n",
      "Generated Code3: \n",
      " ```python\n",
      "import subprocess\n",
      "\n",
      "def paste(xsel=\"clipboard\"):\n",
      "    result = subprocess.Popen(['cp', xsel], stdout=subprocess.PIPE)\n",
      "    return result.stdout.decode('ascii')\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOriginal Code: \\n\",r2[\"Original Code\"])\n",
    "print(\"\\nGenerated Code3: \\n\",r2[\"Generated Code3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Original Code      def paste(xsel=False):\\n    \"\"\"Returns system ...\n",
       "Generated Code1    ```python\\ndef paste_from_clipboard(board):\\n ...\n",
       "Generated Code2    ```python\\ndef paste(xsel=\"clipboard\"):\\n    #...\n",
       "Generated Code3    ```python\\nimport subprocess\\n\\ndef paste(xsel...\n",
       "Explanation1       The code pastes text from either the system cl...\n",
       "Explanation2       </think>\\n\\nThe code snippet demonstrates a fu...\n",
       "Explanation3       </think>\\n\\nThe code snippet defines a method ...\n",
       "Exact Match                                    [False, False, False]\n",
       "CodeBERTScore      [0.6677306294441223, 0.7519256472587585, 0.819...\n",
       "RTCPass                                                     0.746391\n",
       "Pass@1                                                      0.666667\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19604, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df= pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/results/round_check_deepseek_single_exp/merged_deepseek_single_exp_results.csv\")\n",
    "complete_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Code</th>\n",
       "      <th>Generated Code1</th>\n",
       "      <th>Generated Code2</th>\n",
       "      <th>Generated Code3</th>\n",
       "      <th>Explanation1</th>\n",
       "      <th>Explanation2</th>\n",
       "      <th>Explanation3</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>CodeBERTScore</th>\n",
       "      <th>RTCPass</th>\n",
       "      <th>Pass@1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>def writeBoolean(self, n):\\n        \"\"\"\\n     ...</td>\n",
       "      <td>```python\\ndef write_boolean_value(input_value...</td>\n",
       "      <td>```python\\ndef writeBoolean(n):\\n    if n == F...</td>\n",
       "      <td>```python\\ndef boolean_value():\\n    return Tr...</td>\n",
       "      <td>The doc and code are related to writing a bool...</td>\n",
       "      <td>&lt;/think&gt;\\n\\nThe doc and code are related to wr...</td>\n",
       "      <td>The doc and code are meant to write a boolean ...</td>\n",
       "      <td>[False, False, False]</td>\n",
       "      <td>[0.7316482067108154, 0.8874270915985107, 0.709...</td>\n",
       "      <td>0.776091</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def paste(xsel=False):\\n    \"\"\"Returns system ...</td>\n",
       "      <td>```python\\ndef paste():\\n    return input().st...</td>\n",
       "      <td>```python\\nimport subprocess\\n\\ndef clipboard_...</td>\n",
       "      <td>def clipboard_paste(selection):\\n    # code he...</td>\n",
       "      <td>&lt;/think&gt;\\n\\nThe function pastes clipboard cont...</td>\n",
       "      <td>&lt;/think&gt;\\n\\nThe code snippet manipulates the c...</td>\n",
       "      <td>The function pastes data from the clipboard in...</td>\n",
       "      <td>[False, False, False]</td>\n",
       "      <td>[0.6364813446998596, 0.7315587997436523, 0.611...</td>\n",
       "      <td>0.659943</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>def _format_json(data, theme):\\n    \"\"\"Pretty ...</td>\n",
       "      <td>```python\\nimport json\\nfrom pygments import T...</td>\n",
       "      <td>```python\\ndef _format_json(data, theme=None):...</td>\n",
       "      <td>```python\\nimport json\\n\\ndef _format_json(dat...</td>\n",
       "      <td>&lt;/think&gt;\\n\\nThe code snippet takes a dictionar...</td>\n",
       "      <td>The code snippet is a function called _format_...</td>\n",
       "      <td>The code snippet is a function named _format_j...</td>\n",
       "      <td>[False, False, False]</td>\n",
       "      <td>[0.7832554578781128, 0.7650187611579895, 0.727...</td>\n",
       "      <td>0.758605</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>def create_path(path):\\n    \"\"\"Creates a absol...</td>\n",
       "      <td>```python\\nimport os\\n\\ndef create_path(path):...</td>\n",
       "      <td>```python\\nimport os\\n\\ndef relative_to_absolu...</td>\n",
       "      <td>```\\nimport os\\ndef absolute_path(relative_pat...</td>\n",
       "      <td>&lt;/think&gt;\\n\\nThe function `create_path` takes a...</td>\n",
       "      <td>The doc and code are related to creating a fil...</td>\n",
       "      <td>&lt;/think&gt;\\n\\nThe doc and code create an absolut...</td>\n",
       "      <td>[False, False, False]</td>\n",
       "      <td>[0.8395000696182251, 0.7711982131004333, 0.790...</td>\n",
       "      <td>0.800384</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    \"\"\"...</td>\n",
       "      <td>```python\\ndef scalar(arr=None, shape=None):\\n...</td>\n",
       "      <td>```python\\ndef _vector_or_scalar(x, type='row'...</td>\n",
       "      <td>```python\\ndef convert_to_vector(obj):\\n    if...</td>\n",
       "      <td>&lt;/think&gt;\\n\\nThe function converts an input to ...</td>\n",
       "      <td>&lt;/think&gt;\\n\\nThe doc and code snippet describe ...</td>\n",
       "      <td>The function converts an object into a scalar,...</td>\n",
       "      <td>[False, False, False]</td>\n",
       "      <td>[0.7925320863723755, 0.853780210018158, 0.8149...</td>\n",
       "      <td>0.820408</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Original Code  \\\n",
       "0  def writeBoolean(self, n):\\n        \"\"\"\\n     ...   \n",
       "1  def paste(xsel=False):\\n    \"\"\"Returns system ...   \n",
       "2  def _format_json(data, theme):\\n    \"\"\"Pretty ...   \n",
       "3  def create_path(path):\\n    \"\"\"Creates a absol...   \n",
       "4  def _vector_or_scalar(x, type='row'):\\n    \"\"\"...   \n",
       "\n",
       "                                     Generated Code1  \\\n",
       "0  ```python\\ndef write_boolean_value(input_value...   \n",
       "1  ```python\\ndef paste():\\n    return input().st...   \n",
       "2  ```python\\nimport json\\nfrom pygments import T...   \n",
       "3  ```python\\nimport os\\n\\ndef create_path(path):...   \n",
       "4  ```python\\ndef scalar(arr=None, shape=None):\\n...   \n",
       "\n",
       "                                     Generated Code2  \\\n",
       "0  ```python\\ndef writeBoolean(n):\\n    if n == F...   \n",
       "1  ```python\\nimport subprocess\\n\\ndef clipboard_...   \n",
       "2  ```python\\ndef _format_json(data, theme=None):...   \n",
       "3  ```python\\nimport os\\n\\ndef relative_to_absolu...   \n",
       "4  ```python\\ndef _vector_or_scalar(x, type='row'...   \n",
       "\n",
       "                                     Generated Code3  \\\n",
       "0  ```python\\ndef boolean_value():\\n    return Tr...   \n",
       "1  def clipboard_paste(selection):\\n    # code he...   \n",
       "2  ```python\\nimport json\\n\\ndef _format_json(dat...   \n",
       "3  ```\\nimport os\\ndef absolute_path(relative_pat...   \n",
       "4  ```python\\ndef convert_to_vector(obj):\\n    if...   \n",
       "\n",
       "                                        Explanation1  \\\n",
       "0  The doc and code are related to writing a bool...   \n",
       "1  </think>\\n\\nThe function pastes clipboard cont...   \n",
       "2  </think>\\n\\nThe code snippet takes a dictionar...   \n",
       "3  </think>\\n\\nThe function `create_path` takes a...   \n",
       "4  </think>\\n\\nThe function converts an input to ...   \n",
       "\n",
       "                                        Explanation2  \\\n",
       "0  </think>\\n\\nThe doc and code are related to wr...   \n",
       "1  </think>\\n\\nThe code snippet manipulates the c...   \n",
       "2  The code snippet is a function called _format_...   \n",
       "3  The doc and code are related to creating a fil...   \n",
       "4  </think>\\n\\nThe doc and code snippet describe ...   \n",
       "\n",
       "                                        Explanation3            Exact Match  \\\n",
       "0  The doc and code are meant to write a boolean ...  [False, False, False]   \n",
       "1  The function pastes data from the clipboard in...  [False, False, False]   \n",
       "2  The code snippet is a function named _format_j...  [False, False, False]   \n",
       "3  </think>\\n\\nThe doc and code create an absolut...  [False, False, False]   \n",
       "4  The function converts an object into a scalar,...  [False, False, False]   \n",
       "\n",
       "                                       CodeBERTScore   RTCPass    Pass@1  \n",
       "0  [0.7316482067108154, 0.8874270915985107, 0.709...  0.776091  1.000000  \n",
       "1  [0.6364813446998596, 0.7315587997436523, 0.611...  0.659943  0.333333  \n",
       "2  [0.7832554578781128, 0.7650187611579895, 0.727...  0.758605  1.000000  \n",
       "3  [0.8395000696182251, 0.7711982131004333, 0.790...  0.800384  1.000000  \n",
       "4  [0.7925320863723755, 0.853780210018158, 0.8149...  0.820408  1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def paste(xsel=False):\n",
      "    \"\"\"Returns system clipboard contents.\"\"\"\n",
      "    selection = \"primary\" if xsel else \"clipboard\"\n",
      "    try:\n",
      "        return subprocess.Popen([\"xclip\", \"-selection\", selection, \"-o\"], stdout=subprocess.PIPE).communicate()[0].decode(\"utf-8\")\n",
      "    except OSError as why:\n",
      "        raise XclipNotFound\n",
      "def clipboard_paste(selection):\n",
      "    # code here\n",
      "\n",
      "But I'm not sure about the exact implementation.\n",
      "\n",
      "Wait, I need to write a Python function called clipboard_paste that pastes data from the clipboard into the specified selection and returns the decoded string.\n",
      "\n",
      "So, the function needs to take a selection parameter, which can be a string (data) or a bytes object (clipboard data).\n",
      "\n",
      "Then, it should paste this data into the clipboard and return the decoded string.\n",
      "\n",
      "Hmm, but how? Because when you paste clipboard data into a string, you have to decode it.\n",
      "\n",
      "So, the steps are:\n",
      "\n",
      "1. Get the clipboard data: using subprocess.getpaste(), which returns bytes.\n",
      "\n",
      "2. Decode the clipboard data: using bytes.decode(), which returns a string.\n",
      "\n",
      "3. Paste the decoded string into the specified selection.\n",
      "\n",
      "4. Return the decoded string.\n",
      "\n",
      "Wait, but the selection is either a string or bytes. So, if the selection is a string, we need to decode it into bytes, then append the decoded clipboard data.\n",
      "\n",
      "Wait, no. Because when you paste clipboard data into a string, you have to decode it.\n",
      "\n",
      "So, the function would do something like:\n",
      "\n",
      "def clipboard_paste(selection):\n",
      "    # Get the clipboard data\n",
      "    clipboard_data = subprocess.getpaste()\n",
      "    # Decode the clipboard data\n",
      "    decoded = clipboard_data.decode('utf-8')\n",
      "    # Append to the selection\n",
      "    selection += decoded\n",
      "    # Return the decoded data\n",
      "    return decoded\n",
      "\n",
      "But wait, what about when the selection is bytes? Because getpaste() returns bytes, and appending bytes to a bytes object will work. So, whether the selection is a string or bytes, appending the decoded bytes will work.\n",
      "\n",
      "But wait, no. Because if the selection is a string, adding bytes will result in a bytes object. But the function is supposed to return a string.\n",
      "\n",
      "So, perhaps, the function should always return a string, regardless of the input.\n",
      "\n",
      "So, the steps:\n",
      "\n",
      "1. Get the clipboard data from the selection.\n",
      "\n",
      "2. Decode it.\n",
      "\n",
      "3. Append it to the selection.\n",
      "\n",
      "4. Return the decoded string.\n",
      "\n",
      "But wait, what about the case where the clipboard data is bytes and the selection is bytes? Appending should work.\n",
      "\n",
      "But wait, what about the case where the selection is a string and the clipboard data is bytes. So, the function should decode the clipboard data, then append to the selection.\n",
      "\n",
      "So, the code would be:\n",
      "\n",
      "def clipboard_paste(selection):\n",
      "    clipboard_data = subprocess.getpaste\n"
     ]
    }
   ],
   "source": [
    "print(complete_df.iloc[1][\"Original Code\"])\n",
    "print(complete_df.iloc[1][\"Generated Code3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VLLM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import difflib\n",
    "import code_bert_score\n",
    "import ast\n",
    "import pandas as pd\n",
    "import sys\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from codebleu import calc_codebleu\n",
    "import numpy as np\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA L40S\n",
      "(8, 9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.get_device_name(0))  # Should print NVIDIA L40S\n",
    "print(torch.cuda.get_device_capability(0))  # Should print (8, 9) or higher\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Device Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 03-19 02:41:33 arg_utils.py:900] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\n",
      "INFO 03-19 02:41:33 config.py:1013] Chunked prefill is enabled with max_num_batched_tokens=512.\n",
      "INFO 03-19 02:41:33 llm_engine.py:223] Initializing an LLM engine (v0.6.1.post1) with config: model='/datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa', speculative_config=None, tokenizer='/datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)\n",
      "INFO 03-19 02:41:33 selector.py:259] Cannot use FlashAttention-2 backend because the vllm_flash_attn package is not found. `pip install vllm-flash-attn` for better performance.\n",
      "INFO 03-19 02:41:33 selector.py:116] Using XFormers backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_wenlongzhao_umass_edu/27/.venv/lib/python3.12/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/work/pi_wenlongzhao_umass_edu/27/.venv/lib/python3.12/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-19 02:41:34 model_runner.py:997] Starting to load model /datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa...\n",
      "INFO 03-19 02:41:35 selector.py:259] Cannot use FlashAttention-2 backend because the vllm_flash_attn package is not found. `pip install vllm-flash-attn` for better performance.\n",
      "INFO 03-19 02:41:35 selector.py:116] Using XFormers backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc39b8ac8d9c48b3bf8bab24e7807047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-19 02:41:43 model_runner.py:1008] Loading model weights took 3.3460 GB\n",
      "INFO 03-19 02:41:44 gpu_executor.py:122] # GPU blocks: 81535, # CPU blocks: 9362\n",
      "INFO 03-19 02:41:46 model_runner.py:1309] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 03-19 02:41:46 model_runner.py:1313] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 03-19 02:41:58 model_runner.py:1428] Graph capturing finished in 12 secs.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "MODEL_NAME = \"/datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model_vllm = LLM(model=MODEL_NAME, dtype=\"bfloat16\", device=\"cuda\", enforce_eager=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_to_explanations_vllm(doc, code_snippet, temperature = 0.8):\n",
    "    prompts = []\n",
    "        \n",
    "    prompt_templates = [\n",
    "        f\"Doc string: {doc}\\n\"\n",
    "        f\"Code snippet: {code_snippet}\\n\"\n",
    "        \"Instruction: Provide a concise explanation of what the above doc and code mean. \"\n",
    "        \"Generate strictly less than 100 words in total.\\n\"\n",
    "        \"Answer: \\n\"\n",
    "        # , \n",
    "\n",
    "        # f\"Doc string: {doc}\\n\"\n",
    "        # f\"Code snippet: {code_snippet}\\n\"\n",
    "        # \"Instruction: Provide a detailed line-by-line explanation of this code snippet, describing the purpose and functionality of each statement, function, and control structure. \"\n",
    "        # \"Please give the output just as text only. Do not return anything else.\\n\"\n",
    "        # \"Answer: \\n\"\n",
    "        # ,\n",
    "\n",
    "        # f\"Doc string: {doc}\\n\"\n",
    "        # f\"Code snippet: {code_snippet}\\n\"\n",
    "        # \"Instruction: Summarize what this code snippet does in simple, non-technical language, focusing on its overall purpose and key operations for someone with little programming experience. \"\n",
    "        # \"Please give the output just as text only. Do not return anything else.\\n\"\n",
    "        # \"Answer: \\n\"\n",
    "        # ,\n",
    "\n",
    "        # f\"Doc string: {doc}\\n\"\n",
    "        # f\"Code snippet: {code_snippet}\\n\"\n",
    "        # \"Instruction: Generate an explanation of the code snippet in such a way that it can regenerate the code based on this explanation. \"\n",
    "        # \"Please give the output just as text only. Do not return anything else.\\n\"\n",
    "        # \"Answer: \\n\"\n",
    "    ]*3\n",
    "\n",
    "    for template in prompt_templates:\n",
    "        prompt = (\n",
    "            f\"Doc string: {doc}\\n\"\n",
    "            f\"Code snippet: {code_snippet}\\n\"\n",
    "            f\"{template}\\n\"\n",
    "            \"Answer: \\n\"\n",
    "        )\n",
    "        prompts.append(prompt)\n",
    "    sampling_params = SamplingParams(temperature=temperature, top_p=0.9, max_tokens=1000)\n",
    "    generated_exps = deepseek_vllm_generate_func(prompts, sampling_params)\n",
    "    return generated_exps\n",
    "   \n",
    "\n",
    "def deepseek_vllm_generate_func(prompts, sampling_params):\n",
    "    outputs = model_vllm.generate(prompts, sampling_params)\n",
    "    texts = []\n",
    "    for output in outputs:\n",
    "        prompt = output.prompt\n",
    "        generated_text = output.outputs[0].text\n",
    "        cleaned_text = generated_text.strip().replace(prompt, \"\").strip()\n",
    "        cleaned_text=clean_output(cleaned_text, \"<think>\")\n",
    "       # cleaned_text=clean_output(cleaned_text, \"Answer:\")\n",
    "        texts.append(cleaned_text)\n",
    "        print(f\"Generated text: {cleaned_text!r}\")\n",
    "        \n",
    "    return texts\n",
    "    \n",
    "# Forward Pass: Code → 3 Natural Language Descriptions\n",
    "def explanation_to_code_vllm(description, temperature = 0.8):\n",
    "    \"\"\"\n",
    "    Generates Python code from a cleaned natural language description.\n",
    "    \"\"\"\n",
    "    prompts = [(\n",
    "        \"Write only the Python function corresponding to the following description. \"\n",
    "        \"Do not provide explanations, comments, markdown, parameter descriptions, or return values. \"\n",
    "        \"Ensure that the function name and structure exactly match the description.\\n\\n\"\n",
    "        f\"Description:\\n{description}\\n\\nPython Code:\\n\"\n",
    "    )]\n",
    "    sampling_params = SamplingParams(temperature=temperature, top_p=0.9, max_tokens=1000)\n",
    "    generated_codes = deepseek_vllm_generate_func(prompts, sampling_params)\n",
    "    \n",
    "    return generated_codes\n",
    " \n",
    "def clean_output(text,keyword):\n",
    "    # keyword = \"Answer:\"\n",
    "    index = text.rfind(keyword) \n",
    "    if index != -1:\n",
    "        return text[index + len(keyword):].strip()  \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing Code for Better Comparison\n",
    "def normalize_code(code):\n",
    "    \"\"\"\n",
    "    Normalize Python code by parsing it into an AST and standardizing the format.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return ast.dump(ast.parse(code))\n",
    "    except SyntaxError:\n",
    "        return None\n",
    "\n",
    "# Compute Correct Generation Count\n",
    "def correct_generation(sim_scores):\n",
    "    return sum(1 for score in sim_scores if score > 0.7)\n",
    "\n",
    "# Evaluate Metrics\n",
    "def evaluate_metrics(original_code, generated_code):\n",
    "    \"\"\"\n",
    "    Evaluates RTC correctness using similarity metrics.\n",
    "    \"\"\"\n",
    "    exact_match = original_code.strip() == generated_code.strip()\n",
    "    similarity = code_bert_score_func(original_code, generated_code)\n",
    "    \n",
    "    return exact_match, similarity\n",
    "\n",
    "# Pass@1 Computation\n",
    "def pass_at_1(n: int, c: int, k: int) -> float:\n",
    "    if n - c < k:\n",
    "        return 1.0\n",
    "    return 1.0 - np.prod(1.0 - k / np.arange(n - c + 1, n + 1))\n",
    "\n",
    "# CodeBERT Similarity Score\n",
    "def code_bert_score_func(x: str, x_hat: str) -> float:\n",
    "    P, R, F1, _ = code_bert_score.score(cands=[x_hat], refs=[x], lang='python')\n",
    "    return F1.mean().item()\n",
    "\n",
    "# CodeBLEU Similarity Score\n",
    "def codebleu_func(x: str, x_hat: str) -> float:\n",
    "    return calc_codebleu([x], [x_hat], lang=\"python\", weights=(0.25, 0.25, 0.25, 0.25), tokenizer=None)\n",
    "\n",
    "# Compute RTC\n",
    "def compute_rtc(sim_scores):\n",
    "    if not sim_scores:\n",
    "        return 0.0\n",
    "    return sum(sim_scores) / len(sim_scores)\n",
    "\n",
    "# Compute LPass\n",
    "def evaluate_lpass(codes, original_code):\n",
    "    return 1 if any(code_bert_score_func(original_code, code) > 0.75 for code in codes) else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepSeek Single Explanation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s, est. speed input: 198.81 toks/s, output: 176.43 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: 'This doc and code are meant to write a boolean value to a stream. The code checks if the input n is False. If it is, it sets t to TRUE and writes it. If n is True, t remains FALSE and is written. This ensures that the boolean value is accurately recorded.\\n</think>\\n\\nThis doc and code are meant to write a boolean value to a stream. The code checks if the input n is False. If it is, it sets t to TRUE and writes it. If n is True, t remains FALSE and is written. This ensures the boolean value is accurately recorded.'\n",
      "Generated text: \"This doc and code explain how to write a boolean value (1) to a stream.\\nThe code creates a boolean variable, checks its value, and determines whether to write the corresponding boolean type (false or true) to the stream.\\nThe instructions specify that the explanation must be concise, under 100 words, and cover both the docstring and code snippet.\\n</think>\\n\\nTo explain the docstring and code snippet, they demonstrate a method to write a boolean value (1) to a stream. The code creates a boolean value, checks its value, and writes the appropriate boolean type to the stream.\\n\\nExplanation: The code creates a boolean value, checks if it's False or True, and writes the corresponding boolean type to the stream.\"\n",
      "Generated text: 'The doc and code aim to write a boolean value of 1 to the stream. The code checks if the input is False, then sets t to TRUE, else sets it to FALSE, and writes it to the stream.\\n</think>\\n\\nThe doc and code aim to write a boolean value of 1 to the stream. The code checks if the input is False, then sets t to TRUE, else sets it to FALSE, and writes it to the stream.\\n\\nThe doc and code aim to write a boolean value of 1 to the stream. The code checks if the input is False, then sets t to TRUE, else sets it to FALSE, and writes it to the stream.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, est. speed input: 781.26 toks/s, output: 164.71 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: '```\\nt = False\\nif n:\\n    t = True\\n    with open(\\'stream\\', \\'w\\') as f:\\n        f.write(f\"{t}\")\\n```'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s, est. speed input: 1010.96 toks/s, output: 151.11 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: \"```python\\ndef write_boolean_to_stream(value):\\n    if value:\\n        return 'True'\\n    else:\\n        return 'False'\\n```\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s, est. speed input: 679.44 toks/s, output: 164.25 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: '```python\\nimport os\\n\\ndef write_to_stream(input_value):\\n    if input_value is False:\\n        t = True\\n    else:\\n        t = False\\n    os.write(os.devnull, t)\\n```'\n"
     ]
    }
   ],
   "source": [
    "input_csv = \"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/data/deepseek_single_exp_split/split_part_0.csv\"\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Select Only First Row\n",
    "row = df.iloc[0]  # Only one row is selected\n",
    "results = []\n",
    "original_code = str(row[\"code\"]).strip()\n",
    "doc = str(row[\"doc\"]).strip()\n",
    "\n",
    "codes, sim_scores, matches = [], [], []\n",
    "\n",
    "explanations = code_to_explanations_vllm(doc, original_code)\n",
    "for explanation in explanations:\n",
    "    generated_code = explanation_to_code_vllm(explanation)[0]\n",
    "    exact_match, similarity_score = evaluate_metrics(original_code, generated_code)\n",
    "\n",
    "    codes.append(generated_code)\n",
    "    sim_scores.append(similarity_score)\n",
    "    matches.append(exact_match)\n",
    "\n",
    "true_count = correct_generation(sim_scores)\n",
    "final_rtcpass = compute_rtc(sim_scores)\n",
    "pass_score = pass_at_1(3, true_count, 1)\n",
    "\n",
    "results.append({\n",
    "    \"Original Code\": original_code,\n",
    "    \"Generated Code1\": codes[0],\n",
    "    \"Generated Code2\": codes[1],\n",
    "    \"Generated Code3\": codes[2],\n",
    "    \"Explanation1\": explanations[0],\n",
    "    \"Explanation2\": explanations[1],\n",
    "    \"Explanation3\": explanations[2],\n",
    "    \"Exact Match\": matches,\n",
    "    \"CodeBERTScore\": sim_scores,\n",
    "    \"RTCPass\": final_rtcpass,\n",
    "    \"Pass@1\": pass_score\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Original Code': 'def writeBoolean(self, n):\\n        \"\"\"\\n        Writes a Boolean to the stream.\\n        \"\"\"\\n        t = TYPE_BOOL_TRUE\\n\\n        if n is False:\\n            t = TYPE_BOOL_FALSE\\n\\n        self.stream.write(t)',\n",
       "  'Generated Code1': '```\\nt = False\\nif n:\\n    t = True\\n    with open(\\'stream\\', \\'w\\') as f:\\n        f.write(f\"{t}\")\\n```',\n",
       "  'Generated Code2': \"```python\\ndef write_boolean_to_stream(value):\\n    if value:\\n        return 'True'\\n    else:\\n        return 'False'\\n```\",\n",
       "  'Generated Code3': '```python\\nimport os\\n\\ndef write_to_stream(input_value):\\n    if input_value is False:\\n        t = True\\n    else:\\n        t = False\\n    os.write(os.devnull, t)\\n```',\n",
       "  'Explanation1': 'This doc and code are meant to write a boolean value to a stream. The code checks if the input n is False. If it is, it sets t to TRUE and writes it. If n is True, t remains FALSE and is written. This ensures that the boolean value is accurately recorded.\\n</think>\\n\\nThis doc and code are meant to write a boolean value to a stream. The code checks if the input n is False. If it is, it sets t to TRUE and writes it. If n is True, t remains FALSE and is written. This ensures the boolean value is accurately recorded.',\n",
       "  'Explanation2': \"This doc and code explain how to write a boolean value (1) to a stream.\\nThe code creates a boolean variable, checks its value, and determines whether to write the corresponding boolean type (false or true) to the stream.\\nThe instructions specify that the explanation must be concise, under 100 words, and cover both the docstring and code snippet.\\n</think>\\n\\nTo explain the docstring and code snippet, they demonstrate a method to write a boolean value (1) to a stream. The code creates a boolean value, checks its value, and writes the appropriate boolean type to the stream.\\n\\nExplanation: The code creates a boolean value, checks if it's False or True, and writes the corresponding boolean type to the stream.\",\n",
       "  'Explanation3': 'The doc and code aim to write a boolean value of 1 to the stream. The code checks if the input is False, then sets t to TRUE, else sets it to FALSE, and writes it to the stream.\\n</think>\\n\\nThe doc and code aim to write a boolean value of 1 to the stream. The code checks if the input is False, then sets t to TRUE, else sets it to FALSE, and writes it to the stream.\\n\\nThe doc and code aim to write a boolean value of 1 to the stream. The code checks if the input is False, then sets t to TRUE, else sets it to FALSE, and writes it to the stream.',\n",
       "  'Exact Match': [False, False, False],\n",
       "  'CodeBERTScore': [0.7424090504646301, 0.7764660716056824, 0.7641641497612],\n",
       "  'RTCPass': 0.7610130906105042,\n",
       "  'Pass@1': 1.0}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Explanations Sample Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 03-19 04:11:16 arg_utils.py:900] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\n",
      "INFO 03-19 04:11:16 config.py:1013] Chunked prefill is enabled with max_num_batched_tokens=512.\n",
      "INFO 03-19 04:11:16 llm_engine.py:223] Initializing an LLM engine (v0.6.1.post1) with config: model='/datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa', speculative_config=None, tokenizer='/datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)\n",
      "INFO 03-19 04:11:17 selector.py:259] Cannot use FlashAttention-2 backend because the vllm_flash_attn package is not found. `pip install vllm-flash-attn` for better performance.\n",
      "INFO 03-19 04:11:17 selector.py:116] Using XFormers backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_wenlongzhao_umass_edu/27/.venv/lib/python3.12/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/work/pi_wenlongzhao_umass_edu/27/.venv/lib/python3.12/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-19 04:11:17 model_runner.py:997] Starting to load model /datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa...\n",
      "INFO 03-19 04:11:17 selector.py:259] Cannot use FlashAttention-2 backend because the vllm_flash_attn package is not found. `pip install vllm-flash-attn` for better performance.\n",
      "INFO 03-19 04:11:17 selector.py:116] Using XFormers backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498c9ecd8c374f938bb7aed4dc322e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-19 04:11:18 model_runner.py:1008] Loading model weights took 3.3460 GB\n",
      "INFO 03-19 04:11:18 gpu_executor.py:122] # GPU blocks: 81535, # CPU blocks: 9362\n",
      "INFO 03-19 04:11:21 model_runner.py:1309] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 03-19 04:11:21 model_runner.py:1313] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 03-19 04:11:32 model_runner.py:1428] Graph capturing finished in 11 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, est. speed input: 229.09 toks/s, output: 63.36 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.02s/it, est. speed input: 90.54 toks/s, output: 166.13 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s, est. speed input: 2392.83 toks/s, output: 155.77 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s, est. speed input: 1497.02 toks/s, output: 160.26 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:11:43,410 - INFO - Processed row 0 for model deepseek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.82it/s, est. speed input: 185.84 toks/s, output: 169.44 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, est. speed input: 1734.01 toks/s, output: 155.61 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, est. speed input: 208.75 toks/s, output: 130.47 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, est. speed input: 738.56 toks/s, output: 163.93 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:11:47,163 - INFO - Processed row 1 for model deepseek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s, est. speed input: 278.13 toks/s, output: 166.87 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s, est. speed input: 585.52 toks/s, output: 165.67 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, est. speed input: 150.80 toks/s, output: 170.47 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.04s/it, est. speed input: 90.44 toks/s, output: 165.63 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:11:56,462 - INFO - Processed row 2 for model deepseek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s, est. speed input: 1076.45 toks/s, output: 158.29 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.58s/it, est. speed input: 152.57 toks/s, output: 165.98 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 10.40it/s, est. speed input: 1354.67 toks/s, output: 156.29 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, est. speed input: 1752.38 toks/s, output: 158.82 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:12:02,206 - INFO - Processed row 3 for model deepseek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.93it/s, est. speed input: 307.72 toks/s, output: 168.37 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s, est. speed input: 1065.02 toks/s, output: 162.46 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.52it/s, est. speed input: 333.36 toks/s, output: 169.20 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.02s/it, est. speed input: 90.53 toks/s, output: 166.11 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:12:11,057 - INFO - Processed row 4 for model deepseek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  8.20it/s, est. speed input: 786.53 toks/s, output: 157.29 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it, est. speed input: 417.06 toks/s, output: 164.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s, est. speed input: 940.74 toks/s, output: 162.35 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00, 17.90it/s, est. speed input: 2084.03 toks/s, output: 143.70 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:12:15,431 - INFO - Processed row 5 for model deepseek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s, est. speed input: 234.75 toks/s, output: 167.95 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, est. speed input: 504.73 toks/s, output: 164.90 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, est. speed input: 117.53 toks/s, output: 170.75 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:06<00:00,  6.01s/it, est. speed input: 90.85 toks/s, output: 166.40 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:12:25,462 - INFO - Processed row 6 for model deepseek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s, est. speed input: 556.34 toks/s, output: 163.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, est. speed input: 606.34 toks/s, output: 163.24 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s, est. speed input: 1417.82 toks/s, output: 158.40 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s, est. speed input: 644.39 toks/s, output: 165.90 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:12:32,052 - INFO - Processed row 7 for model deepseek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s, est. speed input: 743.64 toks/s, output: 157.73 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.71it/s, est. speed input: 1482.80 toks/s, output: 157.51 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 127.41 toks/s, output: 170.68 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s, est. speed input: 749.65 toks/s, output: 165.73 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:12:35,439 - INFO - Processed row 8 for model deepseek\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, est. speed input: 441.49 toks/s, output: 163.83 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s, est. speed input: 1374.33 toks/s, output: 158.57 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, est. speed input: 523.53 toks/s, output: 166.29 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, est. speed input: 617.51 toks/s, output: 165.01 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:12:38,789 - INFO - Processed row 9 for model deepseek\n",
      "INFO 03-19 04:12:38 llm_engine.py:223] Initializing an LLM engine (v0.6.1.post1) with config: model='/datasets/ai/ibm-granite/hub/models--ibm-granite--granite-3.0-2b-instruct/snapshots/69e41fe735f54cec1792de2ac4f124b6cc84638f', speculative_config=None, tokenizer='/datasets/ai/ibm-granite/hub/models--ibm-granite--granite-3.0-2b-instruct/snapshots/69e41fe735f54cec1792de2ac4f124b6cc84638f', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/datasets/ai/ibm-granite/hub/models--ibm-granite--granite-3.0-2b-instruct/snapshots/69e41fe735f54cec1792de2ac4f124b6cc84638f, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)\n",
      "INFO 03-19 04:12:39 selector.py:259] Cannot use FlashAttention-2 backend because the vllm_flash_attn package is not found. `pip install vllm-flash-attn` for better performance.\n",
      "INFO 03-19 04:12:39 selector.py:116] Using XFormers backend.\n",
      "INFO 03-19 04:12:39 model_runner.py:997] Starting to load model /datasets/ai/ibm-granite/hub/models--ibm-granite--granite-3.0-2b-instruct/snapshots/69e41fe735f54cec1792de2ac4f124b6cc84638f...\n",
      "INFO 03-19 04:12:39 selector.py:259] Cannot use FlashAttention-2 backend because the vllm_flash_attn package is not found. `pip install vllm-flash-attn` for better performance.\n",
      "INFO 03-19 04:12:39 selector.py:116] Using XFormers backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f8f10abff94f9385ccae9652562e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-19 04:12:40 model_runner.py:1008] Loading model weights took 4.7198 GB\n",
      "INFO 03-19 04:12:41 gpu_executor.py:122] # GPU blocks: 28367, # CPU blocks: 3276\n",
      "INFO 03-19 04:12:41 model_runner.py:1309] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 03-19 04:12:41 model_runner.py:1313] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 03-19 04:12:53 model_runner.py:1428] Graph capturing finished in 11 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.78s/it, est. speed input: 24.85 toks/s, output: 102.26 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it, est. speed input: 394.73 toks/s, output: 91.53 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.06s/it, est. speed input: 49.65 toks/s, output: 104.52 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.03s/it, est. speed input: 108.11 toks/s, output: 103.15 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:13:12,184 - INFO - Processed row 0 for model granite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.51s/it, est. speed input: 71.07 toks/s, output: 97.82 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s, est. speed input: 426.30 toks/s, output: 99.23 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.71s/it, est. speed input: 91.93 toks/s, output: 103.64 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, est. speed input: 385.97 toks/s, output: 102.33 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:13:20,020 - INFO - Processed row 1 for model granite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s, est. speed input: 143.67 toks/s, output: 104.21 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it, est. speed input: 494.86 toks/s, output: 101.20 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it, est. speed input: 69.86 toks/s, output: 104.55 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.23s/it, est. speed input: 439.66 toks/s, output: 101.40 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:13:26,843 - INFO - Processed row 2 for model granite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.50s/it, est. speed input: 40.87 toks/s, output: 104.32 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s, est. speed input: 1086.49 toks/s, output: 98.39 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.58s/it, est. speed input: 36.48 toks/s, output: 98.96 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, est. speed input: 518.83 toks/s, output: 101.70 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:13:37,038 - INFO - Processed row 3 for model granite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.02s/it, est. speed input: 63.56 toks/s, output: 103.62 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.44s/it, est. speed input: 89.74 toks/s, output: 102.82 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it, est. speed input: 95.03 toks/s, output: 104.17 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it, est. speed input: 219.31 toks/s, output: 102.89 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:13:50,491 - INFO - Processed row 4 for model granite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.46s/it, est. speed input: 52.77 toks/s, output: 104.73 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.81s/it, est. speed input: 276.32 toks/s, output: 102.24 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.76s/it, est. speed input: 135.10 toks/s, output: 103.18 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  2.04it/s, est. speed input: 810.83 toks/s, output: 100.08 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:13:58,611 - INFO - Processed row 5 for model granite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:09<00:00,  9.64s/it, est. speed input: 17.13 toks/s, output: 103.79 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it, est. speed input: 260.33 toks/s, output: 102.34 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.90s/it, est. speed input: 65.32 toks/s, output: 104.83 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.47s/it, est. speed input: 294.81 toks/s, output: 102.36 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:14:15,189 - INFO - Processed row 6 for model granite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.20s/it, est. speed input: 53.39 toks/s, output: 104.27 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:03<00:00,  3.99s/it, est. speed input: 125.33 toks/s, output: 103.02 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it, est. speed input: 151.14 toks/s, output: 103.44 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.08s/it, est. speed input: 83.81 toks/s, output: 103.42 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:14:30,049 - INFO - Processed row 7 for model granite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 196.32 toks/s, output: 103.58 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it, est. speed input: 313.50 toks/s, output: 102.34 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.95s/it, est. speed input: 59.66 toks/s, output: 104.92 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, est. speed input: 283.65 toks/s, output: 103.15 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:14:36,521 - INFO - Processed row 8 for model granite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.87s/it, est. speed input: 110.74 toks/s, output: 103.43 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.37s/it, est. speed input: 375.34 toks/s, output: 101.70 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.06s/it, est. speed input: 87.95 toks/s, output: 104.46 toks/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it, est. speed input: 202.27 toks/s, output: 102.05 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 04:14:45,881 - INFO - Processed row 9 for model granite\n",
      "2025-03-19 04:14:45,891 - INFO - Writing combined results to CSV\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from vllm import LLM, SamplingParams\n",
    "import code_bert_score\n",
    "import gc\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    level=logging.INFO\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "class VLLMEvaluation:\n",
    "    def __init__(self, model_path, model_type):\n",
    "        self.device = self.setup_cuda()\n",
    "        self.model = self.load_model(model_path)\n",
    "        self.model_type = model_type\n",
    "        self.sampling_params = SamplingParams(temperature=0.8, top_p=0.9, max_tokens=1000)\n",
    "    \n",
    "    def setup_cuda(self):\n",
    "        return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        return LLM(model=model_path, dtype=\"bfloat16\", device=\"cuda\", enforce_eager=False)\n",
    "\n",
    "    def generate_text(self, prompts):\n",
    "        texts = []\n",
    "        for prompt in prompts:\n",
    "            output = self.model.generate([prompt], self.sampling_params)[0]\n",
    "            texts.append(self.clean_output(output.outputs[0].text.strip(), \"<think>\"))\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.ipc_collect()\n",
    "        return texts\n",
    "\n",
    "    def clean_output(self, text, keyword):\n",
    "        index = text.rfind(keyword)\n",
    "        return text[index + len(keyword):].strip() if index != -1 else text\n",
    "\n",
    "    def explanation_to_code(self, description):\n",
    "        prompt = (\n",
    "            \"Write only the Python function corresponding to the following description. \"\n",
    "            \"Do not provide explanations, comments, markdown, parameter descriptions, or return values. \"\n",
    "            \"Ensure that the function name and structure exactly match the description.\\n\\n\"\n",
    "            f\"Description:\\n{description}\\n\\nPython Code:\\n\"\n",
    "        )\n",
    "        return self.generate_text([prompt])[0]\n",
    "\n",
    "    def compute_similarity(self, original_code, generated_code):\n",
    "        P, R, F1, _ = code_bert_score.score(cands=[generated_code], refs=[original_code], lang='python')\n",
    "        return F1.mean().item()\n",
    "\n",
    "    def evaluate_generated_code(self, original_code, generated_code):\n",
    "        exact_match = original_code.strip() == generated_code.strip()\n",
    "        similarity = self.compute_similarity(original_code, generated_code)\n",
    "        return exact_match, similarity\n",
    "\n",
    "    def compute_rtc(self, sim_scores):\n",
    "        return sum(sim_scores) / len(sim_scores) if sim_scores else 0.0\n",
    "\n",
    "    def pass_at_1(self, n, c, k):\n",
    "        return 1.0 if n - c < k else 1.0 - np.prod(1.0 - k / np.arange(n - c + 1, n + 1))\n",
    "\n",
    "    def process_data(self, df):\n",
    "        results = []\n",
    "        for iter, row in df.iterrows():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.ipc_collect()\n",
    "            gc.collect()\n",
    "\n",
    "            original_code = str(row[\"code\"]).strip()\n",
    "            doc = str(row[\"doc\"]).strip()\n",
    "            explanations = [row[f\"explanation_{self.model_type}_{i+1}\"] for i in range(4)]\n",
    "\n",
    "            codes, sim_scores, matches = [], [], []\n",
    "            for explanation in explanations:\n",
    "                generated_code = self.explanation_to_code(explanation)\n",
    "                exact_match, similarity_score = self.evaluate_generated_code(original_code, generated_code)\n",
    "                \n",
    "                codes.append(generated_code)\n",
    "                sim_scores.append(similarity_score)\n",
    "                matches.append(exact_match)\n",
    "\n",
    "            true_count = sum(1 for score in sim_scores if score > 0.7)\n",
    "            final_rtcpass = self.compute_rtc(sim_scores)\n",
    "            pass_score = self.pass_at_1(8, true_count, 1)\n",
    "\n",
    "            results.append({\n",
    "                \"Original Code\": original_code,\n",
    "                \"doc\": doc,\n",
    "                **{f\"Exp_{self.model_type}{i+1}\": explanations[i] for i in range(4)},\n",
    "                **{f\"Generated Code_{self.model_type}{i+1}\": codes[i] for i in range(4)},\n",
    "                f\"Exact Match_{self.model_type}\": matches,\n",
    "                f\"CodeBERTScore_{self.model_type}\": sim_scores,\n",
    "                f\"RTCPass_{self.model_type}\": final_rtcpass,\n",
    "                f\"Pass@1_{self.model_type}\": pass_score\n",
    "            })\n",
    "\n",
    "            logger.info(f\"Processed row {iter} for model {self.model_type}\")\n",
    "        return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    deepseek_model_path = \"/datasets/ai/deepseek/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/530ca3e1ad39d440e182c2e4317aa40f012512fa\"\n",
    "    granite_model_path = \"/datasets/ai/ibm-granite/hub/models--ibm-granite--granite-3.0-2b-instruct/snapshots/69e41fe735f54cec1792de2ac4f124b6cc84638f\"\n",
    "    \n",
    "    input_csv = \"/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CoSQA_explanations_vllm.csv\"\n",
    "    output_csv = \"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/results/exps_sample.csv\"\n",
    "    \n",
    "    \n",
    "    evaluator_deepseek = VLLMEvaluation(deepseek_model_path, \"deepseek\")\n",
    "    df = pd.read_csv(input_csv).iloc[:10]\n",
    "    deepseek_results = evaluator_deepseek.process_data(df)\n",
    "    del evaluator_deepseek\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    \n",
    "    evaluator_granite = VLLMEvaluation(granite_model_path, \"granite\")\n",
    "    granite_results = evaluator_granite.process_data(df)\n",
    "    del evaluator_granite\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    \n",
    "    combined_results = []\n",
    "    for d, g in zip(deepseek_results, granite_results):\n",
    "        combined_results.append({**d, **g})\n",
    "    \n",
    "    logger.info(\"Writing combined results to CSV\")\n",
    "    pd.DataFrame(combined_results).to_csv(output_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                                   0\n",
       "Generated_Code_deepseek_1    ```python\\ndef flip_stream(n):\\n    current_va...\n",
       "Generated_Code_deepseek_2    def writeBoolean(self, n: int) -> None:\\n    i...\n",
       "Generated_Code_deepseek_3    ```python\\ndef writeBoolean(n):\\n    t = TYPE_...\n",
       "Generated_Code_deepseek_4    The Python function is named writeBoolean and ...\n",
       "Original_Code                def writeBoolean(self, n):\\n        \"\"\"\\n     ...\n",
       "corpus_id                                                                   d1\n",
       "query_id                                                                    q1\n",
       "Generated_Code_granite_1     ```python\\ndef writeBoolean(self, n):\\n    \"\"\"...\n",
       "Generated_Code_granite_2     ```python\\ndef writeBoolean(self, n):\\n    \"\"\"...\n",
       "Generated_Code_granite_3     ```python\\ndef write_bool(stream, n):\\n    t =...\n",
       "Generated_Code_granite_4     ```python\\ndef writeBoolean(self, n):\\n    \"\"\"...\n",
       "Sim_Code_deepseek_1                                                   0.673183\n",
       "Exact_Match_deepseek_1                                                   False\n",
       "Sim_Code_deepseek_2                                                   0.761766\n",
       "Exact_Match_deepseek_2                                                   False\n",
       "Sim_Code_deepseek_3                                                   0.891583\n",
       "Exact_Match_deepseek_3                                                   False\n",
       "Sim_Code_deepseek_4                                                   0.714208\n",
       "Exact_Match_deepseek_4                                                   False\n",
       "RTC_deepseek                                                          0.760185\n",
       "Pass@1_deepseek                                                           0.75\n",
       "Sim_Code_granite_1                                                    0.796146\n",
       "Exact_Match_granite_1                                                    False\n",
       "Sim_Code_granite_2                                                    0.710083\n",
       "Exact_Match_granite_2                                                    False\n",
       "Sim_Code_granite_3                                                    0.725649\n",
       "Exact_Match_granite_3                                                    False\n",
       "Sim_Code_granite_4                                                    0.879212\n",
       "Exact_Match_granite_4                                                    False\n",
       "RTC_granite                                                           0.777773\n",
       "Pass@1_granite                                                             1.0\n",
       "RTC_Common                                                            0.768979\n",
       "Pass@1_Common                                                            0.875\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "out=pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/results/exps_10_sample_result.csv\")\n",
    "out.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VLLM - Entire Dataset Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not Cleaned explanation and not cleaned generated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* Empty Strings/ NaN values ***********\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "corpus_id                    0\n",
       "query_id                     0\n",
       "Original_Code                0\n",
       "Generated_Code_deepseek_1    1\n",
       "Generated_Code_deepseek_2    0\n",
       "Generated_Code_deepseek_3    0\n",
       "Generated_Code_deepseek_4    0\n",
       "Generated_Code_granite_1     0\n",
       "Generated_Code_granite_2     0\n",
       "Generated_Code_granite_3     0\n",
       "Generated_Code_granite_4     0\n",
       "Sim_Code_deepseek_1          0\n",
       "Exact_Match_deepseek_1       0\n",
       "Sim_Code_deepseek_2          0\n",
       "Exact_Match_deepseek_2       0\n",
       "Sim_Code_deepseek_3          0\n",
       "Exact_Match_deepseek_3       0\n",
       "Sim_Code_deepseek_4          0\n",
       "Exact_Match_deepseek_4       0\n",
       "RTC_deepseek                 0\n",
       "Pass@1_deepseek              0\n",
       "Sim_Code_granite_1           0\n",
       "Exact_Match_granite_1        0\n",
       "Sim_Code_granite_2           0\n",
       "Exact_Match_granite_2        0\n",
       "Sim_Code_granite_3           0\n",
       "Exact_Match_granite_3        0\n",
       "Sim_Code_granite_4           0\n",
       "Exact_Match_granite_4        0\n",
       "RTC_granite                  0\n",
       "Pass@1_granite               0\n",
       "RTC_Common                   0\n",
       "Pass@1_Common                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "out=pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/results/exps_rtc_valid_result.csv\")\n",
    "\n",
    "print(\"********* Empty Strings/ NaN values ***********\")\n",
    "out.apply(lambda col: col.isna().sum() + (col == '').sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>Original_Code</th>\n",
       "      <th>Generated_Code_deepseek_1</th>\n",
       "      <th>Generated_Code_deepseek_2</th>\n",
       "      <th>Generated_Code_deepseek_3</th>\n",
       "      <th>Generated_Code_deepseek_4</th>\n",
       "      <th>Generated_Code_granite_1</th>\n",
       "      <th>Generated_Code_granite_2</th>\n",
       "      <th>Generated_Code_granite_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Sim_Code_granite_2</th>\n",
       "      <th>Exact_Match_granite_2</th>\n",
       "      <th>Sim_Code_granite_3</th>\n",
       "      <th>Exact_Match_granite_3</th>\n",
       "      <th>Sim_Code_granite_4</th>\n",
       "      <th>Exact_Match_granite_4</th>\n",
       "      <th>RTC_granite</th>\n",
       "      <th>Pass@1_granite</th>\n",
       "      <th>RTC_Common</th>\n",
       "      <th>Pass@1_Common</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16639</th>\n",
       "      <td>d16640</td>\n",
       "      <td>q16640</td>\n",
       "      <td>def flush(self):\\n        \"\"\"\\n        Flush a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Here is the code to follow:\\n\\n```python\\ndef ...</td>\n",
       "      <td>```python\\ndef flush_class_cache():\\n    \"\"\"Fl...</td>\n",
       "      <td>Write a Python function that represents the fl...</td>\n",
       "      <td>```python\\ndef flush(self):\\n    if self._cach...</td>\n",
       "      <td>```python\\ndef flush(self):\\n    \"\"\"\\n    This...</td>\n",
       "      <td>```python\\ndef flush(self):\\n    if self.chang...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912509</td>\n",
       "      <td>False</td>\n",
       "      <td>0.668658</td>\n",
       "      <td>False</td>\n",
       "      <td>0.915452</td>\n",
       "      <td>False</td>\n",
       "      <td>0.816064</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.74292</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      corpus_id query_id                                      Original_Code  \\\n",
       "16639    d16640   q16640  def flush(self):\\n        \"\"\"\\n        Flush a...   \n",
       "\n",
       "      Generated_Code_deepseek_1  \\\n",
       "16639                       NaN   \n",
       "\n",
       "                               Generated_Code_deepseek_2  \\\n",
       "16639  Here is the code to follow:\\n\\n```python\\ndef ...   \n",
       "\n",
       "                               Generated_Code_deepseek_3  \\\n",
       "16639  ```python\\ndef flush_class_cache():\\n    \"\"\"Fl...   \n",
       "\n",
       "                               Generated_Code_deepseek_4  \\\n",
       "16639  Write a Python function that represents the fl...   \n",
       "\n",
       "                                Generated_Code_granite_1  \\\n",
       "16639  ```python\\ndef flush(self):\\n    if self._cach...   \n",
       "\n",
       "                                Generated_Code_granite_2  \\\n",
       "16639  ```python\\ndef flush(self):\\n    \"\"\"\\n    This...   \n",
       "\n",
       "                                Generated_Code_granite_3  ...  \\\n",
       "16639  ```python\\ndef flush(self):\\n    if self.chang...  ...   \n",
       "\n",
       "      Sim_Code_granite_2  Exact_Match_granite_2  Sim_Code_granite_3  \\\n",
       "16639           0.912509                  False            0.668658   \n",
       "\n",
       "       Exact_Match_granite_3  Sim_Code_granite_4  Exact_Match_granite_4  \\\n",
       "16639                  False            0.915452                  False   \n",
       "\n",
       "       RTC_granite  Pass@1_granite  RTC_Common  Pass@1_Common  \n",
       "16639     0.816064            0.75     0.74292          0.625  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>code</th>\n",
       "      <th>explanation_deepseek_1</th>\n",
       "      <th>explanation_deepseek_2</th>\n",
       "      <th>explanation_deepseek_3</th>\n",
       "      <th>explanation_deepseek_4</th>\n",
       "      <th>explanation_granite_1</th>\n",
       "      <th>explanation_granite_2</th>\n",
       "      <th>explanation_granite_3</th>\n",
       "      <th>explanation_granite_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16639</th>\n",
       "      <td>q16640</td>\n",
       "      <td>python flush request cache</td>\n",
       "      <td>d16640</td>\n",
       "      <td>def flush(self):\\n        \"\"\"\\n        Flush a...</td>\n",
       "      <td>The doc and code flush the request cache, remo...</td>\n",
       "      <td>Here is the step-by-step explanation of the co...</td>\n",
       "      <td>The code is trying to flush the cache in a cla...</td>\n",
       "      <td>The code is a method in a class that takes sel...</td>\n",
       "      <td>\\nThe provided code and docstring are for a Py...</td>\n",
       "      <td>\\nThis code snippet defines a method named `fl...</td>\n",
       "      <td>\\nThis code snippet is for a class that handle...</td>\n",
       "      <td>\\nThe provided code snippet is a method named ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      query_id                         doc corpus_id  \\\n",
       "16639   q16640  python flush request cache    d16640   \n",
       "\n",
       "                                                    code  \\\n",
       "16639  def flush(self):\\n        \"\"\"\\n        Flush a...   \n",
       "\n",
       "                                  explanation_deepseek_1  \\\n",
       "16639  The doc and code flush the request cache, remo...   \n",
       "\n",
       "                                  explanation_deepseek_2  \\\n",
       "16639  Here is the step-by-step explanation of the co...   \n",
       "\n",
       "                                  explanation_deepseek_3  \\\n",
       "16639  The code is trying to flush the cache in a cla...   \n",
       "\n",
       "                                  explanation_deepseek_4  \\\n",
       "16639  The code is a method in a class that takes sel...   \n",
       "\n",
       "                                   explanation_granite_1  \\\n",
       "16639  \\nThe provided code and docstring are for a Py...   \n",
       "\n",
       "                                   explanation_granite_2  \\\n",
       "16639  \\nThis code snippet defines a method named `fl...   \n",
       "\n",
       "                                   explanation_granite_3  \\\n",
       "16639  \\nThis code snippet is for a class that handle...   \n",
       "\n",
       "                                   explanation_granite_4  \n",
       "16639  \\nThe provided code snippet is a method named ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputdf = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CoSQA_explanations_vllm1.csv\")\n",
    "from IPython.display import display\n",
    "\n",
    "display(out[out['Generated_Code_deepseek_1'].isna() | (out['Generated_Code_deepseek_1'] == '')])\n",
    "display(inputdf[(inputdf[\"corpus_id\"] == \"d16640\") & (inputdf[\"query_id\"] == \"q16640\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Original Code ***************** \n",
      " def create_path(path):\n",
      "    \"\"\"Creates a absolute path in the file system.\n",
      "\n",
      "    :param path: The path to be created\n",
      "    \"\"\"\n",
      "    import os\n",
      "    if not os.path.exists(path):\n",
      "        os.makedirs(path)\n",
      "*************** Generated_Code_deepseek_2 ***************** \n",
      " import os\n",
      "\n",
      "def create_path(path):\n",
      "    if not os.path.exists(path):\n",
      "        return os.path.abspath(os.path.join(path, os.path.dirname(os.path.abspath(__file__))))\n",
      "    return path\n",
      "\n",
      "Wait, no. If the path is relative, then the absolute path would be current_dir + path. So, if the current directory is 'src' and the path is 'file.txt', the absolute path is 'src/file.txt'. If the path is already absolute, like 'output', it should return 'output' without changing it.\n",
      "\n",
      "So, the function should check if the given path is absolute. If it is, return it. Otherwise, create the absolute path by joining with the current directory.\n",
      "\n",
      "But how to check if the path is absolute? Using os.path.abspath or os.path.isabs. For example:\n",
      "\n",
      "if os.path.isabs(path):\n",
      "    return path\n",
      "else:\n",
      "    return os.path.abspath(os.path.join(path, os.path.dirname(os.path.abspath(__file__))))\n",
      "\n",
      "But wait, in the function, the path is given. So, let's think about how to construct the absolute path.\n",
      "\n",
      "An alternative way is to use os.path.abspath(__file__) to get the current directory, then use os.path.join with the given path and the directory.\n",
      "\n",
      "Wait, no. If the path is relative to the current directory, then joining with the current directory gives the absolute path.\n",
      "\n",
      "So, the correct way is:\n",
      "\n",
      "if the given path is a relative path, then the absolute path is current_dir + path.\n",
      "\n",
      "But if the path is already absolute, then we don't need to change it.\n",
      "\n",
      "So, in code:\n",
      "\n",
      "import os\n",
      "\n",
      "def create_path(path):\n",
      "    if not os.path.exists(path):\n",
      "        # Check if the path is relative or absolute\n",
      "        if os.path.isabs(path):\n",
      "            return path\n",
      "        else:\n",
      "            # It's a relative path; join with the current directory\n",
      "            return os.path.abspath(os.path.join(path, os.path.dirname(os.path.abspath(__file__))))\n",
      "    return path\n",
      "\n",
      "Wait, but __file__ might not be the current directory. So, perhaps it's better to get the current directory and then join.\n",
      "\n",
      "Let me write a more precise code.\n",
      "\n",
      "First, get the current directory using os.path.abspath(__file__), but that's not necessary. Alternatively, I can construct the absolute path by joining the given path with the current directory.\n",
      "\n",
      "But wait, how do I know what the current directory is? Because if the function is called in a different directory, the current directory might not be the same.\n",
      "\n",
      "Alternatively, we can assume that the current directory is the one in which the function is being executed. So, the absolute path can be constructed by joining the given path with the current directory.\n",
      "\n",
      "So, code:\n",
      "\n",
      "import os\n",
      "\n",
      "def create_path(path):\n",
      "    if not os.path.exists(path):\n",
      "        # Check if the path is absolute\n",
      "        if os.path.isabs(path):\n",
      "            return path\n",
      "        else:\n",
      "            # It's a relative path; create the absolute path by joining\n",
      "            return os.path.abspath(os.path.join(path, os.path.dirname(os.path.abspath(os.path(__file__))))))\n",
      "    return path\n",
      "\n",
      "Wait, but that's redundant. Because os.path.abspath(__file__) gives the absolute path of the current file. So, joining with the dirname of that would give the absolute path of the directory containing that file.\n",
      "\n",
      "But in this case, if the given path is relative, like 'file.txt' in the current directory, then the absolute path is 'current/directory/file.txt'. But if the given path is 'file.txt' in a different directory, then the function will create 'another/directory/file.txt', which is correct.\n",
      "\n",
      "Wait, no. Let me test with an example.\n",
      "\n",
      "Suppose the current directory is 'src' and the given path is 'file.txt'.\n",
      "\n",
      "In the function:\n",
      "\n",
      "os.path.abspath(__file__) is the absolute path of the current file, which is 'src'.\n",
      "\n",
      "os.path.dirname(__file__) is the directory of the current file, which is 'src'.\n",
      "\n",
      "So, os.path.join('file.txt', 'src') is 'src/file.txt'.\n",
      "\n",
      "So, the function would return 'src/file.txt' when given 'file.txt', which is correct.\n",
      "\n",
      "Another example: given path is 'output'.\n",
      "\n",
      "os.path.isabs('output') is False, so it joins 'output' with the current directory.\n",
      "\n",
      "So, correct.\n",
      "\n",
      "Another test: given path is 'C:\\\\path\\\\to\\\\file.txt'.\n",
      "\n",
      "os.path.isabs('C:\\\\path\\\\to\\\\file.txt') is True, so function returns it as is.\n",
      "\n",
      "So, the code seems to handle that.\n",
      "\n",
      "Now, what about if the given path is a directory that doesn't exist? For example, if the function is called with 'not_existent', and the directory doesn't exist.\n",
      "\n",
      "In that case, the function will attempt to create the absolute path, which will fail. But that's an expected behavior\n",
      "*************** Similarity Score ***************** \n",
      " 0.7033584117889404\n"
     ]
    }
   ],
   "source": [
    "print(\"*************** Original Code ***************** \\n\",out.iloc[3][\"Original_Code\"])\n",
    "print(\"*************** Generated_Code_deepseek_2 ***************** \\n\",out.iloc[3][\"Generated_Code_deepseek_2\"])\n",
    "print(\"*************** Similarity Score ***************** \\n\",out.iloc[3][\"Sim_Code_deepseek_2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Original Code ***************** \n",
      " def writeBoolean(self, n):\n",
      "        \"\"\"\n",
      "        Writes a Boolean to the stream.\n",
      "        \"\"\"\n",
      "        t = TYPE_BOOL_TRUE\n",
      "\n",
      "        if n is False:\n",
      "            t = TYPE_BOOL_FALSE\n",
      "\n",
      "        self.stream.write(t)\n",
      "*************** Generated_Code_granite_2 ***************** \n",
      " ```python\n",
      "def writeBoolean(self, n):\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "*************** Similarity Score ***************** \n",
      " 0.8926896452903748\n"
     ]
    }
   ],
   "source": [
    "print(\"*************** Original Code ***************** \\n\",out.iloc[0][\"Original_Code\"])\n",
    "print(\"*************** Generated_Code_granite_2 ***************** \\n\",out.iloc[0][\"Generated_Code_granite_2\"])\n",
    "print(\"*************** Similarity Score ***************** \\n\",out.iloc[3][\"Sim_Code_granite_2\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not Cleaned Explanation and cleaned generated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* Empty Strings/ NaN values ***********\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                      0\n",
       "corpus_id                       0\n",
       "query_id                        0\n",
       "Original_Code                   0\n",
       "Generated_Code_deepseek_1    1505\n",
       "Generated_Code_deepseek_2    1951\n",
       "Generated_Code_deepseek_3    1747\n",
       "Generated_Code_deepseek_4    2136\n",
       "Generated_Code_granite_1        0\n",
       "Generated_Code_granite_2        0\n",
       "Generated_Code_granite_3        0\n",
       "Generated_Code_granite_4        0\n",
       "Sim_Code_deepseek_1             0\n",
       "Exact_Match_deepseek_1          0\n",
       "Sim_Code_deepseek_2             0\n",
       "Exact_Match_deepseek_2          0\n",
       "Sim_Code_deepseek_3             0\n",
       "Exact_Match_deepseek_3          0\n",
       "Sim_Code_deepseek_4             0\n",
       "Exact_Match_deepseek_4          0\n",
       "RTC_deepseek                    0\n",
       "Pass@1_deepseek                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "out=pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/results/exps_metrics_results_file.csv\")\n",
    "print(\"********* Empty Strings/ NaN values ***********\")\n",
    "out.apply(lambda col: col.isna().sum() + (col == '').sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7689970665054631, 0.8838453698311007)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"RTC_deepseek\"].mean(), out[\"Pass@1_deepseek\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>Original_Code</th>\n",
       "      <th>Generated_Code_deepseek_1</th>\n",
       "      <th>Generated_Code_deepseek_2</th>\n",
       "      <th>Generated_Code_deepseek_3</th>\n",
       "      <th>Generated_Code_deepseek_4</th>\n",
       "      <th>Generated_Code_granite_1</th>\n",
       "      <th>Generated_Code_granite_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Sim_Code_deepseek_1</th>\n",
       "      <th>Exact_Match_deepseek_1</th>\n",
       "      <th>Sim_Code_deepseek_2</th>\n",
       "      <th>Exact_Match_deepseek_2</th>\n",
       "      <th>Sim_Code_deepseek_3</th>\n",
       "      <th>Exact_Match_deepseek_3</th>\n",
       "      <th>Sim_Code_deepseek_4</th>\n",
       "      <th>Exact_Match_deepseek_4</th>\n",
       "      <th>RTC_deepseek</th>\n",
       "      <th>Pass@1_deepseek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>d6</td>\n",
       "      <td>q6</td>\n",
       "      <td>def experiment_property(prop):\\n    \"\"\"Get a p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def experiment_property(prop):\\n    exp = expe...</td>\n",
       "      <td>def experiment_property(prop):\\n    exp = expe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>```python\\ndef experiment_property(prop):\\n   ...</td>\n",
       "      <td>```python\\ndef experiment_property(prop):\\n   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.950276</td>\n",
       "      <td>False</td>\n",
       "      <td>0.840602</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.447719</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>d24</td>\n",
       "      <td>q24</td>\n",
       "      <td>def __add__(self, other):\\n        \"\"\"Handle t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>```python\\ndef __add__(self, other):\\n    \"\"\"\\...</td>\n",
       "      <td>```python\\ndef __add__(self, other):\\n    \"\"\"H...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>d31</td>\n",
       "      <td>q31</td>\n",
       "      <td>def context(self):\\n        \"\"\"\\n        Creat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def context(self):\\n    try:\\n        yield se...</td>\n",
       "      <td>```python\\nclass ContextManager:\\n    def __en...</td>\n",
       "      <td>```python\\ndef context(self):\\n    \"\"\"\\n    Th...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.803796</td>\n",
       "      <td>False</td>\n",
       "      <td>0.200949</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>d74</td>\n",
       "      <td>q74</td>\n",
       "      <td>async def list(source):\\n    \"\"\"Generate a sin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def list(streamer: list) -&gt; list:\\n    result ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>```python\\nimport asyncio\\n\\nasync def list(so...</td>\n",
       "      <td>```python\\nasync def list(source):\\n    \"\"\"Gen...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.881107</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.220277</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>d77</td>\n",
       "      <td>q77</td>\n",
       "      <td>def get_next_scheduled_time(cron_string):\\n   ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def get_next_scheduled_time(cron_string):\\n   ...</td>\n",
       "      <td>def get_next_scheduled_time(cron_string):\\n   ...</td>\n",
       "      <td>def get_next_scheduled_time(cron_str):\\n    # ...</td>\n",
       "      <td>```python\\nfrom croniter import croniter\\nfrom...</td>\n",
       "      <td>```python\\nfrom datetime import datetime, time...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.895340</td>\n",
       "      <td>False</td>\n",
       "      <td>0.901514</td>\n",
       "      <td>False</td>\n",
       "      <td>0.699214</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 corpus_id query_id  \\\n",
       "5            5        d6       q6   \n",
       "23          23       d24      q24   \n",
       "30          30       d31      q31   \n",
       "73          73       d74      q74   \n",
       "76          76       d77      q77   \n",
       "\n",
       "                                        Original_Code  \\\n",
       "5   def experiment_property(prop):\\n    \"\"\"Get a p...   \n",
       "23  def __add__(self, other):\\n        \"\"\"Handle t...   \n",
       "30  def context(self):\\n        \"\"\"\\n        Creat...   \n",
       "73  async def list(source):\\n    \"\"\"Generate a sin...   \n",
       "76  def get_next_scheduled_time(cron_string):\\n   ...   \n",
       "\n",
       "   Generated_Code_deepseek_1  \\\n",
       "5                        NaN   \n",
       "23                       NaN   \n",
       "30                       NaN   \n",
       "73                       NaN   \n",
       "76                       NaN   \n",
       "\n",
       "                            Generated_Code_deepseek_2  \\\n",
       "5   def experiment_property(prop):\\n    exp = expe...   \n",
       "23                                                NaN   \n",
       "30                                                NaN   \n",
       "73  def list(streamer: list) -> list:\\n    result ...   \n",
       "76  def get_next_scheduled_time(cron_string):\\n   ...   \n",
       "\n",
       "                            Generated_Code_deepseek_3  \\\n",
       "5   def experiment_property(prop):\\n    exp = expe...   \n",
       "23                                                NaN   \n",
       "30                                                NaN   \n",
       "73                                                NaN   \n",
       "76  def get_next_scheduled_time(cron_string):\\n   ...   \n",
       "\n",
       "                            Generated_Code_deepseek_4  \\\n",
       "5                                                 NaN   \n",
       "23                                                NaN   \n",
       "30  def context(self):\\n    try:\\n        yield se...   \n",
       "73                                                NaN   \n",
       "76  def get_next_scheduled_time(cron_str):\\n    # ...   \n",
       "\n",
       "                             Generated_Code_granite_1  \\\n",
       "5   ```python\\ndef experiment_property(prop):\\n   ...   \n",
       "23  ```python\\ndef __add__(self, other):\\n    \"\"\"\\...   \n",
       "30  ```python\\nclass ContextManager:\\n    def __en...   \n",
       "73  ```python\\nimport asyncio\\n\\nasync def list(so...   \n",
       "76  ```python\\nfrom croniter import croniter\\nfrom...   \n",
       "\n",
       "                             Generated_Code_granite_2  ...  \\\n",
       "5   ```python\\ndef experiment_property(prop):\\n   ...  ...   \n",
       "23  ```python\\ndef __add__(self, other):\\n    \"\"\"H...  ...   \n",
       "30  ```python\\ndef context(self):\\n    \"\"\"\\n    Th...  ...   \n",
       "73  ```python\\nasync def list(source):\\n    \"\"\"Gen...  ...   \n",
       "76  ```python\\nfrom datetime import datetime, time...  ...   \n",
       "\n",
       "   Sim_Code_deepseek_1 Exact_Match_deepseek_1  Sim_Code_deepseek_2  \\\n",
       "5                  0.0                  False             0.950276   \n",
       "23                 0.0                  False             0.000000   \n",
       "30                 0.0                  False             0.000000   \n",
       "73                 0.0                  False             0.881107   \n",
       "76                 0.0                  False             1.000000   \n",
       "\n",
       "    Exact_Match_deepseek_2  Sim_Code_deepseek_3  Exact_Match_deepseek_3  \\\n",
       "5                    False             0.840602                   False   \n",
       "23                   False             0.000000                   False   \n",
       "30                   False             0.000000                   False   \n",
       "73                   False             0.000000                   False   \n",
       "76                    True             0.895340                   False   \n",
       "\n",
       "    Sim_Code_deepseek_4  Exact_Match_deepseek_4  RTC_deepseek  Pass@1_deepseek  \n",
       "5              0.000000                   False      0.447719             0.50  \n",
       "23             0.000000                   False      0.000000             0.00  \n",
       "30             0.803796                   False      0.200949             0.25  \n",
       "73             0.000000                   False      0.220277             0.25  \n",
       "76             0.901514                   False      0.699214             0.75  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>code</th>\n",
       "      <th>explanation_deepseek_1</th>\n",
       "      <th>explanation_deepseek_2</th>\n",
       "      <th>explanation_deepseek_3</th>\n",
       "      <th>explanation_deepseek_4</th>\n",
       "      <th>explanation_granite_1</th>\n",
       "      <th>explanation_granite_2</th>\n",
       "      <th>explanation_granite_3</th>\n",
       "      <th>explanation_granite_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>q24</td>\n",
       "      <td>a+b in python addition code</td>\n",
       "      <td>d24</td>\n",
       "      <td>def __add__(self, other):\\n        \"\"\"Handle t...</td>\n",
       "      <td>The __add__ method in Python handles the addit...</td>\n",
       "      <td>The code snippet is a Python method for handli...</td>\n",
       "      <td>&lt;/think&gt;\\n\\nThis code snippet is about how Pyt...</td>\n",
       "      <td>&lt;/think&gt;\\n\\nThe code snippet provided implemen...</td>\n",
       "      <td>\\nThis Python code defines a method `__add__` ...</td>\n",
       "      <td>\\nThis code snippet is a method definition in ...</td>\n",
       "      <td>\\nThis code snippet is a special function in P...</td>\n",
       "      <td>\\nThis code snippet is a method definition for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                          doc corpus_id  \\\n",
       "23      q24  a+b in python addition code       d24   \n",
       "\n",
       "                                                 code  \\\n",
       "23  def __add__(self, other):\\n        \"\"\"Handle t...   \n",
       "\n",
       "                               explanation_deepseek_1  \\\n",
       "23  The __add__ method in Python handles the addit...   \n",
       "\n",
       "                               explanation_deepseek_2  \\\n",
       "23  The code snippet is a Python method for handli...   \n",
       "\n",
       "                               explanation_deepseek_3  \\\n",
       "23  </think>\\n\\nThis code snippet is about how Pyt...   \n",
       "\n",
       "                               explanation_deepseek_4  \\\n",
       "23  </think>\\n\\nThe code snippet provided implemen...   \n",
       "\n",
       "                                explanation_granite_1  \\\n",
       "23  \\nThis Python code defines a method `__add__` ...   \n",
       "\n",
       "                                explanation_granite_2  \\\n",
       "23  \\nThis code snippet is a method definition in ...   \n",
       "\n",
       "                                explanation_granite_3  \\\n",
       "23  \\nThis code snippet is a special function in P...   \n",
       "\n",
       "                                explanation_granite_4  \n",
       "23  \\nThis code snippet is a method definition for...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>Original_Code</th>\n",
       "      <th>Generated_Code_deepseek_1</th>\n",
       "      <th>Generated_Code_deepseek_2</th>\n",
       "      <th>Generated_Code_deepseek_3</th>\n",
       "      <th>Generated_Code_deepseek_4</th>\n",
       "      <th>Generated_Code_granite_1</th>\n",
       "      <th>Generated_Code_granite_2</th>\n",
       "      <th>Generated_Code_granite_3</th>\n",
       "      <th>Generated_Code_granite_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>d24</td>\n",
       "      <td>q24</td>\n",
       "      <td>def __add__(self, other):\\n        \"\"\"Handle t...</td>\n",
       "      <td>```\\nclass MyClass:\\n    def __add__(self, oth...</td>\n",
       "      <td>```python\\nclass MyClass:\\n    def __add__(sel...</td>\n",
       "      <td>```python\\nclass Adder:\\n    def __add__(self,...</td>\n",
       "      <td>```python\\nclass Add:\\n    def __add__(self, o...</td>\n",
       "      <td>```python\\ndef __add__(self, other):\\n    \"\"\"\\...</td>\n",
       "      <td>```python\\ndef __add__(self, other):\\n    \"\"\"H...</td>\n",
       "      <td>```python\\nclass MyClass:\\n    def __init__(se...</td>\n",
       "      <td>```python\\ndef __add__(self, other):\\n    \"\"\"H...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   corpus_id query_id                                      Original_Code  \\\n",
       "23       d24      q24  def __add__(self, other):\\n        \"\"\"Handle t...   \n",
       "\n",
       "                            Generated_Code_deepseek_1  \\\n",
       "23  ```\\nclass MyClass:\\n    def __add__(self, oth...   \n",
       "\n",
       "                            Generated_Code_deepseek_2  \\\n",
       "23  ```python\\nclass MyClass:\\n    def __add__(sel...   \n",
       "\n",
       "                            Generated_Code_deepseek_3  \\\n",
       "23  ```python\\nclass Adder:\\n    def __add__(self,...   \n",
       "\n",
       "                            Generated_Code_deepseek_4  \\\n",
       "23  ```python\\nclass Add:\\n    def __add__(self, o...   \n",
       "\n",
       "                             Generated_Code_granite_1  \\\n",
       "23  ```python\\ndef __add__(self, other):\\n    \"\"\"\\...   \n",
       "\n",
       "                             Generated_Code_granite_2  \\\n",
       "23  ```python\\ndef __add__(self, other):\\n    \"\"\"H...   \n",
       "\n",
       "                             Generated_Code_granite_3  \\\n",
       "23  ```python\\nclass MyClass:\\n    def __init__(se...   \n",
       "\n",
       "                             Generated_Code_granite_4  \n",
       "23  ```python\\ndef __add__(self, other):\\n    \"\"\"H...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputdf = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CoSQA_explanations_vllm1.csv\")\n",
    "codedf = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/results/exps_generated_code_results.csv\")\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "display(out[out['Generated_Code_deepseek_1'].isna() | (out['Generated_Code_deepseek_1'] == '')].head())\n",
    "display(inputdf[(inputdf[\"corpus_id\"] == \"d24\") & (inputdf[\"query_id\"] == \"q24\")])\n",
    "display(codedf[(codedf[\"corpus_id\"] == \"d24\") & (codedf[\"query_id\"] == \"q24\")])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>Original_Code</th>\n",
       "      <th>Generated_Code_deepseek_1</th>\n",
       "      <th>Generated_Code_deepseek_2</th>\n",
       "      <th>Generated_Code_deepseek_3</th>\n",
       "      <th>Generated_Code_deepseek_4</th>\n",
       "      <th>Generated_Code_granite_1</th>\n",
       "      <th>Generated_Code_granite_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Sim_Code_deepseek_1</th>\n",
       "      <th>Exact_Match_deepseek_1</th>\n",
       "      <th>Sim_Code_deepseek_2</th>\n",
       "      <th>Exact_Match_deepseek_2</th>\n",
       "      <th>Sim_Code_deepseek_3</th>\n",
       "      <th>Exact_Match_deepseek_3</th>\n",
       "      <th>Sim_Code_deepseek_4</th>\n",
       "      <th>Exact_Match_deepseek_4</th>\n",
       "      <th>RTC_deepseek</th>\n",
       "      <th>Pass@1_deepseek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>d6</td>\n",
       "      <td>q6</td>\n",
       "      <td>def experiment_property(prop):\\n    \"\"\"Get a p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def experiment_property(prop):\\n    exp = expe...</td>\n",
       "      <td>def experiment_property(prop):\\n    exp = expe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>```python\\ndef experiment_property(prop):\\n   ...</td>\n",
       "      <td>```python\\ndef experiment_property(prop):\\n   ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.950276</td>\n",
       "      <td>False</td>\n",
       "      <td>0.840602</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.447719</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>d24</td>\n",
       "      <td>q24</td>\n",
       "      <td>def __add__(self, other):\\n        \"\"\"Handle t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>```python\\ndef __add__(self, other):\\n    \"\"\"\\...</td>\n",
       "      <td>```python\\ndef __add__(self, other):\\n    \"\"\"H...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>d31</td>\n",
       "      <td>q31</td>\n",
       "      <td>def context(self):\\n        \"\"\"\\n        Creat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def context(self):\\n    try:\\n        yield se...</td>\n",
       "      <td>```python\\nclass ContextManager:\\n    def __en...</td>\n",
       "      <td>```python\\ndef context(self):\\n    \"\"\"\\n    Th...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.803796</td>\n",
       "      <td>False</td>\n",
       "      <td>0.200949</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>d74</td>\n",
       "      <td>q74</td>\n",
       "      <td>async def list(source):\\n    \"\"\"Generate a sin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def list(streamer: list) -&gt; list:\\n    result ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>```python\\nimport asyncio\\n\\nasync def list(so...</td>\n",
       "      <td>```python\\nasync def list(source):\\n    \"\"\"Gen...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.881107</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.220277</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>d77</td>\n",
       "      <td>q77</td>\n",
       "      <td>def get_next_scheduled_time(cron_string):\\n   ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def get_next_scheduled_time(cron_string):\\n   ...</td>\n",
       "      <td>def get_next_scheduled_time(cron_string):\\n   ...</td>\n",
       "      <td>def get_next_scheduled_time(cron_str):\\n    # ...</td>\n",
       "      <td>```python\\nfrom croniter import croniter\\nfrom...</td>\n",
       "      <td>```python\\nfrom datetime import datetime, time...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.895340</td>\n",
       "      <td>False</td>\n",
       "      <td>0.901514</td>\n",
       "      <td>False</td>\n",
       "      <td>0.699214</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 corpus_id query_id  \\\n",
       "5            5        d6       q6   \n",
       "23          23       d24      q24   \n",
       "30          30       d31      q31   \n",
       "73          73       d74      q74   \n",
       "76          76       d77      q77   \n",
       "\n",
       "                                        Original_Code  \\\n",
       "5   def experiment_property(prop):\\n    \"\"\"Get a p...   \n",
       "23  def __add__(self, other):\\n        \"\"\"Handle t...   \n",
       "30  def context(self):\\n        \"\"\"\\n        Creat...   \n",
       "73  async def list(source):\\n    \"\"\"Generate a sin...   \n",
       "76  def get_next_scheduled_time(cron_string):\\n   ...   \n",
       "\n",
       "   Generated_Code_deepseek_1  \\\n",
       "5                        NaN   \n",
       "23                       NaN   \n",
       "30                       NaN   \n",
       "73                       NaN   \n",
       "76                       NaN   \n",
       "\n",
       "                            Generated_Code_deepseek_2  \\\n",
       "5   def experiment_property(prop):\\n    exp = expe...   \n",
       "23                                                NaN   \n",
       "30                                                NaN   \n",
       "73  def list(streamer: list) -> list:\\n    result ...   \n",
       "76  def get_next_scheduled_time(cron_string):\\n   ...   \n",
       "\n",
       "                            Generated_Code_deepseek_3  \\\n",
       "5   def experiment_property(prop):\\n    exp = expe...   \n",
       "23                                                NaN   \n",
       "30                                                NaN   \n",
       "73                                                NaN   \n",
       "76  def get_next_scheduled_time(cron_string):\\n   ...   \n",
       "\n",
       "                            Generated_Code_deepseek_4  \\\n",
       "5                                                 NaN   \n",
       "23                                                NaN   \n",
       "30  def context(self):\\n    try:\\n        yield se...   \n",
       "73                                                NaN   \n",
       "76  def get_next_scheduled_time(cron_str):\\n    # ...   \n",
       "\n",
       "                             Generated_Code_granite_1  \\\n",
       "5   ```python\\ndef experiment_property(prop):\\n   ...   \n",
       "23  ```python\\ndef __add__(self, other):\\n    \"\"\"\\...   \n",
       "30  ```python\\nclass ContextManager:\\n    def __en...   \n",
       "73  ```python\\nimport asyncio\\n\\nasync def list(so...   \n",
       "76  ```python\\nfrom croniter import croniter\\nfrom...   \n",
       "\n",
       "                             Generated_Code_granite_2  ...  \\\n",
       "5   ```python\\ndef experiment_property(prop):\\n   ...  ...   \n",
       "23  ```python\\ndef __add__(self, other):\\n    \"\"\"H...  ...   \n",
       "30  ```python\\ndef context(self):\\n    \"\"\"\\n    Th...  ...   \n",
       "73  ```python\\nasync def list(source):\\n    \"\"\"Gen...  ...   \n",
       "76  ```python\\nfrom datetime import datetime, time...  ...   \n",
       "\n",
       "   Sim_Code_deepseek_1 Exact_Match_deepseek_1  Sim_Code_deepseek_2  \\\n",
       "5                  0.0                  False             0.950276   \n",
       "23                 0.0                  False             0.000000   \n",
       "30                 0.0                  False             0.000000   \n",
       "73                 0.0                  False             0.881107   \n",
       "76                 0.0                  False             1.000000   \n",
       "\n",
       "    Exact_Match_deepseek_2  Sim_Code_deepseek_3  Exact_Match_deepseek_3  \\\n",
       "5                    False             0.840602                   False   \n",
       "23                   False             0.000000                   False   \n",
       "30                   False             0.000000                   False   \n",
       "73                   False             0.000000                   False   \n",
       "76                    True             0.895340                   False   \n",
       "\n",
       "    Sim_Code_deepseek_4  Exact_Match_deepseek_4  RTC_deepseek  Pass@1_deepseek  \n",
       "5              0.000000                   False      0.447719             0.50  \n",
       "23             0.000000                   False      0.000000             0.00  \n",
       "30             0.803796                   False      0.200949             0.25  \n",
       "73             0.000000                   False      0.220277             0.25  \n",
       "76             0.901514                   False      0.699214             0.75  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>code</th>\n",
       "      <th>explanation_deepseek_1</th>\n",
       "      <th>explanation_deepseek_2</th>\n",
       "      <th>explanation_deepseek_3</th>\n",
       "      <th>explanation_deepseek_4</th>\n",
       "      <th>explanation_granite_1</th>\n",
       "      <th>explanation_granite_2</th>\n",
       "      <th>explanation_granite_3</th>\n",
       "      <th>explanation_granite_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>q74</td>\n",
       "      <td>async list comprehension python</td>\n",
       "      <td>d74</td>\n",
       "      <td>async def list(source):\\n    \"\"\"Generate a sin...</td>\n",
       "      <td>&lt;/think&gt;\\n\\nThe doc and code mean that the fun...</td>\n",
       "      <td>&lt;/think&gt;\\n\\n1. **Line 1**: `result = []`  \\n  ...</td>\n",
       "      <td>&lt;/think&gt;\\n\\nThis code snippet is a function ca...</td>\n",
       "      <td>Alright, I'm trying to understand this async l...</td>\n",
       "      <td>\\nThe provided code defines an asynchronous fu...</td>\n",
       "      <td>\\n1. `async def list(source):` - This line def...</td>\n",
       "      <td>\\nThis code snippet defines an asynchronous fu...</td>\n",
       "      <td>\\nThe code snippet provided is an asynchronous...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                              doc corpus_id  \\\n",
       "73      q74  async list comprehension python       d74   \n",
       "\n",
       "                                                 code  \\\n",
       "73  async def list(source):\\n    \"\"\"Generate a sin...   \n",
       "\n",
       "                               explanation_deepseek_1  \\\n",
       "73  </think>\\n\\nThe doc and code mean that the fun...   \n",
       "\n",
       "                               explanation_deepseek_2  \\\n",
       "73  </think>\\n\\n1. **Line 1**: `result = []`  \\n  ...   \n",
       "\n",
       "                               explanation_deepseek_3  \\\n",
       "73  </think>\\n\\nThis code snippet is a function ca...   \n",
       "\n",
       "                               explanation_deepseek_4  \\\n",
       "73  Alright, I'm trying to understand this async l...   \n",
       "\n",
       "                                explanation_granite_1  \\\n",
       "73  \\nThe provided code defines an asynchronous fu...   \n",
       "\n",
       "                                explanation_granite_2  \\\n",
       "73  \\n1. `async def list(source):` - This line def...   \n",
       "\n",
       "                                explanation_granite_3  \\\n",
       "73  \\nThis code snippet defines an asynchronous fu...   \n",
       "\n",
       "                                explanation_granite_4  \n",
       "73  \\nThe code snippet provided is an asynchronous...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>Original_Code</th>\n",
       "      <th>Generated_Code_deepseek_1</th>\n",
       "      <th>Generated_Code_deepseek_2</th>\n",
       "      <th>Generated_Code_deepseek_3</th>\n",
       "      <th>Generated_Code_deepseek_4</th>\n",
       "      <th>Generated_Code_granite_1</th>\n",
       "      <th>Generated_Code_granite_2</th>\n",
       "      <th>Generated_Code_granite_3</th>\n",
       "      <th>Generated_Code_granite_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>d74</td>\n",
       "      <td>q74</td>\n",
       "      <td>async def list(source):\\n    \"\"\"Generate a sin...</td>\n",
       "      <td>```python\\nasync for item in streamer:\\n    re...</td>\n",
       "      <td>```python\\ndef list(streamer: list) -&gt; list:\\n...</td>\n",
       "      <td>```python\\nasync def list(source):\\n    result...</td>\n",
       "      <td>async def list(source):\\n    result = []\\n    ...</td>\n",
       "      <td>```python\\nimport asyncio\\n\\nasync def list(so...</td>\n",
       "      <td>```python\\nasync def list(source):\\n    \"\"\"Gen...</td>\n",
       "      <td>```python\\nimport asyncio\\n\\nasync def list(so...</td>\n",
       "      <td>```python\\nasync def list(source):\\n    result...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   corpus_id query_id                                      Original_Code  \\\n",
       "73       d74      q74  async def list(source):\\n    \"\"\"Generate a sin...   \n",
       "\n",
       "                            Generated_Code_deepseek_1  \\\n",
       "73  ```python\\nasync for item in streamer:\\n    re...   \n",
       "\n",
       "                            Generated_Code_deepseek_2  \\\n",
       "73  ```python\\ndef list(streamer: list) -> list:\\n...   \n",
       "\n",
       "                            Generated_Code_deepseek_3  \\\n",
       "73  ```python\\nasync def list(source):\\n    result...   \n",
       "\n",
       "                            Generated_Code_deepseek_4  \\\n",
       "73  async def list(source):\\n    result = []\\n    ...   \n",
       "\n",
       "                             Generated_Code_granite_1  \\\n",
       "73  ```python\\nimport asyncio\\n\\nasync def list(so...   \n",
       "\n",
       "                             Generated_Code_granite_2  \\\n",
       "73  ```python\\nasync def list(source):\\n    \"\"\"Gen...   \n",
       "\n",
       "                             Generated_Code_granite_3  \\\n",
       "73  ```python\\nimport asyncio\\n\\nasync def list(so...   \n",
       "\n",
       "                             Generated_Code_granite_4  \n",
       "73  ```python\\nasync def list(source):\\n    result...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(out[out['Generated_Code_deepseek_1'].isna() | (out['Generated_Code_deepseek_1'] == '')].head())\n",
    "display(inputdf[(inputdf[\"corpus_id\"] == \"d74\") & (inputdf[\"query_id\"] == \"q74\")])\n",
    "display(codedf[(codedf[\"corpus_id\"] == \"d74\") & (codedf[\"query_id\"] == \"q74\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Original Code ***************** \n",
      " def writeBoolean(self, n):\n",
      "        \"\"\"\n",
      "        Writes a Boolean to the stream.\n",
      "        \"\"\"\n",
      "        t = TYPE_BOOL_TRUE\n",
      "\n",
      "        if n is False:\n",
      "            t = TYPE_BOOL_FALSE\n",
      "\n",
      "        self.stream.write(t)\n",
      "*************** Generated_Code_deepseek_2 ***************** \n",
      " def writeBoolean(self, n: int) -> None:\n",
      "    if n:\n",
      "        self.stream.write(True)\n",
      "    else:\n",
      "        self.stream.write(False)\n",
      "*************** Similarity Score ***************** \n",
      " 0.8175770044326782\n"
     ]
    }
   ],
   "source": [
    "print(\"*************** Original Code ***************** \\n\",out.iloc[0][\"Original_Code\"])\n",
    "print(\"*************** Generated_Code_deepseek_2 ***************** \\n\",out.iloc[0][\"Generated_Code_deepseek_2\"])\n",
    "print(\"*************** Similarity Score ***************** \\n\",out.iloc[3][\"Sim_Code_deepseek_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Granite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                      0\n",
       "corpus_id                       0\n",
       "query_id                        0\n",
       "Original_Code                   0\n",
       "Generated_Code_deepseek_1       1\n",
       "Generated_Code_deepseek_2       0\n",
       "Generated_Code_deepseek_3       0\n",
       "Generated_Code_deepseek_4       0\n",
       "Generated_Code_granite_1      940\n",
       "Generated_Code_granite_2      870\n",
       "Generated_Code_granite_3      616\n",
       "Generated_Code_granite_4     1563\n",
       "Sim_Code_granite_1              0\n",
       "Exact_Match_granite_1           0\n",
       "Sim_Code_granite_2              0\n",
       "Exact_Match_granite_2           0\n",
       "Sim_Code_granite_3              0\n",
       "Exact_Match_granite_3           0\n",
       "Sim_Code_granite_4              0\n",
       "Exact_Match_granite_4           0\n",
       "RTC_granite                     0\n",
       "Pass@1_granite                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "inputdf = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CoSQA_explanations_vllm1.csv\")\n",
    "codedf = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/results/exps_generated_code_results.csv\")\n",
    "out=pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/results/granite_exps_metrics_results.csv\")\n",
    "out.apply(lambda col: col.isna().sum() + (col == '').sum())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>Original_Code</th>\n",
       "      <th>Generated_Code_deepseek_1</th>\n",
       "      <th>Generated_Code_deepseek_2</th>\n",
       "      <th>Generated_Code_deepseek_3</th>\n",
       "      <th>Generated_Code_deepseek_4</th>\n",
       "      <th>Generated_Code_granite_1</th>\n",
       "      <th>Generated_Code_granite_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Sim_Code_granite_1</th>\n",
       "      <th>Exact_Match_granite_1</th>\n",
       "      <th>Sim_Code_granite_2</th>\n",
       "      <th>Exact_Match_granite_2</th>\n",
       "      <th>Sim_Code_granite_3</th>\n",
       "      <th>Exact_Match_granite_3</th>\n",
       "      <th>Sim_Code_granite_4</th>\n",
       "      <th>Exact_Match_granite_4</th>\n",
       "      <th>RTC_granite</th>\n",
       "      <th>Pass@1_granite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>d26</td>\n",
       "      <td>q26</td>\n",
       "      <td>def get_column(self, X, column):\\n        \"\"\"R...</td>\n",
       "      <td>```python\\ndef get_column(matrix, index=None, ...</td>\n",
       "      <td>```python\\ndef get_column(self, X, column):\\n ...</td>\n",
       "      <td>def get_column(X, column):\\n    if isinstance(...</td>\n",
       "      <td>```python\\ndef get_column(X, column):\\n    if ...</td>\n",
       "      <td>def get_column(X, column):\\n    if isinstance(...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842354</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.837411</td>\n",
       "      <td>False</td>\n",
       "      <td>0.845411</td>\n",
       "      <td>False</td>\n",
       "      <td>0.631294</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>d38</td>\n",
       "      <td>q38</td>\n",
       "      <td>def __add__(self,other):\\n        \"\"\"\\n       ...</td>\n",
       "      <td>```python\\ndef __add__(self, other):\\n    \"\"\"\\...</td>\n",
       "      <td>```python\\nclass LabeledMatrix:\\n    def __add...</td>\n",
       "      <td>```python\\ndef __add__(self, other):\\n    if n...</td>\n",
       "      <td>```python\\ndef count_frequencies(s):\\n    freq...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.750286</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.187572</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>d74</td>\n",
       "      <td>q74</td>\n",
       "      <td>async def list(source):\\n    \"\"\"Generate a sin...</td>\n",
       "      <td>```python\\nasync for item in streamer:\\n    re...</td>\n",
       "      <td>```python\\ndef list(streamer: list) -&gt; list:\\n...</td>\n",
       "      <td>```python\\nasync def list(source):\\n    result...</td>\n",
       "      <td>async def list(source):\\n    result = []\\n    ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>d100</td>\n",
       "      <td>q100</td>\n",
       "      <td>def table_top_abs(self):\\n        \"\"\"Returns t...</td>\n",
       "      <td>def get_table_top_height():\\n    # Calculate t...</td>\n",
       "      <td>def table_top_abs(self):\\n    table_height = n...</td>\n",
       "      <td>```python\\ndef table_top_abs(self):\\n    retur...</td>\n",
       "      <td>import numpy as np\\n\\ndef table_top_abs(self):...</td>\n",
       "      <td>def table_top_abs(floor):\\n    table_height = ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864315</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.913406</td>\n",
       "      <td>False</td>\n",
       "      <td>0.995568</td>\n",
       "      <td>False</td>\n",
       "      <td>0.693323</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>d113</td>\n",
       "      <td>q113</td>\n",
       "      <td>def parse(self, s):\\n        \"\"\"\\n        Pars...</td>\n",
       "      <td>The Python function is named `date_from_str` a...</td>\n",
       "      <td>def parse(self, s):\\n    return datetime.datet...</td>\n",
       "      <td>```python\\nclass DateParser:\\n    def __init__...</td>\n",
       "      <td>```python\\nimport datetime\\nimport calendar\\n\\...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.828415</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.207104</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 corpus_id query_id  \\\n",
       "25           25       d26      q26   \n",
       "37           37       d38      q38   \n",
       "73           73       d74      q74   \n",
       "99           99      d100     q100   \n",
       "112         112      d113     q113   \n",
       "\n",
       "                                         Original_Code  \\\n",
       "25   def get_column(self, X, column):\\n        \"\"\"R...   \n",
       "37   def __add__(self,other):\\n        \"\"\"\\n       ...   \n",
       "73   async def list(source):\\n    \"\"\"Generate a sin...   \n",
       "99   def table_top_abs(self):\\n        \"\"\"Returns t...   \n",
       "112  def parse(self, s):\\n        \"\"\"\\n        Pars...   \n",
       "\n",
       "                             Generated_Code_deepseek_1  \\\n",
       "25   ```python\\ndef get_column(matrix, index=None, ...   \n",
       "37   ```python\\ndef __add__(self, other):\\n    \"\"\"\\...   \n",
       "73   ```python\\nasync for item in streamer:\\n    re...   \n",
       "99   def get_table_top_height():\\n    # Calculate t...   \n",
       "112  The Python function is named `date_from_str` a...   \n",
       "\n",
       "                             Generated_Code_deepseek_2  \\\n",
       "25   ```python\\ndef get_column(self, X, column):\\n ...   \n",
       "37   ```python\\nclass LabeledMatrix:\\n    def __add...   \n",
       "73   ```python\\ndef list(streamer: list) -> list:\\n...   \n",
       "99   def table_top_abs(self):\\n    table_height = n...   \n",
       "112  def parse(self, s):\\n    return datetime.datet...   \n",
       "\n",
       "                             Generated_Code_deepseek_3  \\\n",
       "25   def get_column(X, column):\\n    if isinstance(...   \n",
       "37   ```python\\ndef __add__(self, other):\\n    if n...   \n",
       "73   ```python\\nasync def list(source):\\n    result...   \n",
       "99   ```python\\ndef table_top_abs(self):\\n    retur...   \n",
       "112  ```python\\nclass DateParser:\\n    def __init__...   \n",
       "\n",
       "                             Generated_Code_deepseek_4  \\\n",
       "25   ```python\\ndef get_column(X, column):\\n    if ...   \n",
       "37   ```python\\ndef count_frequencies(s):\\n    freq...   \n",
       "73   async def list(source):\\n    result = []\\n    ...   \n",
       "99   import numpy as np\\n\\ndef table_top_abs(self):...   \n",
       "112  ```python\\nimport datetime\\nimport calendar\\n\\...   \n",
       "\n",
       "                              Generated_Code_granite_1  \\\n",
       "25   def get_column(X, column):\\n    if isinstance(...   \n",
       "37                                                 NaN   \n",
       "73                                                 NaN   \n",
       "99   def table_top_abs(floor):\\n    table_height = ...   \n",
       "112                                                NaN   \n",
       "\n",
       "    Generated_Code_granite_2  ... Sim_Code_granite_1 Exact_Match_granite_1  \\\n",
       "25                       NaN  ...           0.842354                 False   \n",
       "37                       NaN  ...           0.000000                 False   \n",
       "73                       NaN  ...           0.000000                 False   \n",
       "99                       NaN  ...           0.864315                 False   \n",
       "112                      NaN  ...           0.000000                 False   \n",
       "\n",
       "     Sim_Code_granite_2  Exact_Match_granite_2  Sim_Code_granite_3  \\\n",
       "25                  0.0                  False            0.837411   \n",
       "37                  0.0                  False            0.750286   \n",
       "73                  0.0                  False            0.000000   \n",
       "99                  0.0                  False            0.913406   \n",
       "112                 0.0                  False            0.828415   \n",
       "\n",
       "     Exact_Match_granite_3  Sim_Code_granite_4  Exact_Match_granite_4  \\\n",
       "25                   False            0.845411                  False   \n",
       "37                   False            0.000000                  False   \n",
       "73                   False            0.000000                  False   \n",
       "99                   False            0.995568                  False   \n",
       "112                  False            0.000000                  False   \n",
       "\n",
       "     RTC_granite  Pass@1_granite  \n",
       "25      0.631294            0.75  \n",
       "37      0.187572            0.25  \n",
       "73      0.000000            0.00  \n",
       "99      0.693323            0.75  \n",
       "112     0.207104            0.25  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(out[out['Generated_Code_granite_2'].isna() | (out['Generated_Code_granite_2'] == '')].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8381319595339911, 0.9371481265773636)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"RTC_granite\"].mean(), out[\"Pass@1_granite\"].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"*************** Original Code ***************** \\n\",out.iloc[0][\"Original_Code\"])\n",
    "print(\"*************** Generated_Code_granite_2 ***************** \\n\",out.iloc[0][\"Generated_Code_granite_2\"])\n",
    "print(\"*************** Similarity Score ***************** \\n\",out.iloc[3][\"Sim_Code_granite_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepSeek - Cleaned Explanation and cleaned generated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* Empty Strings/ NaN values ***********\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                      0\n",
       "Generated_Code_deepseek_1    3777\n",
       "Generated_Code_deepseek_2    2051\n",
       "Generated_Code_deepseek_3    2303\n",
       "Generated_Code_deepseek_4    1724\n",
       "Original_Code                   0\n",
       "corpus_id                       0\n",
       "query_id                        0\n",
       "Sim_Code_deepseek_1             0\n",
       "Exact_Match_deepseek_1          0\n",
       "Sim_Code_deepseek_2             0\n",
       "Exact_Match_deepseek_2          0\n",
       "Sim_Code_deepseek_3             0\n",
       "Exact_Match_deepseek_3          0\n",
       "Sim_Code_deepseek_4             0\n",
       "Exact_Match_deepseek_4          0\n",
       "RTC_deepseek                    0\n",
       "Pass@1_deepseek                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "out=pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_code_1/metrics/cleaned_deepseek_metrics_result.csv\")\n",
    "print(\"********* Empty Strings/ NaN values ***********\")\n",
    "out.apply(lambda col: col.isna().sum() + (col == '').sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.726913331027324, 0.8099398175111628)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"RTC_deepseek\"].mean(), out[\"Pass@1_deepseek\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codedf = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/results/cleaned_deepseek_exps_result.csv\")\n",
    "df1 = codedf[[\"Generated_Code_deepseek_2\", \"query_id\", \"corpus_id\"]]\n",
    "df2 = out[out['Generated_Code_deepseek_2'].isna() | (out['Generated_Code_deepseek_2'] == '')][[\"Generated_Code_deepseek_2\", \"query_id\", \"corpus_id\"]].rename({\"Generated_Code_deepseek_2\": \"Cleaned_Generated_Code_deepseek_2\"})\n",
    "result_df=pd.merge(df1, df2, on=\"query_id\" and \"corpus_id\",how =\"inner\")\n",
    "result_df.to_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/cleaned_deepseek2_missing_val.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Generated_Code_deepseek_1</th>\n",
       "      <th>Generated_Code_deepseek_2</th>\n",
       "      <th>Generated_Code_deepseek_3</th>\n",
       "      <th>Generated_Code_deepseek_4</th>\n",
       "      <th>Original_Code</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>Sim_Code_deepseek_1</th>\n",
       "      <th>Exact_Match_deepseek_1</th>\n",
       "      <th>Sim_Code_deepseek_2</th>\n",
       "      <th>Exact_Match_deepseek_2</th>\n",
       "      <th>Sim_Code_deepseek_3</th>\n",
       "      <th>Exact_Match_deepseek_3</th>\n",
       "      <th>Sim_Code_deepseek_4</th>\n",
       "      <th>Exact_Match_deepseek_4</th>\n",
       "      <th>RTC_deepseek</th>\n",
       "      <th>Pass@1_deepseek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def timespan(start_time):\\n    # code\\n    ret...</td>\n",
       "      <td>def timespan(start_time):\\n    return (datetim...</td>\n",
       "      <td>def timespan(start_time):\\n    \"\"\"Return time ...</td>\n",
       "      <td>d9</td>\n",
       "      <td>q9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.805496</td>\n",
       "      <td>False</td>\n",
       "      <td>0.921541</td>\n",
       "      <td>False</td>\n",
       "      <td>0.431759</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def __exit__(self, exc_type, exc_val, exc_tb):...</td>\n",
       "      <td>def context(self):\\n    try:\\n        # code\\n...</td>\n",
       "      <td>def context(self):\\n        \"\"\"\\n        Creat...</td>\n",
       "      <td>d31</td>\n",
       "      <td>q31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.658593</td>\n",
       "      <td>False</td>\n",
       "      <td>0.704185</td>\n",
       "      <td>False</td>\n",
       "      <td>0.340695</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def add(a, b):\\n    # ... code ...\\n    return...</td>\n",
       "      <td>def calculate_correlation(a, b):\\n    return n...</td>\n",
       "      <td>def __add__(self,other):\\n        \"\"\"\\n       ...</td>\n",
       "      <td>d38</td>\n",
       "      <td>q38</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.640751</td>\n",
       "      <td>False</td>\n",
       "      <td>0.684916</td>\n",
       "      <td>False</td>\n",
       "      <td>0.331417</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>def round_to_int(number, precision):\\n    retu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def round_to_int(number, precision):\\n    roun...</td>\n",
       "      <td>def round_to_int(number, precision):\\n    prec...</td>\n",
       "      <td>def round_to_int(number, precision):\\n    \"\"\"R...</td>\n",
       "      <td>d62</td>\n",
       "      <td>q62</td>\n",
       "      <td>0.836063</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.889443</td>\n",
       "      <td>False</td>\n",
       "      <td>0.941842</td>\n",
       "      <td>False</td>\n",
       "      <td>0.666837</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>def create_abs_path(path):\\n    absolute_path ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def absolute_path(p):\\n    import os\\n    impo...</td>\n",
       "      <td>def create_path(path):\\n    import os\\n    if ...</td>\n",
       "      <td>def create_path(path):\\n    \"\"\"Creates a absol...</td>\n",
       "      <td>d65</td>\n",
       "      <td>q65</td>\n",
       "      <td>0.767821</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.810940</td>\n",
       "      <td>False</td>\n",
       "      <td>0.901522</td>\n",
       "      <td>False</td>\n",
       "      <td>0.620071</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                          Generated_Code_deepseek_1  \\\n",
       "8            8                                                NaN   \n",
       "30          30                                                NaN   \n",
       "37          37                                                NaN   \n",
       "61          61  def round_to_int(number, precision):\\n    retu...   \n",
       "64          64  def create_abs_path(path):\\n    absolute_path ...   \n",
       "\n",
       "   Generated_Code_deepseek_2  \\\n",
       "8                        NaN   \n",
       "30                       NaN   \n",
       "37                       NaN   \n",
       "61                       NaN   \n",
       "64                       NaN   \n",
       "\n",
       "                            Generated_Code_deepseek_3  \\\n",
       "8   def timespan(start_time):\\n    # code\\n    ret...   \n",
       "30  def __exit__(self, exc_type, exc_val, exc_tb):...   \n",
       "37  def add(a, b):\\n    # ... code ...\\n    return...   \n",
       "61  def round_to_int(number, precision):\\n    roun...   \n",
       "64  def absolute_path(p):\\n    import os\\n    impo...   \n",
       "\n",
       "                            Generated_Code_deepseek_4  \\\n",
       "8   def timespan(start_time):\\n    return (datetim...   \n",
       "30  def context(self):\\n    try:\\n        # code\\n...   \n",
       "37  def calculate_correlation(a, b):\\n    return n...   \n",
       "61  def round_to_int(number, precision):\\n    prec...   \n",
       "64  def create_path(path):\\n    import os\\n    if ...   \n",
       "\n",
       "                                        Original_Code corpus_id query_id  \\\n",
       "8   def timespan(start_time):\\n    \"\"\"Return time ...        d9       q9   \n",
       "30  def context(self):\\n        \"\"\"\\n        Creat...       d31      q31   \n",
       "37  def __add__(self,other):\\n        \"\"\"\\n       ...       d38      q38   \n",
       "61  def round_to_int(number, precision):\\n    \"\"\"R...       d62      q62   \n",
       "64  def create_path(path):\\n    \"\"\"Creates a absol...       d65      q65   \n",
       "\n",
       "    Sim_Code_deepseek_1  Exact_Match_deepseek_1  Sim_Code_deepseek_2  \\\n",
       "8              0.000000                   False                  0.0   \n",
       "30             0.000000                   False                  0.0   \n",
       "37             0.000000                   False                  0.0   \n",
       "61             0.836063                   False                  0.0   \n",
       "64             0.767821                   False                  0.0   \n",
       "\n",
       "    Exact_Match_deepseek_2  Sim_Code_deepseek_3  Exact_Match_deepseek_3  \\\n",
       "8                    False             0.805496                   False   \n",
       "30                   False             0.658593                   False   \n",
       "37                   False             0.640751                   False   \n",
       "61                   False             0.889443                   False   \n",
       "64                   False             0.810940                   False   \n",
       "\n",
       "    Sim_Code_deepseek_4  Exact_Match_deepseek_4  RTC_deepseek  Pass@1_deepseek  \n",
       "8              0.921541                   False      0.431759             0.50  \n",
       "30             0.704185                   False      0.340695             0.25  \n",
       "37             0.684916                   False      0.331417             0.00  \n",
       "61             0.941842                   False      0.666837             0.75  \n",
       "64             0.901522                   False      0.620071             0.75  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>code</th>\n",
       "      <th>explanation_granite_1</th>\n",
       "      <th>explanation_granite_2</th>\n",
       "      <th>explanation_granite_3</th>\n",
       "      <th>explanation_granite_4</th>\n",
       "      <th>explanation_deepseek_1_cleaned</th>\n",
       "      <th>explanation_deepseek_2_cleaned</th>\n",
       "      <th>explanation_deepseek_3_cleaned</th>\n",
       "      <th>explanation_deepseek_4_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>q9</td>\n",
       "      <td>python compare timespan to number</td>\n",
       "      <td>d9</td>\n",
       "      <td>def timespan(start_time):\\n    \"\"\"Return time ...</td>\n",
       "      <td>\\nThe provided code defines a function called ...</td>\n",
       "      <td>\\n1. `def timespan(start_time):` - This line d...</td>\n",
       "      <td>\\nThis code snippet defines a function called ...</td>\n",
       "      <td>\\nThe code snippet defines a function called `...</td>\n",
       "      <td>The function `timespan` calculates the duratio...</td>\n",
       "      <td>def timespan(start_time):    \"\"\"Return time in...</td>\n",
       "      <td>The code snippet is a function called timespan...</td>\n",
       "      <td>The code snippet is a function called timespan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 query_id                                doc corpus_id  \\\n",
       "8           8       q9  python compare timespan to number        d9   \n",
       "\n",
       "                                                code  \\\n",
       "8  def timespan(start_time):\\n    \"\"\"Return time ...   \n",
       "\n",
       "                               explanation_granite_1  \\\n",
       "8  \\nThe provided code defines a function called ...   \n",
       "\n",
       "                               explanation_granite_2  \\\n",
       "8  \\n1. `def timespan(start_time):` - This line d...   \n",
       "\n",
       "                               explanation_granite_3  \\\n",
       "8  \\nThis code snippet defines a function called ...   \n",
       "\n",
       "                               explanation_granite_4  \\\n",
       "8  \\nThe code snippet defines a function called `...   \n",
       "\n",
       "                      explanation_deepseek_1_cleaned  \\\n",
       "8  The function `timespan` calculates the duratio...   \n",
       "\n",
       "                      explanation_deepseek_2_cleaned  \\\n",
       "8  def timespan(start_time):    \"\"\"Return time in...   \n",
       "\n",
       "                      explanation_deepseek_3_cleaned  \\\n",
       "8  The code snippet is a function called timespan...   \n",
       "\n",
       "                      explanation_deepseek_4_cleaned  \n",
       "8  The code snippet is a function called timespan...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated_Code_deepseek_1</th>\n",
       "      <th>Generated_Code_deepseek_2</th>\n",
       "      <th>Generated_Code_deepseek_3</th>\n",
       "      <th>Generated_Code_deepseek_4</th>\n",
       "      <th>Original_Code</th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>query_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>timespan(start_time, current_time)\\ntimespan(1...</td>\n",
       "      <td>def timespan(start_time):  \\n    \"\"\" \"\"\"  \\n  ...</td>\n",
       "      <td>def timespan(start_time):\\n    # code\\n    ret...</td>\n",
       "      <td>The code snippet is a function named `timespan...</td>\n",
       "      <td>def timespan(start_time):\\n    \"\"\"Return time ...</td>\n",
       "      <td>d9</td>\n",
       "      <td>q9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Generated_Code_deepseek_1  \\\n",
       "8  timespan(start_time, current_time)\\ntimespan(1...   \n",
       "\n",
       "                           Generated_Code_deepseek_2  \\\n",
       "8  def timespan(start_time):  \\n    \"\"\" \"\"\"  \\n  ...   \n",
       "\n",
       "                           Generated_Code_deepseek_3  \\\n",
       "8  def timespan(start_time):\\n    # code\\n    ret...   \n",
       "\n",
       "                           Generated_Code_deepseek_4  \\\n",
       "8  The code snippet is a function named `timespan...   \n",
       "\n",
       "                                       Original_Code corpus_id query_id  \n",
       "8  def timespan(start_time):\\n    \"\"\"Return time ...        d9       q9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputdf = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CoSQA_explanations_query_code.csv\")\n",
    "codedf = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_code_1/code_generation/cleaned_deepseek_exps_result.csv\")\n",
    "\n",
    "display(out[out['Generated_Code_deepseek_2'].isna() | (out['Generated_Code_deepseek_2'] == '')].head())\n",
    "display(inputdf[(inputdf[\"corpus_id\"] == \"d9\") & (inputdf[\"query_id\"] == \"q9\")])\n",
    "display(codedf[(codedf[\"corpus_id\"] == \"d9\") & (codedf[\"query_id\"] == \"q9\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20604, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codedf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Original Code ***************** \n",
      " def writeBoolean(self, n):\n",
      "        \"\"\"\n",
      "        Writes a Boolean to the stream.\n",
      "        \"\"\"\n",
      "        t = TYPE_BOOL_TRUE\n",
      "\n",
      "        if n is False:\n",
      "            t = TYPE_BOOL_FALSE\n",
      "\n",
      "        self.stream.write(t)\n",
      "*************** Generated_Code_deepseek_2 ***************** \n",
      " def writeBoolean(self, n):\n",
      "    t = TYPE_BOOL_TRUE\n",
      "    if n == False:\n",
      "        t = TYPE_BOOL_FALSE\n",
      "    self.stream.write(t)\n",
      "*************** Similarity Score ***************** \n",
      " 0.8176217079162598\n"
     ]
    }
   ],
   "source": [
    "print(\"*************** Original Code ***************** \\n\",out.iloc[0][\"Original_Code\"])\n",
    "print(\"*************** Generated_Code_deepseek_2 ***************** \\n\",out.iloc[0][\"Generated_Code_deepseek_2\"])\n",
    "print(\"*************** Similarity Score ***************** \\n\",out.iloc[3][\"Sim_Code_deepseek_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Granite - Cleaned Explanation and Cleaned Generated Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* Empty Strings/ NaN values ***********\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                     0\n",
       "Generated_Code_granite_1     918\n",
       "Generated_Code_granite_2     875\n",
       "Generated_Code_granite_3     591\n",
       "Generated_Code_granite_4    1585\n",
       "Original_Code                  0\n",
       "corpus_id                      0\n",
       "query_id                       0\n",
       "Sim_Code_granite_1             0\n",
       "Exact_Match_granite_1          0\n",
       "Sim_Code_granite_2             0\n",
       "Exact_Match_granite_2          0\n",
       "Sim_Code_granite_3             0\n",
       "Exact_Match_granite_3          0\n",
       "Sim_Code_granite_4             0\n",
       "Exact_Match_granite_4          0\n",
       "RTC_granite                    0\n",
       "Pass@1_granite                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "out=pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/results/cleaned_granite_metrics_result.csv\")\n",
    "print(\"********* Empty Strings/ NaN values ***********\")\n",
    "out.apply(lambda col: col.isna().sum() + (col == '').sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8384574330993138, 0.9375849349640847)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"RTC_granite\"].mean(), out[\"Pass@1_granite\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** Original Code ***************** \n",
      " def writeBoolean(self, n):\n",
      "        \"\"\"\n",
      "        Writes a Boolean to the stream.\n",
      "        \"\"\"\n",
      "        t = TYPE_BOOL_TRUE\n",
      "\n",
      "        if n is False:\n",
      "            t = TYPE_BOOL_FALSE\n",
      "\n",
      "        self.stream.write(t)\n",
      "*************** Generated_Code_granite_2 ***************** \n",
      " def writeBoolean(self, n):\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    This function writes a Boolean value to the stream.\n",
      "\n",
      "    Parameters:\n",
      "    n (bool): The Boolean value to be written to the stream.\n",
      "*************** Similarity Score ***************** \n",
      " 0.8942779302597046\n"
     ]
    }
   ],
   "source": [
    "print(\"*************** Original Code ***************** \\n\",out.iloc[0][\"Original_Code\"])\n",
    "print(\"*************** Generated_Code_granite_2 ***************** \\n\",out.iloc[0][\"Generated_Code_granite_2\"])\n",
    "print(\"*************** Similarity Score ***************** \\n\",out.iloc[3][\"Sim_Code_granite_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWE-RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'similarities': [{'path': 'example.py', 'pred_change': '@@ -1,2 +1,2 @@\\n-def sort_list(lst):\\n+def sort_list(lst: list[int]) -> list[int]:\\n     return sorted(lst)', 'oracle_change': '@@ -1,2 +1,2 @@\\n-def sort_list(lst):\\n+def sort_list(lst: list[int]) -> list[int]:\\n     return sorted(lst)', 'similarity': 1.0}], 'thought': '...thoughts by LLM', 'answer': '```python\\n### example.py\\n<<<<<<< SEARCH\\ndef sort_list(lst):\\n=======\\ndef sort_list(lst: list[int]) -> list[int]:\\n>>>>>>> REPLACE\\n```'}\n"
     ]
    }
   ],
   "source": [
    "import swerl.src.swerl as sw\n",
    "\n",
    "file = \"\"\"\n",
    "def sort_list(lst):\n",
    "    return sorted(lst)\n",
    "\"\"\".strip()\n",
    "\n",
    "oracle_file = \"\"\"\n",
    "def sort_list(lst: list[int]) -> list[int]:\n",
    "    return sorted(lst)\n",
    "\"\"\".strip()\n",
    "\n",
    "context = {\"example.py\": file}\n",
    "oracle = {\"example.py\": oracle_file}\n",
    "\n",
    "output = \"\"\"\n",
    "<think>\n",
    "...thoughts by LLM\n",
    "</think>\n",
    "<solution>\n",
    "```python\n",
    "### example.py\n",
    "<<<<<<< SEARCH\n",
    "def sort_list(lst):\n",
    "=======\n",
    "def sort_list(lst: list[int]) -> list[int]:\n",
    ">>>>>>> REPLACE\n",
    "```\n",
    "</solution>\n",
    "\"\"\".strip()\n",
    "\n",
    "reward, metadata = sw.core.reward.calculate_search_replace_reward(context, oracle, output)\n",
    "assert reward == 1.0\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Code:\n",
      " {'example.py': 'def writeBoolean(self, n):\\n        \"\"\"\\n        Writes a Boolean to the stream.\\n        \"\"\"\\n        t = TYPE_BOOL_TRUE\\n\\n        if n is False:\\n            t = TYPE_BOOL_FALSE\\n\\n        self.stream.write(t)'}\n",
      "\n",
      "Generated Code:\n",
      " {'example.py': '```python\\ndef flip_stream(n):\\n    current_value = 1 if (n % 2 == 1) else 0\\n    return current_value\\n```'}\n",
      "\n",
      "Explanation:\n",
      " The doc string and code both write the boolean value 1 to the stream. The code uses a condition based on n, flipping between TRUE and FALSE values. The stream is a mechanism for writing to a binary stream.\n",
      "\n",
      "\n",
      "The docstring and code both write the boolean value 1 to the stream. The code uses a condition based on n, flipping between TRUE and FALSE values. The stream is a mechanism for writing to a binary stream.\n",
      "\n",
      "Reward: -1.0\n",
      "Metadata: {'error': 'count of <think> is not 1'}\n",
      "⚠️ Explanation did not lead to perfect match. Review metadata above.\n"
     ]
    }
   ],
   "source": [
    "import swerl.src.swerl as sw\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSVs\n",
    "out = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/results/exps_10_sample_result.csv\").iloc[0]\n",
    "df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CoSQA_explanations_vllm1.csv\")\n",
    "\n",
    "# Match keys\n",
    "querid_val = out['query_id']\n",
    "corpus_id = out['corpus_id']\n",
    "code = out['Original_Code']\n",
    "\n",
    "# Filter explanation\n",
    "result_exp = df.loc[\n",
    "    (df['query_id'] == querid_val) &\n",
    "    (df['corpus_id'] == corpus_id) &\n",
    "    (df['code'] == code),\n",
    "    'explanation_deepseek_1'\n",
    "]\n",
    "\n",
    "# Proceed if explanation exists\n",
    "if not result_exp.empty:\n",
    "    explanation = result_exp.values[0].replace(\"</think>\", \"\").strip()\n",
    "    #explanation = result_exp.values[0]\n",
    "\n",
    "    original_code = {\"example.py\": out[\"Original_Code\"]}\n",
    "    generated_code = {\"example.py\": out[\"Generated_Code_deepseek_1\"]}\n",
    "    output = explanation\n",
    "\n",
    "    # Show everything for debugging\n",
    "    print(\"Original Code:\\n\", original_code)\n",
    "    print(\"\\nGenerated Code:\\n\", generated_code)\n",
    "    print(\"\\nExplanation:\\n\", output)\n",
    "\n",
    "    reward, metadata = sw.core.reward.calculate_search_replace_reward(generated_code, original_code, output)\n",
    "    print(\"\\nReward:\", reward)\n",
    "    print(\"Metadata:\", metadata)\n",
    "\n",
    "    # Safer check\n",
    "    if reward != 1.0:\n",
    "        print(\"⚠️ Explanation did not lead to perfect match. Review metadata above.\")\n",
    "    else:\n",
    "        print(\"Reward is 1.0! Explanation was effective.\")\n",
    "else:\n",
    "    print(\"No matching explanation found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Code:\n",
      "{'example.py': 'def writeBoolean(self, n):\\n        \"\"\"\\n        Writes a Boolean to the stream.\\n        \"\"\"\\n        t = TYPE_BOOL_TRUE\\n\\n        if n is False:\\n            t = TYPE_BOOL_FALSE\\n\\n        self.stream.write(t)'}\n",
      "\n",
      "Generated Code:\n",
      "{'example.py': '```python\\ndef flip_stream(n):\\n    current_value = 1 if (n % 2 == 1) else 0\\n    return current_value\\n```'}\n",
      "\n",
      "Explanation Output:\n",
      "The doc string and code both write the boolean value 1 to the stream. The code uses a condition based on n, flipping between TRUE and FALSE values. The stream is a mechanism for writing to a binary stream.\n",
      "\n",
      "\n",
      "The docstring and code both write the boolean value 1 to the stream. The code uses a condition based on n, flipping between TRUE and FALSE values. The stream is a mechanism for writing to a binary stream.\n",
      "\n",
      "Reward and Metadata:\n",
      "Reward: -1.0\n",
      "Metadata: {'error': 'count of <think> is not 1'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Code:\")\n",
    "print(original_code)\n",
    "\n",
    "print(\"\\nGenerated Code:\")\n",
    "print(generated_code)\n",
    "\n",
    "print(\"\\nExplanation Output:\")\n",
    "print(output)\n",
    "\n",
    "print(\"\\nReward and Metadata:\")\n",
    "reward, metadata = sw.core.reward.calculate_search_replace_reward(generated_code, original_code, output)\n",
    "print(\"Reward:\", reward)\n",
    "print(\"Metadata:\", metadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning of Code - Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import textwrap\n",
    "\n",
    "def clean_to_function_or_class(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = textwrap.dedent(text).strip()\n",
    "\n",
    "    def extract_method_signature(text):\n",
    "        \"\"\"\n",
    "        Extracts method signatures in the format ClassName.method_name(self, ...)\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "\n",
    "        # Match things like: LabeledMatrix.add(self, other)\n",
    "        pattern = re.compile(r'\\b(\\w+\\.\\w+\\s*\\([^)]*\\))')\n",
    "        matches = pattern.findall(text)\n",
    "\n",
    "        return matches[-1].strip() if matches else \"\"\n",
    "    \n",
    "    def remove_empty_docstring(code):\n",
    "        lines = code.splitlines()\n",
    "        cleaned = []\n",
    "        skip_next = False\n",
    "        for i, line in enumerate(lines):\n",
    "            if i < len(lines) - 1 and re.match(r'^\\s*\"\"\"\\s*\"\"\"\\s*$', line) and re.match(r'^\\s*\"\"\"\\s*\"\"\"\\s*$', lines[i+1]):\n",
    "                skip_next = True\n",
    "                continue\n",
    "            elif skip_next:\n",
    "                skip_next = False\n",
    "                continue\n",
    "            cleaned.append(line)\n",
    "        return \"\\n\".join(cleaned)\n",
    "\n",
    "    try:\n",
    "        tree = ast.parse(text)\n",
    "        for node in reversed(tree.body):\n",
    "            if isinstance(node, (ast.FunctionDef, ast.ClassDef)):\n",
    "                segment = ast.get_source_segment(text, node)\n",
    "                return remove_empty_docstring(segment)\n",
    "    except SyntaxError:\n",
    "        pass\n",
    "\n",
    "    # More flexible fallback regex: allow any indent and line count\n",
    "    func_pattern = re.compile(\n",
    "        r\"^(def\\s+\\w+\\(.*?\\):\\s*\\n(?:[ \\t]+.+\\n?)+)\", re.MULTILINE)\n",
    "    class_pattern = re.compile(\n",
    "        r\"^(class\\s+\\w+.*?:\\s*\\n(?:[ \\t]+.+\\n?)+)\", re.MULTILINE)\n",
    "\n",
    "\n",
    "    matches = func_pattern.findall(text) or class_pattern.findall(text)\n",
    "    if matches:\n",
    "        return remove_empty_docstring(matches[-1].strip())\n",
    "\n",
    "    return extract_method_signature(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def timespan(start_time):  \\n    timespan = datetime.datetime.now() - start_time  \\n    timespan_ms = timespan.total_seconds() * 1000  \\n    return timespan_ms'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation = \"\"\"def timespan(start_time):  \n",
    "    \"\"\"\"\"\" \"\"\"\"\"\"  \n",
    "    timespan = datetime.datetime.now() - start_time  \n",
    "    timespan_ms = timespan.total_seconds() * 1000  \n",
    "    return timespan_ms  \n",
    "  \n",
    "\n",
    "Wait, I think I might have missed something in the description. Let me read it again. The function is called timespan, and it's supposed to return the time in milliseconds from start_time. The start_time is passed as a parameter. The function uses datetime.datetime.now() to get the current time, subtracts start_time, converts to total seconds, multiplies by 1000 to get milliseconds, and returns that.\n",
    "\n",
    "So, the Python function should take start_time as an argument, compute the difference, convert to milliseconds, and return.\n",
    "\n",
    "Looking at the code provided, the function is written as def timespan(start_time):, which matches the description. Then the docstring is written as \"\"\"\"\"\"Return time in milliseconds from start_time\"\"\"\"\"\" followed by the code.\n",
    "\n",
    "But in the code I wrote, the function does return timespan_ms, which is correct. So the code seems to match.\n",
    "\n",
    "Wait, but in the description, the first line is a function definition. Then the docstring is multi-line. But in the code I wrote, the docstring is empty, and the code is correctly written. So perhaps the initial code provided by the user is wrong. The user wants the function name and structure to exactly match the description.\n",
    "\n",
    "So, according to the description, the function should be named timespan, take a parameter start_time, and return the difference in milliseconds.\n",
    "\n",
    "Looking at the code the user provided, it's written as:\n",
    "\n",
    "def timespan(start_time):  \n",
    "    \"\"\"\"\"\" \"\"\"\"\"\"  \n",
    "    timespan = datetime.datetime.now() - start_time  \n",
    "    timespan_ms = timespan.total_seconds() * 1000  \n",
    "    return timespan_ms  \n",
    "\n",
    "Which is not matching. The first line is a function definition. Then the docstring is empty, and the code is correct. So that doesn't match the description.\n",
    "\n",
    "But the user's code to write is the function. So perhaps I should write the correct function code, regardless of the provided code.\n",
    "\n",
    "Wait, the user said: \"\"Do not provide explanations, comments, markdown, parameter descriptions, or return values. Ensure that the function name and structure exactly match the description.\"\"\n",
    "\n",
    "So I need to write the Python function as per the description. So the function should be named timespan, take start_time as a parameter, compute the difference, return in milliseconds.\n",
    "\n",
    "In Python, that would be:\n",
    "\n",
    "def timespan(start_time):  \n",
    "    timespan = datetime.datetime.now() - start_time  \n",
    "    timespan_ms = timespan.total_seconds() * 1000  \n",
    "    return timespan_ms  \n",
    "\n",
    "So that's the code.\n",
    "\n",
    "Looking back at the code I provided, I had:\n",
    "\n",
    "def timespan(start_time):  \n",
    "    \"\"\"\"\"\" \"\"\"\"\"\"  \n",
    "    timespan = datetime.datetime.now() - start_time  \n",
    "    timespan_ms = timespan.total_seconds() * 1000  \n",
    "    return timespan_ms  \n",
    "\n",
    "Which is not correct, because the docstring is empty. So perhaps I made a mistake earlier.\n",
    "\n",
    "But according to the description, the function is named timespan, takes start_time as a parameter, and returns the time in milliseconds.\n",
    "\n",
    "So the correct code is as I wrote above.\n",
    "\n",
    "So the Python function is as written.\n",
    "</think>\n",
    "\n",
    "def timespan(start_time):  \n",
    "    timespan = datetime.datetime.now() - start_time  \n",
    "    timespan_ms = timespan.total_seconds() * 1000  \n",
    "    return timespan_ms\"\"\"\n",
    "clean_to_function_or_class(explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class ActionContextManager:\\n    def context(self):\\n        parent = self._ACTION_CONTEXT.set(self)\\n        try:\\n            yield self\\n        finally:\\n            self._ACTION_CONTEXT.reset(parent)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2 = \"\"\"\n",
    "\"</think>\n",
    "\n",
    "To create a Python context manager that adheres to the described functionality, we can define the `context` function as follows:\n",
    "\n",
    "```python\n",
    "class ActionContextManager:\n",
    "    def context(self):\n",
    "        parent = self._ACTION_CONTEXT.set(self)\n",
    "        try:\n",
    "            yield self\n",
    "        finally:\n",
    "            self._ACTION_CONTEXT.reset(parent)\n",
    "```\"\n",
    "\"\"\"\n",
    "clean_to_function_or_class(exp2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LabeledMatrix.add(self, other)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp3=\"\"\"\n",
    "\"LabeledMatrix.add(self, other)\n",
    "\n",
    "Let's start by opening a docstring that explains the purpose of the code snippet, which is to add two matrices with the same shape, expecting one dimension in Python.\n",
    "\n",
    "Then, the method checks for the assertion that the number of columns in self.matrix and other.matrix are equal. If not, it raises an error.\n",
    "\n",
    "After that, it concatenates the self.matrix and other.matrix along axis=0, creating a new matrix.\n",
    "\n",
    "Finally, it returns a new LabeledMatrix object with the concatenated matrix and the same labels as self.\n",
    "\n",
    "Each statement in the code snippet is crucial for the functionality. The docstring provides context and purpose, the method checks for consistency before proceeding, the concatenation combines the matrices correctly, and returning the new object ensures the class maintains its structure.\n",
    "\n",
    "Now, let's write the Python function corresponding to the description.\n",
    "</think>\n",
    "\n",
    "LabeledMatrix.add(self, other)\"\n",
    "\"\"\"\n",
    "clean_to_function_or_class(exp3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<unknown>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<unknown>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:7: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:2: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<unknown>:7: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<unknown>:10: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<unknown>:2: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<unknown>:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<unknown>:4: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:4: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<unknown>:4: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:5: SyntaxWarning: invalid escape sequence '\\;'\n",
      "<unknown>:2: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:9: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:3: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:3: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<unknown>:5: SyntaxWarning: invalid escape sequence '\\;'\n",
      "<unknown>:2: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<unknown>:8: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<unknown>:6: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<unknown>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<unknown>:3: SyntaxWarning: invalid escape sequence '\\d'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing or empty values in cleaned: 872\n",
      "Missing or empty values in csv['Generated_Code_deepseek_2']: 2051\n",
      "Indices with missing/empty in cleaned: [61, 78, 101, 111, 118, 191, 222, 244, 256, 317, 326, 362, 365, 519, 535, 556, 635, 647, 689, 699, 702, 810, 838, 848, 884, 907, 935, 939, 964, 966, 1032, 1054, 1090, 1111, 1139, 1141, 1178, 1202, 1252, 1281, 1320, 1327, 1363, 1373, 1464, 1472, 1512, 1530, 1577, 1662, 1731, 1736, 1756, 1757, 1807, 1827, 1846, 1901, 1958, 1975, 2049, 2056, 2083, 2097, 2102, 2130, 2165, 2182, 2324, 2336, 2377, 2395, 2435, 2467, 2502, 2538, 2611, 2628, 2633, 2665, 2772, 2788, 2792, 2797, 2827, 2836, 2850, 2911, 2928, 2965, 3015, 3044, 3060, 3144, 3168, 3197, 3198, 3202, 3209, 3210, 3221, 3240, 3271, 3276, 3291, 3295, 3340, 3361, 3378, 3471, 3516, 3548, 3568, 3570, 3659, 3663, 3673, 3677, 3718, 3758, 3767, 3778, 3795, 3814, 3832, 3841, 3877, 3894, 3930, 3995, 4020, 4098, 4138, 4153, 4170, 4189, 4231, 4292, 4328, 4379, 4414, 4431, 4443, 4487, 4489, 4552, 4558, 4562, 4579, 4616, 4656, 4722, 4725, 4729, 4786, 4787, 4792, 4874, 4941, 4972, 4979, 5031, 5062, 5132, 5135, 5145, 5148, 5171, 5181, 5191, 5207, 5233, 5234, 5255, 5278, 5340, 5360, 5373, 5439, 5485, 5507, 5512, 5514, 5519, 5563, 5612, 5647, 5668, 5711, 5735, 5746, 5770, 5781, 5904, 5952, 5959, 5977, 5988, 6078, 6136, 6142, 6143, 6229, 6237, 6269, 6380, 6404, 6429, 6431, 6442, 6455, 6474, 6506, 6563, 6569, 6574, 6605, 6625, 6634, 6638, 6712, 6733, 6745, 6777, 6943, 6946, 7016, 7112, 7175, 7255, 7337, 7407, 7426, 7427, 7429, 7455, 7492, 7503, 7549, 7668, 7681, 7710, 7743, 7745, 7808, 7816, 7869, 7872, 7892, 7908, 7911, 7955, 8000, 8036, 8056, 8073, 8116, 8121, 8130, 8134, 8180, 8209, 8289, 8296, 8323, 8343, 8371, 8381, 8408, 8416, 8425, 8439, 8492, 8506, 8523, 8539, 8572, 8602, 8619, 8623, 8630, 8638, 8663, 8676, 8694, 8730, 8787, 8797, 8804, 8822, 8838, 8941, 9008, 9017, 9130, 9154, 9163, 9180, 9182, 9203, 9252, 9318, 9321, 9323, 9340, 9344, 9376, 9413, 9473, 9585, 9603, 9611, 9644, 9645, 9655, 9656, 9692, 9718, 9720, 9730, 9746, 9781, 9803, 9882, 9887, 9895, 9949, 9969, 10017, 10125, 10139, 10204, 10241, 10294, 10305, 10307, 10320, 10412, 10421, 10508, 10518, 10550, 10577, 10584, 10598, 10670, 10703, 10719, 10745, 10817, 10893, 10903, 10914, 10922, 10931, 10946, 10977, 10983, 10999, 11081, 11118, 11126, 11168, 11210, 11219, 11247, 11286, 11298, 11301, 11339, 11346, 11358, 11377, 11386, 11427, 11479, 11493, 11527, 11535, 11568, 11574, 11576, 11616, 11621, 11626, 11674, 11706, 11712, 11763, 11774, 11808, 11810, 11822, 11856, 11887, 12009, 12036, 12045, 12047, 12050, 12058, 12075, 12155, 12199, 12327, 12330, 12351, 12447, 12477, 12489, 12526, 12575, 12583, 12606, 12640, 12678, 12832, 12865, 12892, 12910, 12937, 12947, 12977, 13015, 13031, 13069, 13132, 13211, 13233, 13332, 13410, 13437, 13451, 13458, 13464, 13495, 13505, 13534, 13546, 13612, 13668, 13687, 13713, 13726, 13746, 13758, 13812, 13813, 13822, 13833, 13898, 13906, 13935, 14008, 14069, 14109, 14214, 14216, 14241, 14301, 14302, 14304, 14446, 14509, 14572, 14588, 14605, 14619, 14660, 14674, 14695, 14751, 14766, 14785, 14804, 14810, 14817, 14835, 14859, 14908, 14914, 14980, 15044, 15076, 15127, 15131, 15263, 15280, 15422, 15478, 15485, 15498, 15503, 15553, 15556, 15564, 15605, 15615, 15661, 15665, 15719, 15721, 15734, 15818, 15870, 15884, 15932, 15935, 16054, 16073, 16085, 16097, 16100, 16106, 16141, 16154, 16251, 16356, 16358, 16360, 16384, 16409, 16419, 16446, 16576, 16649, 16654, 16662, 16667, 16673, 16678, 16682, 16690, 16698, 16712, 16714, 16737, 16756, 16784, 16787, 16788, 16796, 16800, 16802, 16804, 16823, 16824, 16828, 16834, 16861, 16868, 16888, 16898, 16932, 16934, 16945, 16985, 16994, 17000, 17003, 17005, 17006, 17024, 17028, 17053, 17060, 17061, 17081, 17113, 17114, 17120, 17122, 17134, 17141, 17181, 17183, 17187, 17200, 17239, 17246, 17256, 17270, 17272, 17283, 17290, 17299, 17302, 17328, 17332, 17343, 17345, 17350, 17353, 17354, 17356, 17360, 17375, 17392, 17396, 17404, 17408, 17409, 17410, 17411, 17413, 17427, 17428, 17432, 17442, 17465, 17467, 17480, 17494, 17497, 17499, 17511, 17512, 17540, 17547, 17571, 17574, 17575, 17595, 17601, 17607, 17620, 17624, 17625, 17636, 17637, 17648, 17653, 17668, 17681, 17683, 17686, 17727, 17733, 17736, 17740, 17742, 17758, 17770, 17775, 17784, 17795, 17800, 17802, 17816, 17821, 17834, 17836, 17846, 17852, 17856, 17866, 17900, 17903, 17904, 17923, 17927, 17934, 17937, 17939, 17940, 17951, 17982, 18054, 18056, 18059, 18060, 18062, 18063, 18075, 18079, 18083, 18092, 18114, 18116, 18130, 18136, 18152, 18159, 18164, 18169, 18195, 18205, 18227, 18272, 18273, 18274, 18276, 18280, 18286, 18289, 18292, 18306, 18314, 18322, 18334, 18344, 18364, 18365, 18372, 18378, 18379, 18381, 18384, 18396, 18398, 18425, 18426, 18427, 18464, 18465, 18477, 18492, 18494, 18500, 18510, 18516, 18517, 18524, 18529, 18534, 18554, 18570, 18576, 18591, 18596, 18623, 18630, 18635, 18638, 18643, 18644, 18654, 18655, 18657, 18684, 18687, 18690, 18712, 18713, 18717, 18718, 18729, 18763, 18771, 18803, 18807, 18809, 18814, 18816, 18822, 18833, 18836, 18837, 18838, 18840, 18842, 18848, 18856, 18858, 18868, 18871, 18872, 18878, 18899, 18917, 18926, 18948, 18960, 18990, 18992, 18995, 19008, 19014, 19026, 19027, 19052, 19075, 19093, 19097, 19110, 19130, 19134, 19144, 19149, 19171, 19176, 19187, 19191, 19209, 19242, 19249, 19263, 19268, 19277, 19291, 19299, 19309, 19343, 19347, 19350, 19360, 19362, 19396, 19399, 19426, 19457, 19465, 19466, 19467, 19478, 19488, 19520, 19525, 19526, 19531, 19572, 19580, 19592, 19598, 19600, 19635, 19654, 19680, 19689, 19724, 19738, 19743, 19746, 19754, 19773, 19774, 19798, 19817, 19832, 19839, 19848, 19889, 19977, 20018, 20033, 20045, 20059, 20073, 20089, 20110, 20130, 20159, 20172, 20229, 20267, 20270, 20286, 20289, 20299, 20327, 20337, 20382, 20394, 20410, 20420, 20447, 20453, 20478, 20480, 20491, 20525, 20586]\n",
      "Indices with missing/empty in Generated_Code_deepseek_2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "inputdf = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/anamikaghosh/CoSQA_explanations_query_code.csv\")\n",
    "csv = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/cleaned_deepseek_missing_val.csv\")\n",
    "csv2 = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_code_1/code_generation/cleaned_deepseek_exps_result.csv\")\n",
    "cleaned = [clean_to_function_or_class(desc) for desc in csv2[\"Generated_Code_deepseek_2\"]]\n",
    "cleaned_series = pd.Series(cleaned)\n",
    "\n",
    "# Find missing or empty values\n",
    "missing_in_cleaned = cleaned_series.isnull() | (cleaned_series == \"\")\n",
    "missing_in_generated = csv[\"Generated_Code_deepseek_2\"].isnull() | (csv[\"Generated_Code_deepseek_2\"].astype(str).str.strip() == \"\")\n",
    "\n",
    "# Print counts\n",
    "print(\"Missing or empty values in cleaned:\", missing_in_cleaned.sum())\n",
    "print(\"Missing or empty values in csv['Generated_Code_deepseek_2']:\", missing_in_generated.sum())\n",
    "\n",
    "# Optional: Print indices\n",
    "print(\"Indices with missing/empty in cleaned:\", cleaned_series[missing_in_cleaned].index.tolist())\n",
    "print(\"Indices with missing/empty in Generated_Code_deepseek_2:\", csv[missing_in_generated].index.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61,\n",
       " 78,\n",
       " 101,\n",
       " 111,\n",
       " 118,\n",
       " 191,\n",
       " 222,\n",
       " 244,\n",
       " 256,\n",
       " 317,\n",
       " 326,\n",
       " 362,\n",
       " 365,\n",
       " 519,\n",
       " 535,\n",
       " 556,\n",
       " 635,\n",
       " 647,\n",
       " 689,\n",
       " 699,\n",
       " 702,\n",
       " 810,\n",
       " 838,\n",
       " 848,\n",
       " 884,\n",
       " 907,\n",
       " 935,\n",
       " 939,\n",
       " 964,\n",
       " 966,\n",
       " 1032,\n",
       " 1054,\n",
       " 1090,\n",
       " 1111,\n",
       " 1139,\n",
       " 1141,\n",
       " 1178,\n",
       " 1202,\n",
       " 1252,\n",
       " 1281,\n",
       " 1320,\n",
       " 1327,\n",
       " 1363,\n",
       " 1373,\n",
       " 1464,\n",
       " 1472,\n",
       " 1512,\n",
       " 1530,\n",
       " 1577,\n",
       " 1662,\n",
       " 1731,\n",
       " 1736,\n",
       " 1756,\n",
       " 1757,\n",
       " 1807,\n",
       " 1827,\n",
       " 1846,\n",
       " 1901,\n",
       " 1958,\n",
       " 1975,\n",
       " 2049,\n",
       " 2056,\n",
       " 2083,\n",
       " 2097,\n",
       " 2102,\n",
       " 2130,\n",
       " 2165,\n",
       " 2182,\n",
       " 2324,\n",
       " 2336,\n",
       " 2377,\n",
       " 2395,\n",
       " 2435,\n",
       " 2467,\n",
       " 2502,\n",
       " 2538,\n",
       " 2611,\n",
       " 2628,\n",
       " 2633,\n",
       " 2665,\n",
       " 2772,\n",
       " 2788,\n",
       " 2792,\n",
       " 2797,\n",
       " 2827,\n",
       " 2836,\n",
       " 2850,\n",
       " 2911,\n",
       " 2928,\n",
       " 2965,\n",
       " 3015,\n",
       " 3044,\n",
       " 3060,\n",
       " 3144,\n",
       " 3168,\n",
       " 3197,\n",
       " 3198,\n",
       " 3202,\n",
       " 3209,\n",
       " 3210,\n",
       " 3221,\n",
       " 3240,\n",
       " 3271,\n",
       " 3276,\n",
       " 3291,\n",
       " 3295,\n",
       " 3340,\n",
       " 3361,\n",
       " 3378,\n",
       " 3471,\n",
       " 3516,\n",
       " 3548,\n",
       " 3568,\n",
       " 3570,\n",
       " 3659,\n",
       " 3663,\n",
       " 3673,\n",
       " 3677,\n",
       " 3718,\n",
       " 3758,\n",
       " 3767,\n",
       " 3778,\n",
       " 3795,\n",
       " 3814,\n",
       " 3832,\n",
       " 3841,\n",
       " 3877,\n",
       " 3894,\n",
       " 3930,\n",
       " 3995,\n",
       " 4020,\n",
       " 4098,\n",
       " 4138,\n",
       " 4153,\n",
       " 4170,\n",
       " 4189,\n",
       " 4231,\n",
       " 4292,\n",
       " 4328,\n",
       " 4379,\n",
       " 4414,\n",
       " 4431,\n",
       " 4443,\n",
       " 4487,\n",
       " 4489,\n",
       " 4552,\n",
       " 4558,\n",
       " 4562,\n",
       " 4579,\n",
       " 4616,\n",
       " 4656,\n",
       " 4722,\n",
       " 4725,\n",
       " 4729,\n",
       " 4786,\n",
       " 4787,\n",
       " 4792,\n",
       " 4874,\n",
       " 4941,\n",
       " 4972,\n",
       " 4979,\n",
       " 5031,\n",
       " 5062,\n",
       " 5132,\n",
       " 5135,\n",
       " 5145,\n",
       " 5148,\n",
       " 5171,\n",
       " 5181,\n",
       " 5191,\n",
       " 5207,\n",
       " 5233,\n",
       " 5234,\n",
       " 5255,\n",
       " 5278,\n",
       " 5340,\n",
       " 5360,\n",
       " 5373,\n",
       " 5439,\n",
       " 5485,\n",
       " 5507,\n",
       " 5512,\n",
       " 5514,\n",
       " 5519,\n",
       " 5563,\n",
       " 5612,\n",
       " 5647,\n",
       " 5668,\n",
       " 5711,\n",
       " 5735,\n",
       " 5746,\n",
       " 5770,\n",
       " 5781,\n",
       " 5904,\n",
       " 5952,\n",
       " 5959,\n",
       " 5977,\n",
       " 5988,\n",
       " 6078,\n",
       " 6136,\n",
       " 6142,\n",
       " 6143,\n",
       " 6229,\n",
       " 6237,\n",
       " 6269,\n",
       " 6380,\n",
       " 6404,\n",
       " 6429,\n",
       " 6431,\n",
       " 6442,\n",
       " 6455,\n",
       " 6474,\n",
       " 6506,\n",
       " 6563,\n",
       " 6569,\n",
       " 6574,\n",
       " 6605,\n",
       " 6625,\n",
       " 6634,\n",
       " 6638,\n",
       " 6712,\n",
       " 6733,\n",
       " 6745,\n",
       " 6777,\n",
       " 6943,\n",
       " 6946,\n",
       " 7016,\n",
       " 7112,\n",
       " 7175,\n",
       " 7255,\n",
       " 7337,\n",
       " 7407,\n",
       " 7426,\n",
       " 7427,\n",
       " 7429,\n",
       " 7455,\n",
       " 7492,\n",
       " 7503,\n",
       " 7549,\n",
       " 7668,\n",
       " 7681,\n",
       " 7710,\n",
       " 7743,\n",
       " 7745,\n",
       " 7808,\n",
       " 7816,\n",
       " 7869,\n",
       " 7872,\n",
       " 7892,\n",
       " 7908,\n",
       " 7911,\n",
       " 7955,\n",
       " 8000,\n",
       " 8036,\n",
       " 8056,\n",
       " 8073,\n",
       " 8116,\n",
       " 8121,\n",
       " 8130,\n",
       " 8134,\n",
       " 8180,\n",
       " 8209,\n",
       " 8289,\n",
       " 8296,\n",
       " 8323,\n",
       " 8343,\n",
       " 8371,\n",
       " 8381,\n",
       " 8408,\n",
       " 8416,\n",
       " 8425,\n",
       " 8439,\n",
       " 8492,\n",
       " 8506,\n",
       " 8523,\n",
       " 8539,\n",
       " 8572,\n",
       " 8602,\n",
       " 8619,\n",
       " 8623,\n",
       " 8630,\n",
       " 8638,\n",
       " 8663,\n",
       " 8676,\n",
       " 8694,\n",
       " 8730,\n",
       " 8787,\n",
       " 8797,\n",
       " 8804,\n",
       " 8822,\n",
       " 8838,\n",
       " 8941,\n",
       " 9008,\n",
       " 9017,\n",
       " 9130,\n",
       " 9154,\n",
       " 9163,\n",
       " 9180,\n",
       " 9182,\n",
       " 9203,\n",
       " 9252,\n",
       " 9318,\n",
       " 9321,\n",
       " 9323,\n",
       " 9340,\n",
       " 9344,\n",
       " 9376,\n",
       " 9413,\n",
       " 9473,\n",
       " 9585,\n",
       " 9603,\n",
       " 9611,\n",
       " 9644,\n",
       " 9645,\n",
       " 9655,\n",
       " 9656,\n",
       " 9692,\n",
       " 9718,\n",
       " 9720,\n",
       " 9730,\n",
       " 9746,\n",
       " 9781,\n",
       " 9803,\n",
       " 9882,\n",
       " 9887,\n",
       " 9895,\n",
       " 9949,\n",
       " 9969,\n",
       " 10017,\n",
       " 10125,\n",
       " 10139,\n",
       " 10204,\n",
       " 10241,\n",
       " 10294,\n",
       " 10305,\n",
       " 10307,\n",
       " 10320,\n",
       " 10412,\n",
       " 10421,\n",
       " 10508,\n",
       " 10518,\n",
       " 10550,\n",
       " 10577,\n",
       " 10584,\n",
       " 10598,\n",
       " 10670,\n",
       " 10703,\n",
       " 10719,\n",
       " 10745,\n",
       " 10817,\n",
       " 10893,\n",
       " 10903,\n",
       " 10914,\n",
       " 10922,\n",
       " 10931,\n",
       " 10946,\n",
       " 10977,\n",
       " 10983,\n",
       " 10999,\n",
       " 11081,\n",
       " 11118,\n",
       " 11126,\n",
       " 11168,\n",
       " 11210,\n",
       " 11219,\n",
       " 11247,\n",
       " 11286,\n",
       " 11298,\n",
       " 11301,\n",
       " 11339,\n",
       " 11346,\n",
       " 11358,\n",
       " 11377,\n",
       " 11386,\n",
       " 11427,\n",
       " 11479,\n",
       " 11493,\n",
       " 11527,\n",
       " 11535,\n",
       " 11568,\n",
       " 11574,\n",
       " 11576,\n",
       " 11616,\n",
       " 11621,\n",
       " 11626,\n",
       " 11674,\n",
       " 11706,\n",
       " 11712,\n",
       " 11763,\n",
       " 11774,\n",
       " 11808,\n",
       " 11810,\n",
       " 11822,\n",
       " 11856,\n",
       " 11887,\n",
       " 12009,\n",
       " 12036,\n",
       " 12045,\n",
       " 12047,\n",
       " 12050,\n",
       " 12058,\n",
       " 12075,\n",
       " 12155,\n",
       " 12199,\n",
       " 12327,\n",
       " 12330,\n",
       " 12351,\n",
       " 12447,\n",
       " 12477,\n",
       " 12489,\n",
       " 12526,\n",
       " 12575,\n",
       " 12583,\n",
       " 12606,\n",
       " 12640,\n",
       " 12678,\n",
       " 12832,\n",
       " 12865,\n",
       " 12892,\n",
       " 12910,\n",
       " 12937,\n",
       " 12947,\n",
       " 12977,\n",
       " 13015,\n",
       " 13031,\n",
       " 13069,\n",
       " 13132,\n",
       " 13211,\n",
       " 13233,\n",
       " 13332,\n",
       " 13410,\n",
       " 13437,\n",
       " 13451,\n",
       " 13458,\n",
       " 13464,\n",
       " 13495,\n",
       " 13505,\n",
       " 13534,\n",
       " 13546,\n",
       " 13612,\n",
       " 13668,\n",
       " 13687,\n",
       " 13713,\n",
       " 13726,\n",
       " 13746,\n",
       " 13758,\n",
       " 13812,\n",
       " 13813,\n",
       " 13822,\n",
       " 13833,\n",
       " 13898,\n",
       " 13906,\n",
       " 13935,\n",
       " 14008,\n",
       " 14069,\n",
       " 14109,\n",
       " 14214,\n",
       " 14216,\n",
       " 14241,\n",
       " 14301,\n",
       " 14302,\n",
       " 14304,\n",
       " 14446,\n",
       " 14509,\n",
       " 14572,\n",
       " 14588,\n",
       " 14605,\n",
       " 14619,\n",
       " 14660,\n",
       " 14674,\n",
       " 14695,\n",
       " 14751,\n",
       " 14766,\n",
       " 14785,\n",
       " 14804,\n",
       " 14810,\n",
       " 14817,\n",
       " 14835,\n",
       " 14859,\n",
       " 14908,\n",
       " 14914,\n",
       " 14980,\n",
       " 15044,\n",
       " 15076,\n",
       " 15127,\n",
       " 15131,\n",
       " 15263,\n",
       " 15280,\n",
       " 15422,\n",
       " 15478,\n",
       " 15485,\n",
       " 15498,\n",
       " 15503,\n",
       " 15553,\n",
       " 15556,\n",
       " 15564,\n",
       " 15605,\n",
       " 15615,\n",
       " 15661,\n",
       " 15665,\n",
       " 15719,\n",
       " 15721,\n",
       " 15734,\n",
       " 15818,\n",
       " 15870,\n",
       " 15884,\n",
       " 15932,\n",
       " 15935,\n",
       " 16054,\n",
       " 16073,\n",
       " 16085,\n",
       " 16097,\n",
       " 16100,\n",
       " 16106,\n",
       " 16141,\n",
       " 16154,\n",
       " 16251,\n",
       " 16356,\n",
       " 16358,\n",
       " 16360,\n",
       " 16384,\n",
       " 16409,\n",
       " 16419,\n",
       " 16446,\n",
       " 16576,\n",
       " 16649,\n",
       " 16654,\n",
       " 16662,\n",
       " 16667,\n",
       " 16673,\n",
       " 16678,\n",
       " 16682,\n",
       " 16690,\n",
       " 16698,\n",
       " 16712,\n",
       " 16714,\n",
       " 16737,\n",
       " 16756,\n",
       " 16784,\n",
       " 16787,\n",
       " 16788,\n",
       " 16796,\n",
       " 16800,\n",
       " 16802,\n",
       " 16804,\n",
       " 16823,\n",
       " 16824,\n",
       " 16828,\n",
       " 16834,\n",
       " 16861,\n",
       " 16868,\n",
       " 16888,\n",
       " 16898,\n",
       " 16932,\n",
       " 16934,\n",
       " 16945,\n",
       " 16985,\n",
       " 16994,\n",
       " 17000,\n",
       " 17003,\n",
       " 17005,\n",
       " 17006,\n",
       " 17024,\n",
       " 17028,\n",
       " 17053,\n",
       " 17060,\n",
       " 17061,\n",
       " 17081,\n",
       " 17113,\n",
       " 17114,\n",
       " 17120,\n",
       " 17122,\n",
       " 17134,\n",
       " 17141,\n",
       " 17181,\n",
       " 17183,\n",
       " 17187,\n",
       " 17200,\n",
       " 17239,\n",
       " 17246,\n",
       " 17256,\n",
       " 17270,\n",
       " 17272,\n",
       " 17283,\n",
       " 17290,\n",
       " 17299,\n",
       " 17302,\n",
       " 17328,\n",
       " 17332,\n",
       " 17343,\n",
       " 17345,\n",
       " 17350,\n",
       " 17353,\n",
       " 17354,\n",
       " 17356,\n",
       " 17360,\n",
       " 17375,\n",
       " 17392,\n",
       " 17396,\n",
       " 17404,\n",
       " 17408,\n",
       " 17409,\n",
       " 17410,\n",
       " 17411,\n",
       " 17413,\n",
       " 17427,\n",
       " 17428,\n",
       " 17432,\n",
       " 17442,\n",
       " 17465,\n",
       " 17467,\n",
       " 17480,\n",
       " 17494,\n",
       " 17497,\n",
       " 17499,\n",
       " 17511,\n",
       " 17512,\n",
       " 17540,\n",
       " 17547,\n",
       " 17571,\n",
       " 17574,\n",
       " 17575,\n",
       " 17595,\n",
       " 17601,\n",
       " 17607,\n",
       " 17620,\n",
       " 17624,\n",
       " 17625,\n",
       " 17636,\n",
       " 17637,\n",
       " 17648,\n",
       " 17653,\n",
       " 17668,\n",
       " 17681,\n",
       " 17683,\n",
       " 17686,\n",
       " 17727,\n",
       " 17733,\n",
       " 17736,\n",
       " 17740,\n",
       " 17742,\n",
       " 17758,\n",
       " 17770,\n",
       " 17775,\n",
       " 17784,\n",
       " 17795,\n",
       " 17800,\n",
       " 17802,\n",
       " 17816,\n",
       " 17821,\n",
       " 17834,\n",
       " 17836,\n",
       " 17846,\n",
       " 17852,\n",
       " 17856,\n",
       " 17866,\n",
       " 17900,\n",
       " 17903,\n",
       " 17904,\n",
       " 17923,\n",
       " 17927,\n",
       " 17934,\n",
       " 17937,\n",
       " 17939,\n",
       " 17940,\n",
       " 17951,\n",
       " 17982,\n",
       " 18054,\n",
       " 18056,\n",
       " 18059,\n",
       " 18060,\n",
       " 18062,\n",
       " 18063,\n",
       " 18075,\n",
       " 18079,\n",
       " 18083,\n",
       " 18092,\n",
       " 18114,\n",
       " 18116,\n",
       " 18130,\n",
       " 18136,\n",
       " 18152,\n",
       " 18159,\n",
       " 18164,\n",
       " 18169,\n",
       " 18195,\n",
       " 18205,\n",
       " 18227,\n",
       " 18272,\n",
       " 18273,\n",
       " 18274,\n",
       " 18276,\n",
       " 18280,\n",
       " 18286,\n",
       " 18289,\n",
       " 18292,\n",
       " 18306,\n",
       " 18314,\n",
       " 18322,\n",
       " 18334,\n",
       " 18344,\n",
       " 18364,\n",
       " 18365,\n",
       " 18372,\n",
       " 18378,\n",
       " 18379,\n",
       " 18381,\n",
       " 18384,\n",
       " 18396,\n",
       " 18398,\n",
       " 18425,\n",
       " 18426,\n",
       " 18427,\n",
       " 18464,\n",
       " 18465,\n",
       " 18477,\n",
       " 18492,\n",
       " 18494,\n",
       " 18500,\n",
       " 18510,\n",
       " 18516,\n",
       " 18517,\n",
       " 18524,\n",
       " 18529,\n",
       " 18534,\n",
       " 18554,\n",
       " 18570,\n",
       " 18576,\n",
       " 18591,\n",
       " 18596,\n",
       " 18623,\n",
       " 18630,\n",
       " 18635,\n",
       " 18638,\n",
       " 18643,\n",
       " 18644,\n",
       " 18654,\n",
       " 18655,\n",
       " 18657,\n",
       " 18684,\n",
       " 18687,\n",
       " 18690,\n",
       " 18712,\n",
       " 18713,\n",
       " 18717,\n",
       " 18718,\n",
       " 18729,\n",
       " 18763,\n",
       " 18771,\n",
       " 18803,\n",
       " 18807,\n",
       " 18809,\n",
       " 18814,\n",
       " 18816,\n",
       " 18822,\n",
       " 18833,\n",
       " 18836,\n",
       " 18837,\n",
       " 18838,\n",
       " 18840,\n",
       " 18842,\n",
       " 18848,\n",
       " 18856,\n",
       " 18858,\n",
       " 18868,\n",
       " 18871,\n",
       " 18872,\n",
       " 18878,\n",
       " 18899,\n",
       " 18917,\n",
       " 18926,\n",
       " 18948,\n",
       " 18960,\n",
       " 18990,\n",
       " 18992,\n",
       " 18995,\n",
       " 19008,\n",
       " 19014,\n",
       " 19026,\n",
       " 19027,\n",
       " 19052,\n",
       " 19075,\n",
       " 19093,\n",
       " 19097,\n",
       " 19110,\n",
       " 19130,\n",
       " 19134,\n",
       " 19144,\n",
       " 19149,\n",
       " 19171,\n",
       " 19176,\n",
       " 19187,\n",
       " 19191,\n",
       " 19209,\n",
       " 19242,\n",
       " 19249,\n",
       " 19263,\n",
       " 19268,\n",
       " 19277,\n",
       " 19291,\n",
       " 19299,\n",
       " 19309,\n",
       " 19343,\n",
       " 19347,\n",
       " 19350,\n",
       " 19360,\n",
       " 19362,\n",
       " 19396,\n",
       " 19399,\n",
       " 19426,\n",
       " 19457,\n",
       " 19465,\n",
       " 19466,\n",
       " 19467,\n",
       " 19478,\n",
       " 19488,\n",
       " 19520,\n",
       " 19525,\n",
       " 19526,\n",
       " 19531,\n",
       " 19572,\n",
       " 19580,\n",
       " 19592,\n",
       " 19598,\n",
       " 19600,\n",
       " 19635,\n",
       " 19654,\n",
       " 19680,\n",
       " 19689,\n",
       " 19724,\n",
       " 19738,\n",
       " 19743,\n",
       " 19746,\n",
       " 19754,\n",
       " 19773,\n",
       " 19774,\n",
       " 19798,\n",
       " 19817,\n",
       " 19832,\n",
       " 19839,\n",
       " 19848,\n",
       " 19889,\n",
       " 19977,\n",
       " 20018,\n",
       " 20033,\n",
       " 20045,\n",
       " 20059,\n",
       " 20073,\n",
       " 20089,\n",
       " 20110,\n",
       " 20130,\n",
       " 20159,\n",
       " 20172,\n",
       " 20229,\n",
       " 20267,\n",
       " 20270,\n",
       " 20286,\n",
       " 20289,\n",
       " 20299,\n",
       " 20327,\n",
       " 20337,\n",
       " 20382,\n",
       " 20394,\n",
       " 20410,\n",
       " 20420,\n",
       " 20447,\n",
       " 20453,\n",
       " 20478,\n",
       " 20480,\n",
       " 20491,\n",
       " 20525,\n",
       " 20586]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_series[missing_in_cleaned].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"number = 1.2345\\nprec = 0.678\\nprec = int(prec)\\nnumber = int(number)\\nrounded = (int(number) + prec/2) // prec * prec\\nreturn rounded\\n\\nWait, but I think that (int(number) + prec/2) // prec * prec could be causing issues when the number is very small or when precision is very small. Also, when the number is already an integer, this approach should return the integer without any decimal points.\\n\\nAnother approach is to multiply the number by 10^precision, round it to the nearest integer, then divide by 10^precision.\\n\\nBut in Python, for large numbers, multiplying by 10^precision might cause floating point inaccuracies, but I think for the purpose of this function, it's acceptable.\\n\\nAlternatively, we can use the round() function in a clever way. For example, multiplying the number by 10^precision, rounding to the nearest integer, then dividing by 10^precision.\\n\\nSo, another formula is: rounded = round(number * (10 ** precision)) / (10 ** precision)\\n\\nBut we have to handle the case where precision is zero, but in the problem statement, precision is being converted to an integer, so if it's zero, then 10**0 is 1, so it would round to the nearest integer.\\n\\nWait, but if the precision is zero, then the code would round the number to the nearest integer, because multiplying by 10^0 is 1, and then dividing by 1 is still the same as rounding to the nearest integer.\\n\\nWait, but the precision can be zero? Let me check the problem statement.\\n\\nThe description says: precision = int(precision). So, for example, if the input is 0.678, it becomes 0. So, if the precision is zero, what is the expected behavior?\\n\\nIn that case, 10**0 is 1, so the formula becomes round(number * 1) / 1, which is just round(number). So, the function would round the number to the nearest integer if the precision is zero.\\n\\nBut is that correct? For example, if the number is 3.1415, and precision is zero, the function would return 3.\\n\\nBut according to the problem statement, when precision is zero, it's allowed, but what's the expected rounding behavior?\\n\\nAlternatively, perhaps when precision is zero, the function should return the integer part of the number, without any decimal points.\\n\\nWait, but that's a different approach. So perhaps, when precision is zero, the formula is (int(number) + 0 / 2) // 0 * 0. But dividing by zero is a problem. So, that approach might not work when precision is zero.\\n\\nSo, the first approach is to use the first formula:\\n\\nrounded = (int(number) + precision / 2) // precision * precision\\n\\nBut wait, when precision is zero, this would cause division by zero. So, the code as given in the problem statement would fail when precision is zero.\\n\\nSo, perhaps the correct approach is to handle the case when precision is zero separately.\\n\\nAlternatively, the second approach is to use the formula:\\n\\nrounded = round(number * (10 ** precision)) / (10 ** precision)\\n\\nBut this also has issues when precision is zero because 10**0 is 1, so the formula becomes round(number * 1) / 1, which is just round(number). But when the precision is zero, the function is supposed to round the number to the nearest integer, not to the nearest multiple of 1, which is just the integer part.\\n\\nWait, but 10**0 is 1, so the formula is the same as rounding to the nearest integer. But when the precision is zero, the function is supposed to round to the nearest integer, so that would be correct.\\n\\nWait, let's see: if precision is zero, then 10**0 is 1, so number * 1 is the same as number, then rounded to nearest integer, then divided by 1 is same as number rounded to nearest integer.\\n\\nBut wait, the problem statement says that when precision is zero, the function should round to the nearest integer. So, the formula round(number) is the same as the formula with precision zero.\\n\\nSo, the formula round(number * 10**precision) / (10**precision) is the same as the formula that handles all cases, including when precision is zero.\\n\\nBut in Python, when using the round function, numbers can have precision issues due to floating point representation.\\n\\nSo, for example, 1.2345 * 10**3 is 1234.5, and round(1\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv2.iloc[61][\"Generated_Code_deepseek_2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-Sitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.00\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'normalized_code1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 160\u001b[39m\n\u001b[32m    158\u001b[39m result = analyzer.compare_code(code1, code2)\n\u001b[32m    159\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSimilarity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNormalized 1:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnormalized_code1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m    161\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNormalized 2:\u001b[39m\u001b[33m\"\u001b[39m, result[\u001b[33m'\u001b[39m\u001b[33mnormalized_code2\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    163\u001b[39m result = analyzer.compare_code(code1, code3)\n",
      "\u001b[31mKeyError\u001b[39m: 'normalized_code1'"
     ]
    }
   ],
   "source": [
    "import tree_sitter_python as tspython\n",
    "from tree_sitter import Language, Parser\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import re\n",
    "\n",
    "class CodeSimilarityAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Initialize Tree-sitter parser\n",
    "        self.language = Language(tspython.language())\n",
    "        self.parser = Parser(self.language)\n",
    "        \n",
    "        # Keywords to preserve during normalization\n",
    "        self.preserved_keywords = {\n",
    "            'True', 'False', 'None', 'and', 'or', 'not', 'if', 'else', 'elif',\n",
    "            'for', 'while', 'break', 'continue', 'def', 'class', 'return', 'import'\n",
    "        }\n",
    "        \n",
    "        # Pre-compile queries\n",
    "        self.identifier_query = self.language.query(\"\"\"\n",
    "            (identifier) @id\n",
    "            (#not-eq? @id \"True\")\n",
    "            (#not-eq? @id \"False\")\n",
    "            (#not-eq? @id \"None\")\n",
    "        \"\"\")\n",
    "        \n",
    "        self.function_query = self.language.query(\"\"\"\n",
    "            (function_definition\n",
    "                name: (identifier) @name)\n",
    "        \"\"\")\n",
    "\n",
    "    def normalize_code(self, code):\n",
    "        \"\"\"Normalize variable/function names while preserving structure\"\"\"\n",
    "        tree = self.parser.parse(bytes(code, 'utf8'))\n",
    "        code_lines = code.splitlines(keepends=True)\n",
    "        replacements = {}\n",
    "        var_counter = 1\n",
    "        func_counter = 1\n",
    "\n",
    "        # Process function names\n",
    "        for match in self.function_query.matches(tree.root_node):\n",
    "            node = match[0][1]\n",
    "            original = node.text.decode('utf8')\n",
    "            if original not in replacements:\n",
    "                replacements[original] = f\"func{func_counter}\"\n",
    "                func_counter += 1\n",
    "\n",
    "        # Process variable names\n",
    "        for match in self.identifier_query.matches(tree.root_node):\n",
    "            node = match[0][1]\n",
    "            original = node.text.decode('utf8')\n",
    "            \n",
    "            # Skip preserved keywords and capitalized names\n",
    "            if (original in self.preserved_keywords or \n",
    "                re.match(r'^[A-Z]', original) or\n",
    "                original in replacements):\n",
    "                continue\n",
    "                \n",
    "            replacements[original] = f\"var{var_counter}\"\n",
    "            var_counter += 1\n",
    "\n",
    "        # Apply replacements\n",
    "        if replacements:\n",
    "            # Process functions first\n",
    "            for match in self.function_query.matches(tree.root_node):\n",
    "                node = match[0][1]\n",
    "                original = node.text.decode('utf8')\n",
    "                if original in replacements:\n",
    "                    start_line, start_col = node.start_point\n",
    "                    end_line, end_col = node.end_point\n",
    "                    if start_line == end_line:\n",
    "                        line = code_lines[start_line]\n",
    "                        code_lines[start_line] = (line[:start_col] + \n",
    "                                               replacements[original] + \n",
    "                                               line[end_col:])\n",
    "            \n",
    "            # Then process variables\n",
    "            for match in self.identifier_query.matches(tree.root_node):\n",
    "                node = match[0][1]\n",
    "                original = node.text.decode('utf8')\n",
    "                if original in replacements:\n",
    "                    start_line, start_col = node.start_point\n",
    "                    end_line, end_col = node.end_point\n",
    "                    if start_line == end_line:\n",
    "                        line = code_lines[start_line]\n",
    "                        code_lines[start_line] = (line[:start_col] + \n",
    "                                               replacements[original] + \n",
    "                                               line[end_col:])\n",
    "\n",
    "        return ''.join(code_lines)\n",
    "\n",
    "    def extract_structural_features(self, code):\n",
    "        \"\"\"Extract AST patterns from normalized code\"\"\"\n",
    "        tree = self.parser.parse(bytes(code, 'utf8'))\n",
    "        features = defaultdict(float)\n",
    "        \n",
    "        def _walk(node, parent_type=None, depth=0):\n",
    "            # Weight features by depth (shallow nodes matter more)\n",
    "            weight = 1.0 / (1 + depth)\n",
    "            \n",
    "            # Node type with parent context\n",
    "            if parent_type:\n",
    "                feature_key = f\"{parent_type}→{node.type}\"\n",
    "                features[feature_key] += weight\n",
    "            \n",
    "            # Node type alone\n",
    "            features[node.type] += weight\n",
    "            \n",
    "            # Child relationships\n",
    "            for child in node.children:\n",
    "                _walk(child, node.type, depth + 1)\n",
    "                \n",
    "        _walk(tree.root_node)\n",
    "        return features\n",
    "\n",
    "    def cosine_similarity(self, vec1, vec2):\n",
    "        \"\"\"Calculate cosine similarity between feature vectors\"\"\"\n",
    "        all_features = set(vec1.keys()).union(set(vec2.keys()))\n",
    "        dot_product = 0.0\n",
    "        mag1 = 0.0\n",
    "        mag2 = 0.0\n",
    "        \n",
    "        for feature in all_features:\n",
    "            v1 = vec1.get(feature, 0.0)\n",
    "            v2 = vec2.get(feature, 0.0)\n",
    "            dot_product += v1 * v2\n",
    "            mag1 += v1 ** 2\n",
    "            mag2 += v2 ** 2\n",
    "            \n",
    "        mag1 = math.sqrt(mag1)\n",
    "        mag2 = math.sqrt(mag2)\n",
    "        \n",
    "        if mag1 == 0 or mag2 == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        return min(max(dot_product / (mag1 * mag2), 0.0), 1.0)\n",
    "\n",
    "    def compare_code(self, code1, code2):\n",
    "        \"\"\"Complete comparison pipeline\"\"\"\n",
    "        # Step 1: Normalize both code snippets\n",
    "        norm1 = self.normalize_code(code1)\n",
    "        norm2 = self.normalize_code(code2)\n",
    "        \n",
    "        # Step 2: Parse normalized code\n",
    "        try:\n",
    "            # Step 3: Extract structural features\n",
    "            features1 = self.extract_structural_features(norm1)\n",
    "            features2 = self.extract_structural_features(norm2)\n",
    "            \n",
    "            # Step 4: Calculate similarity\n",
    "            similarity = self.cosine_similarity(features1, features2)\n",
    "            \n",
    "            return {\n",
    "                'similarity': similarity,\n",
    "                'normalized_code1': norm1,\n",
    "                'normalized_code2': norm2\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'error': f\"Comparison failed: {str(e)}\",\n",
    "                'similarity': 0.0\n",
    "            }\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = CodeSimilarityAnalyzer()\n",
    "    \n",
    "    # Example 1: Similar structure, different names\n",
    "    code1 = \"\"\"\n",
    "    def calculate_total(items):\n",
    "        sum = 0\n",
    "        for item in items:\n",
    "            sum += item.price\n",
    "        return sum\n",
    "    \"\"\"\n",
    "    \n",
    "    code2 = \"\"\"\n",
    "    def compute_sum(products):\n",
    "        total = 0\n",
    "        for product in products:\n",
    "            total += product.cost\n",
    "        return total\n",
    "    \"\"\"\n",
    "    \n",
    "    # Example 2: Different structure\n",
    "    code3 = \"\"\"\n",
    "    def process_data(input_list):\n",
    "        return [x*2 for x in input_list]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compare code\n",
    "    result = analyzer.compare_code(code1, code2)\n",
    "    print(f\"Similarity between code1 and code2: {result['similarity']:.2f}\")\n",
    "    print(\"Normalized code1:\")\n",
    "    print(result['normalized_code1'])\n",
    "    print(\"Normalized code2:\")\n",
    "    print(result['normalized_code2'])\n",
    "    \n",
    "    result = analyzer.compare_code(code1, code3)\n",
    "    print(f\"\\nSimilarity between code1 and code3: {result['similarity']:.2f}\")\n",
    "\n",
    "    # For your specific comparison:\n",
    "    PY_LANGUAGE = Language(tspython.language())\n",
    "    parser = Parser()\n",
    "    parser.set_language(PY_LANGUAGE)\n",
    "    \n",
    "    def get_function_names(code):\n",
    "        \"\"\"Extract function names from code\"\"\"\n",
    "        tree = parser.parse(bytes(code, 'utf8'))\n",
    "        query = PY_LANGUAGE.query(\"\"\"\n",
    "        (function_definition\n",
    "            name: (identifier) @name)\n",
    "        \"\"\")\n",
    "        return [match[0][1].text.decode('utf8') for match in query.matches(tree.root_node)]\n",
    "    \n",
    "    def is_valid_python(code):\n",
    "        \"\"\"Check if code is valid Python syntax\"\"\"\n",
    "        try:\n",
    "            parser.parse(bytes(code, 'utf8'))\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    # Example usage with your data:\n",
    "    generated_code = \"def example(): pass\"  # Replace with actual code from csv2\n",
    "    reference_code = \"def sample(): pass\"   # Replace with actual code from csv2\n",
    "    \n",
    "    print(\"\\nValidity check:\")\n",
    "    print(\"Reference code valid:\", is_valid_python(reference_code))\n",
    "    print(\"Generated code valid:\", is_valid_python(generated_code))\n",
    "    \n",
    "    print(\"\\nFunction name comparison:\")\n",
    "    gen_func_names = get_function_names(generated_code)\n",
    "    ref_func_names = get_function_names(reference_code)\n",
    "    print(\"Generated function names:\", gen_func_names)\n",
    "    print(\"Reference function names:\", ref_func_names)\n",
    "    print(\"Match:\", gen_func_names == ref_func_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during comparison: too many values to unpack (expected 2)\n",
      "Similarity (should be high): 0.00\n",
      "Normalized code 1:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'normalized_code1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 164\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSimilarity (should be high): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    163\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNormalized code 1:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnormalized_code1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m    165\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNormalized code 2:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    166\u001b[39m \u001b[38;5;28mprint\u001b[39m(result[\u001b[33m'\u001b[39m\u001b[33mnormalized_code2\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mKeyError\u001b[39m: 'normalized_code1'"
     ]
    }
   ],
   "source": [
    "import tree_sitter_python as tspython\n",
    "from tree_sitter import Language, Parser\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import re\n",
    "\n",
    "class CodeSimilarityAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Initialize Tree-sitter parser\n",
    "        self.language = Language(tspython.language())\n",
    "        self.parser = Parser(self.language)\n",
    "        \n",
    "        # Keywords to preserve during normalization\n",
    "        self.preserved_keywords = {\n",
    "            'True', 'False', 'None', 'and', 'or', 'not', 'if', 'else', 'elif',\n",
    "            'for', 'while', 'break', 'continue', 'def', 'class', 'return', 'import'\n",
    "        }\n",
    "        \n",
    "        # Corrected queries with proper capture names\n",
    "        self.identifier_query = self.language.query(\"\"\"\n",
    "            (identifier) @variable\n",
    "            (#not-eq? @variable \"True\")\n",
    "            (#not-eq? @variable \"False\")\n",
    "            (#not-eq? @variable \"None\")\n",
    "        \"\"\")\n",
    "        \n",
    "        self.function_query = self.language.query(\"\"\"\n",
    "            (function_definition\n",
    "                name: (identifier) @function_name)\n",
    "        \"\"\")\n",
    "\n",
    "    \n",
    "    def normalize_code(self, code):\n",
    "        tree = self.parser.parse(bytes(code, 'utf8'))\n",
    "        code_bytes = bytearray(code, 'utf8')\n",
    "        replacements = {}\n",
    "        var_counter = 1\n",
    "        func_counter = 1\n",
    "\n",
    "        # Capture function names\n",
    "        function_captures = [\n",
    "            (node, capture) for node, capture in self.function_query.captures(tree.root_node)\n",
    "            if capture == \"function_name\"\n",
    "        ]\n",
    "        # Capture variable identifiers\n",
    "        identifier_captures = [\n",
    "            (node, capture) for node, capture in self.identifier_query.captures(tree.root_node)\n",
    "            if capture == \"variable\"\n",
    "        ]\n",
    "\n",
    "        # Combine and sort all captures by start_byte DESCENDING (important!)\n",
    "        all_captures = function_captures + identifier_captures\n",
    "        all_captures.sort(key=lambda x: x[0].start_byte, reverse=True)\n",
    "\n",
    "        for node, capture in all_captures:\n",
    "            original = node.text.decode('utf8')\n",
    "            \n",
    "            # Skip preserved keywords and already replaced\n",
    "            if original in self.preserved_keywords or re.match(r'^[A-Z]', original):\n",
    "                continue\n",
    "\n",
    "            if original not in replacements:\n",
    "                if capture == \"function_name\":\n",
    "                    replacements[original] = f\"func{func_counter}\"\n",
    "                    func_counter += 1\n",
    "                else:\n",
    "                    replacements[original] = f\"var{var_counter}\"\n",
    "                    var_counter += 1\n",
    "\n",
    "            replacement = replacements[original]\n",
    "            code_bytes[node.start_byte:node.end_byte] = replacement.encode(\"utf8\")\n",
    "\n",
    "        return code_bytes.decode(\"utf8\")\n",
    "\n",
    "\n",
    "    def extract_structural_features(self, code):\n",
    "        \"\"\"Extract AST patterns from normalized code\"\"\"\n",
    "        tree = self.parser.parse(bytes(code, 'utf8'))\n",
    "        features = defaultdict(float)\n",
    "        \n",
    "        def _walk(node, parent_type=None, depth=0):\n",
    "            weight = 1.0 / (1 + depth)\n",
    "            \n",
    "            if parent_type:\n",
    "                feature_key = f\"{parent_type}→{node.type}\"\n",
    "                features[feature_key] += weight\n",
    "            \n",
    "            features[node.type] += weight\n",
    "            \n",
    "            for child in node.children:\n",
    "                _walk(child, node.type, depth + 1)\n",
    "                \n",
    "        _walk(tree.root_node)\n",
    "        return features\n",
    "\n",
    "    def cosine_similarity(self, vec1, vec2):\n",
    "        \"\"\"Calculate cosine similarity between feature vectors\"\"\"\n",
    "        all_features = set(vec1.keys()).union(set(vec2.keys()))\n",
    "        dot_product = 0.0\n",
    "        mag1 = 0.0\n",
    "        mag2 = 0.0\n",
    "        \n",
    "        for feature in all_features:\n",
    "            v1 = vec1.get(feature, 0.0)\n",
    "            v2 = vec2.get(feature, 0.0)\n",
    "            dot_product += v1 * v2\n",
    "            mag1 += v1 ** 2\n",
    "            mag2 += v2 ** 2\n",
    "            \n",
    "        mag1 = math.sqrt(mag1)\n",
    "        mag2 = math.sqrt(mag2)\n",
    "        \n",
    "        if mag1 == 0 or mag2 == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        return min(max(dot_product / (mag1 * mag2), 0.0), 1.0)\n",
    "\n",
    "    def compare_code(self, code1, code2):\n",
    "        \"\"\"Complete comparison pipeline\"\"\"\n",
    "        try:\n",
    "            norm1 = self.normalize_code(code1)\n",
    "            norm2 = self.normalize_code(code2)\n",
    "            \n",
    "            features1 = self.extract_structural_features(norm1)\n",
    "            features2 = self.extract_structural_features(norm2)\n",
    "            \n",
    "            similarity = self.cosine_similarity(features1, features2)\n",
    "            \n",
    "            return {\n",
    "                'similarity': similarity,\n",
    "                'normalized_code1': norm1,\n",
    "                'normalized_code2': norm2\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error during comparison: {str(e)}\")  # Debug output\n",
    "            return {\n",
    "                'error': f\"Comparison failed: {str(e)}\",\n",
    "                'similarity': 0.0\n",
    "            }\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = CodeSimilarityAnalyzer()\n",
    "    \n",
    "    # Test case 1: Similar structure, different names\n",
    "    code1 = \"\"\"\n",
    "def calculate(items):\n",
    "    total = 0\n",
    "    for item in items:\n",
    "        total += item.price\n",
    "    return total\n",
    "\"\"\"\n",
    "    \n",
    "    code2 = \"\"\"\n",
    "def compute(products):\n",
    "    sum = 0\n",
    "    for product in products:\n",
    "        sum += product.cost\n",
    "    return sum\n",
    "\"\"\"\n",
    "    result = analyzer.compare_code(code1, code2)\n",
    "    print(f\"Similarity (should be high): {result['similarity']:.2f}\")\n",
    "    print(\"Normalized code 1:\")\n",
    "    print(result['normalized_code1'])\n",
    "    print(\"Normalized code 2:\")\n",
    "    print(result['normalized_code2'])\n",
    "    \n",
    "    # Test case 2: Different structure\n",
    "    code3 = \"\"\"\n",
    "def process(inputs):\n",
    "    return [x*2 for x in inputs]\n",
    "\"\"\"\n",
    "    result = analyzer.compare_code(code1, code3)\n",
    "    print(f\"\\nSimilarity (should be low): {result['similarity']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization failed: Failed to initialize analyzer: 'tree_sitter.Parser' object has no attribute 'set_language'\n"
     ]
    }
   ],
   "source": [
    "import tree_sitter_python as tspython\n",
    "from tree_sitter import Language, Parser\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import re\n",
    "\n",
    "class CodeSimilarityAnalyzer:\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            # Initialize Tree-sitter parser\n",
    "            self.language = Language(tspython.language())\n",
    "            self.parser = Parser(self.language)\n",
    "            \n",
    "            # Keywords to preserve during normalization\n",
    "            self.preserved_keywords = {\n",
    "                'True', 'False', 'None', 'and', 'or', 'not', 'if', 'else', 'elif',\n",
    "                'for', 'while', 'break', 'continue', 'def', 'class', 'return', 'import'\n",
    "            }\n",
    "            \n",
    "            # Queries for capturing identifiers\n",
    "            self.function_query = self.language.query(\"\"\"\n",
    "                (function_definition\n",
    "                    name: (identifier) @func_name)\n",
    "            \"\"\")\n",
    "            \n",
    "            self.variable_query = self.language.query(\"\"\"\n",
    "                (identifier) @variable\n",
    "                (#not-eq? @variable \"True\")\n",
    "                (#not-eq? @variable \"False\")\n",
    "                (#not-eq? @variable \"None\")\n",
    "            \"\"\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to initialize analyzer: {str(e)}\")\n",
    "\n",
    "    def normalize_code(self, code):\n",
    "        \"\"\"Normalize variable/function names while preserving structure\"\"\"\n",
    "        try:\n",
    "            tree = self.parser.parse(bytes(code, 'utf8'))\n",
    "            if not tree.root_node:\n",
    "                return code\n",
    "                \n",
    "            # We'll build the normalized code by chunks\n",
    "            chunks = []\n",
    "            last_pos = 0\n",
    "            replacements = {}\n",
    "            var_counter = 1\n",
    "            func_counter = 1\n",
    "\n",
    "            # First pass: collect all identifiers that need replacement\n",
    "            identifiers = []\n",
    "            \n",
    "            # Function names\n",
    "            for node, tag in self.function_query.captures(tree.root_node):\n",
    "                if tag == \"func_name\":\n",
    "                    original = node.text.decode('utf8')\n",
    "                    if original not in replacements:\n",
    "                        replacements[original] = f\"func{func_counter}\"\n",
    "                        func_counter += 1\n",
    "                    identifiers.append((node.start_byte, node.end_byte, replacements[original]))\n",
    "            \n",
    "            # Variable names\n",
    "            for node, tag in self.variable_query.captures(tree.root_node):\n",
    "                if tag == \"variable\":\n",
    "                    original = node.text.decode('utf8')\n",
    "                    if (original not in replacements and \n",
    "                        original not in self.preserved_keywords and\n",
    "                        not re.match(r'^[A-Z]', original)):\n",
    "                        replacements[original] = f\"var{var_counter}\"\n",
    "                        var_counter += 1\n",
    "                    if original in replacements:\n",
    "                        identifiers.append((node.start_byte, node.end_byte, replacements[original]))\n",
    "            \n",
    "            # Sort identifiers by position\n",
    "            identifiers.sort()\n",
    "            \n",
    "            # Rebuild the code with replacements\n",
    "            code_bytes = bytes(code, 'utf8')\n",
    "            last_pos = 0\n",
    "            for start, end, replacement in identifiers:\n",
    "                chunks.append(code_bytes[last_pos:start])\n",
    "                chunks.append(replacement.encode('utf8'))\n",
    "                last_pos = end\n",
    "            chunks.append(code_bytes[last_pos:])\n",
    "            \n",
    "            return b''.join(chunks).decode('utf8')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Normalization error: {str(e)}\")\n",
    "            return code\n",
    "\n",
    "    def extract_structural_features(self, code):\n",
    "        \"\"\"Extract AST patterns from normalized code\"\"\"\n",
    "        try:\n",
    "            tree = self.parser.parse(bytes(code, 'utf8'))\n",
    "            if not tree.root_node:\n",
    "                return defaultdict(float)\n",
    "                \n",
    "            features = defaultdict(float)\n",
    "            \n",
    "            def _walk(node, parent_type=None, depth=0):\n",
    "                weight = 1.0 / (1 + depth)\n",
    "                \n",
    "                if parent_type:\n",
    "                    feature_key = f\"{parent_type}→{node.type}\"\n",
    "                    features[feature_key] += weight\n",
    "                \n",
    "                features[node.type] += weight\n",
    "                \n",
    "                for child in node.children:\n",
    "                    _walk(child, node.type, depth + 1)\n",
    "                    \n",
    "            _walk(tree.root_node)\n",
    "            return features\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Feature extraction error: {str(e)}\")\n",
    "            return defaultdict(float)\n",
    "\n",
    "    def cosine_similarity(self, vec1, vec2):\n",
    "        \"\"\"Calculate cosine similarity between feature vectors\"\"\"\n",
    "        try:\n",
    "            all_features = set(vec1.keys()).union(set(vec2.keys()))\n",
    "            dot_product = 0.0\n",
    "            mag1 = 0.0\n",
    "            mag2 = 0.0\n",
    "            \n",
    "            for feature in all_features:\n",
    "                v1 = vec1.get(feature, 0.0)\n",
    "                v2 = vec2.get(feature, 0.0)\n",
    "                dot_product += v1 * v2\n",
    "                mag1 += v1 ** 2\n",
    "                mag2 += v2 ** 2\n",
    "                \n",
    "            mag1 = math.sqrt(mag1)\n",
    "            mag2 = math.sqrt(mag2)\n",
    "            \n",
    "            if mag1 == 0 or mag2 == 0:\n",
    "                return 0.0\n",
    "                \n",
    "            return min(max(dot_product / (mag1 * mag2), 0.0), 1.0)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Similarity calculation error: {str(e)}\")\n",
    "            return 0.0\n",
    "\n",
    "    def compare_code(self, code1, code2):\n",
    "        \"\"\"Complete comparison pipeline\"\"\"\n",
    "        try:\n",
    "            norm1 = self.normalize_code(code1)\n",
    "            norm2 = self.normalize_code(code2)\n",
    "            \n",
    "            features1 = self.extract_structural_features(norm1)\n",
    "            features2 = self.extract_structural_features(norm2)\n",
    "            \n",
    "            similarity = self.cosine_similarity(features1, features2)\n",
    "            \n",
    "            return {\n",
    "                'similarity': similarity,\n",
    "                'normalized_code1': norm1,\n",
    "                'normalized_code2': norm2,\n",
    "                'error': None\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Comparison failed: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            return {\n",
    "                'similarity': 0.0,\n",
    "                'normalized_code1': code1,\n",
    "                'normalized_code2': code2,\n",
    "                'error': error_msg\n",
    "            }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        analyzer = CodeSimilarityAnalyzer()\n",
    "        \n",
    "        # Test case 1: Similar structure, different names\n",
    "        code1 = \"\"\"\n",
    "def calculate(items):\n",
    "    total = 0\n",
    "    for item in items:\n",
    "        total += item.price\n",
    "    return total\n",
    "\"\"\"\n",
    "        code2 = \"\"\"\n",
    "def compute(products):\n",
    "    sum = 0\n",
    "    for product in products:\n",
    "        sum += product.cost\n",
    "    return sum\n",
    "\"\"\"\n",
    "        result = analyzer.compare_code(code1, code2)\n",
    "        print(\"\\nTest 1 - Similar structure:\")\n",
    "        print(f\"Similarity: {result['similarity']:.2f}\")\n",
    "        print(\"Normalized code 1:\")\n",
    "        print(result['normalized_code1'])\n",
    "        print(\"Normalized code 2:\")\n",
    "        print(result['normalized_code2'])\n",
    "        \n",
    "        # Test case 2: Different structure\n",
    "        code3 = \"\"\"\n",
    "def process(inputs):\n",
    "    return [x*2 for x in inputs]\n",
    "\"\"\"\n",
    "        result = analyzer.compare_code(code1, code3)\n",
    "        print(\"\\nTest 2 - Different structure:\")\n",
    "        print(f\"Similarity: {result['similarity']:.2f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Initialization failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization error: 'str' object has no attribute 'text'\n",
      "Normalization error: 'str' object has no attribute 'text'\n",
      "=== Test 1: Similar Functions ===\n",
      "Similarity: 1.0\n",
      "Normalized 1:\n",
      "\n",
      "def calculate_total(items):\n",
      "    result = 0\n",
      "    for item in items:\n",
      "        result += item.price\n",
      "    return result\n",
      "\n",
      "Normalized 2:\n",
      "\n",
      "def compute_sum(products):\n",
      "    total = 0\n",
      "    for product in products:\n",
      "        total += product.cost\n",
      "    return total\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tree_sitter_python as tspython\n",
    "from tree_sitter import Language, Parser\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import re\n",
    "\n",
    "class PythonCodeComparator:\n",
    "    def __init__(self):\n",
    "        # Initialize Python parser\n",
    "        self.language = Language(tspython.language())\n",
    "        self.parser = Parser(self.language)\n",
    "        self.parser.set_language()\n",
    "        \n",
    "        # Python-specific configuration\n",
    "        self.PYTHON_KEYWORDS = {\n",
    "            'False', 'None', 'True', 'and', 'as', 'assert', 'async', 'await',\n",
    "            'break', 'class', 'continue', 'def', 'del', 'elif', 'else', 'except',\n",
    "            'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is',\n",
    "            'lambda', 'nonlocal', 'not', 'or', 'pass', 'raise', 'return',\n",
    "            'try', 'while', 'with', 'yield'\n",
    "        }\n",
    "        \n",
    "        # Python-specific AST queries\n",
    "        self._setup_queries()\n",
    "        \n",
    "    def _setup_queries(self):\n",
    "        \"\"\"Initialize Python-specific Tree-sitter queries\"\"\"\n",
    "        self.function_query = self.language.query(\"\"\"\n",
    "            (function_definition\n",
    "                name: (identifier) @function_name) @function\n",
    "            (parameters (identifier) @parameter)\n",
    "        \"\"\")\n",
    "        \n",
    "        self.variable_query = self.language.query(\"\"\"\n",
    "            (identifier) @variable\n",
    "            (#not-any-eq? @variable \"True\" \"False\" \"None\")\n",
    "        \"\"\")\n",
    "        \n",
    "        self.class_query = self.language.query(\"\"\"\n",
    "            (class_definition\n",
    "                name: (identifier) @class_name) @class\n",
    "        \"\"\")\n",
    "    \n",
    "    def _should_normalize(self, identifier):\n",
    "        \"\"\"Check if an identifier should be normalized\"\"\"\n",
    "        return (identifier not in self.PYTHON_KEYWORDS and\n",
    "                not re.match(r'^__\\w+__$', identifier) and  # Skip dunder methods\n",
    "                not identifier.startswith('_'))  # Skip private members\n",
    "    \n",
    "    def normalize_python_code(self, code):\n",
    "        \"\"\"Normalize Python code while preserving structure\"\"\"\n",
    "        try:\n",
    "            tree = self.parser.parse(bytes(code, 'utf8'))\n",
    "            if not tree.root_node:\n",
    "                return code\n",
    "                \n",
    "            # Track replacements\n",
    "            replacements = {}\n",
    "            name_counters = {\n",
    "                'function': 1,\n",
    "                'class': 1,\n",
    "                'parameter': 1,\n",
    "                'variable': 1\n",
    "            }\n",
    "            \n",
    "            # Process classes first\n",
    "            for capture in self.class_query.captures(tree.root_node):\n",
    "                node = capture[0]\n",
    "                name = capture[1]\n",
    "                if name == 'class_name':\n",
    "                    original = node.text.decode('utf8')\n",
    "                    if self._should_normalize(original):\n",
    "                        replacements[(node.start_byte, node.end_byte)] = f\"Class{name_counters['class']}\"\n",
    "                        name_counters['class'] += 1\n",
    "            \n",
    "            # Process functions and parameters\n",
    "            for capture in self.function_query.captures(tree.root_node):\n",
    "                node = capture[0]\n",
    "                name = capture[1]\n",
    "                original = node.text.decode('utf8')\n",
    "                if name == 'function_name' and self._should_normalize(original):\n",
    "                    replacements[(node.start_byte, node.end_byte)] = f\"func{name_counters['function']}\"\n",
    "                    name_counters['function'] += 1\n",
    "                elif name == 'parameter' and self._should_normalize(original):\n",
    "                    replacements[(node.start_byte, node.end_byte)] = f\"param{name_counters['parameter']}\"\n",
    "                    name_counters['parameter'] += 1\n",
    "            \n",
    "            # Process other variables\n",
    "            for capture in self.variable_query.captures(tree.root_node):\n",
    "                node = capture[0]\n",
    "                name = capture[1]\n",
    "                if name == 'variable':\n",
    "                    original = node.text.decode('utf8')\n",
    "                    if self._should_normalize(original) and (node.start_byte, node.end_byte) not in replacements:\n",
    "                        replacements[(node.start_byte, node.end_byte)] = f\"var{name_counters['variable']}\"\n",
    "                        name_counters['variable'] += 1\n",
    "            \n",
    "            # Apply replacements in reverse order\n",
    "            sorted_replacements = sorted(replacements.items(), key=lambda x: x[0][0], reverse=True)\n",
    "            code_bytes = bytearray(code, 'utf8')\n",
    "            \n",
    "            for (start, end), new_name in sorted_replacements:\n",
    "                code_bytes[start:end] = new_name.encode('utf8')\n",
    "            \n",
    "            return code_bytes.decode('utf8')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Normalization error: {str(e)}\")\n",
    "            return code\n",
    "    \n",
    "    # [Rest of the methods remain unchanged]\n",
    "    def get_structural_features(self, code):\n",
    "        \"\"\"Extract Python-specific structural features\"\"\"\n",
    "        try:\n",
    "            tree = self.parser.parse(bytes(code, 'utf8'))\n",
    "            if not tree.root_node:\n",
    "                return defaultdict(float)\n",
    "                \n",
    "            features = defaultdict(float)\n",
    "            \n",
    "            def _walk(node, context=None):\n",
    "                # Python-specific feature weighting\n",
    "                weight = 1.0 / (1 + node.start_point[0])  # Weight by line depth\n",
    "                \n",
    "                # Track node type with context\n",
    "                if context:\n",
    "                    features[f\"{context}>{node.type}\"] += weight\n",
    "                \n",
    "                # Python-specific features\n",
    "                if node.type == \"function_definition\":\n",
    "                    features[\"function\"] += weight * 2  # Extra weight for functions\n",
    "                elif node.type == \"class_definition\":\n",
    "                    features[\"class\"] += weight * 1.5\n",
    "                elif node.type == \"list_comprehension\":\n",
    "                    features[\"comprehension\"] += weight\n",
    "                \n",
    "                features[node.type] += weight\n",
    "                \n",
    "                # Walk children with current node as context\n",
    "                for child in node.children:\n",
    "                    _walk(child, node.type)\n",
    "                    \n",
    "            _walk(tree.root_node)\n",
    "            return features\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Feature extraction error: {str(e)}\")\n",
    "            return defaultdict(float)\n",
    "    \n",
    "    def compare(self, code1, code2):\n",
    "        \"\"\"Compare two Python code snippets\"\"\"\n",
    "        try:\n",
    "            # Normalize both snippets\n",
    "            norm1 = self.normalize_python_code(code1)\n",
    "            norm2 = self.normalize_python_code(code2)\n",
    "            \n",
    "            # Extract features\n",
    "            features1 = self.get_structural_features(norm1)\n",
    "            features2 = self.get_structural_features(norm2)\n",
    "            \n",
    "            # Calculate similarity\n",
    "            similarity = self._cosine_similarity(features1, features2)\n",
    "            \n",
    "            return {\n",
    "                'similarity': round(similarity, 2),\n",
    "                'normalized1': norm1,\n",
    "                'normalized2': norm2\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'similarity': 0.0,\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    def _cosine_similarity(self, vec1, vec2):\n",
    "        \"\"\"Calculate cosine similarity between feature vectors\"\"\"\n",
    "        all_features = set(vec1.keys()).union(set(vec2.keys()))\n",
    "        dot = sum(vec1.get(f, 0) * vec2.get(f, 0) for f in all_features)\n",
    "        mag1 = math.sqrt(sum(v**2 for v in vec1.values()))\n",
    "        mag2 = math.sqrt(sum(v**2 for v in vec2.values()))\n",
    "        return dot / (mag1 * mag2) if (mag1 * mag2) > 0 else 0.0\n",
    "\n",
    "\n",
    "# Test Cases\n",
    "if __name__ == \"__main__\":\n",
    "    comparator = PythonCodeComparator()\n",
    "    \n",
    "    # Test 1: Similar functions\n",
    "    code1 = \"\"\"\n",
    "def calculate_total(items):\n",
    "    result = 0\n",
    "    for item in items:\n",
    "        result += item.price\n",
    "    return result\n",
    "\"\"\"\n",
    "    code2 = \"\"\"\n",
    "def compute_sum(products):\n",
    "    total = 0\n",
    "    for product in products:\n",
    "        total += product.cost\n",
    "    return total\n",
    "\"\"\"\n",
    "    result = comparator.compare(code1, code2)\n",
    "    print(\"=== Test 1: Similar Functions ===\")\n",
    "    print(f\"Similarity: {result['similarity']}\")\n",
    "    print(\"Normalized 1:\")\n",
    "    print(result['normalized1'])\n",
    "    print(\"Normalized 2:\")\n",
    "    print(result['normalized2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'var'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 207\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;66;03m# These should be structurally identical\u001b[39;00m\n\u001b[32m    197\u001b[39m code3 = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[33mdef func1(param1, param2):\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[33m    var1 = param1 + param2\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    204\u001b[39m \u001b[33m        self.attr1 = param1\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mComparing code1 and code2:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mcomparator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompare_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode2\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# True\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mComparing code1 and code3:\u001b[39m\u001b[33m\"\u001b[39m, comparator.compare_code(code1, code3))  \u001b[38;5;66;03m# True\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# Different structure\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 129\u001b[39m, in \u001b[36mCodeComparator.compare_code\u001b[39m\u001b[34m(self, code1, code2, language)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# Parse and normalize first code\u001b[39;00m\n\u001b[32m    128\u001b[39m tree1 = \u001b[38;5;28mself\u001b[39m.parse_code(code1)\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m norm_ast1 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalize_ast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mroot_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m# Reset state again for second code\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28mself\u001b[39m.counters = {\n\u001b[32m    133\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mvariable\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m,\n\u001b[32m    134\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    138\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mconstant\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m\n\u001b[32m    139\u001b[39m }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mCodeComparator.normalize_ast\u001b[39m\u001b[34m(self, node, language)\u001b[39m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mself\u001b[39m.scopes.pop()\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     75\u001b[39m     \u001b[38;5;66;03m# Process children normally\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     normalized[\u001b[33m'\u001b[39m\u001b[33mchildren\u001b[39m\u001b[33m'\u001b[39m] = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalize_ast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     77\u001b[39m                             \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m node.children]\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m normalized\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mCodeComparator.normalize_ast\u001b[39m\u001b[34m(self, node, language)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m node.type == \u001b[33m'\u001b[39m\u001b[33mfunction_definition\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     65\u001b[39m     \u001b[38;5;28mself\u001b[39m.scopes.append({})  \u001b[38;5;66;03m# New scope for function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     normalized[\u001b[33m'\u001b[39m\u001b[33mchildren\u001b[39m\u001b[33m'\u001b[39m] = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalize_ast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     67\u001b[39m                             \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m node.children]\n\u001b[32m     68\u001b[39m     \u001b[38;5;28mself\u001b[39m.scopes.pop()\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m node.type == \u001b[33m'\u001b[39m\u001b[33mclass_definition\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mCodeComparator.normalize_ast\u001b[39m\u001b[34m(self, node, language)\u001b[39m\n\u001b[32m     55\u001b[39m     normalized[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.scopes[-\u001b[32m1\u001b[39m][original_name]\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     57\u001b[39m     \u001b[38;5;66;03m# Create new normalized name\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     norm_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcounters\u001b[49m\u001b[43m[\u001b[49m\u001b[43midentifier_type\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     59\u001b[39m     \u001b[38;5;28mself\u001b[39m.counters[identifier_type] += \u001b[32m1\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.scopes[-\u001b[32m1\u001b[39m][original_name] = norm_name\n",
      "\u001b[31mKeyError\u001b[39m: 'var'"
     ]
    }
   ],
   "source": [
    "from tree_sitter import Parser, Language\n",
    "import os\n",
    "import tree_sitter_python as tspython\n",
    "\n",
    "# Initialize Tree-sitter (run this once)\n",
    "def initialize_parser(language_name):\n",
    "    # Point this to your tree-sitter languages repository\n",
    "    language = Language(tspython.language())\n",
    "    return language\n",
    "\n",
    "# For Python (modify for other languages)\n",
    "PYTHON_LANGUAGE = initialize_parser('python')\n",
    "\n",
    "class CodeComparator:\n",
    "    def __init__(self, language=PYTHON_LANGUAGE):\n",
    "        self.parser = Parser(language)\n",
    "        \n",
    "        self.identifier_types = {\n",
    "            'python': {\n",
    "                'variable': ['identifier', 'variable_name'],\n",
    "                'function': ['function_definition>identifier', 'call>identifier'],\n",
    "                'class': ['class_definition>identifier'],\n",
    "                'parameter': ['parameters>identifier', 'lambda_parameters>identifier'],\n",
    "                'attribute': ['attribute>identifier'],\n",
    "                'constant': ['identifier&uppercase']\n",
    "            }\n",
    "            # Add other language configurations here\n",
    "        }\n",
    "        # Initialize counters here to avoid attribute errors\n",
    "        self.counters = {\n",
    "            'variable': 1,\n",
    "            'function': 1,\n",
    "            'class': 1,\n",
    "            'parameter': 1,\n",
    "            'attribute': 1,\n",
    "            'constant': 1\n",
    "        }\n",
    "        self.scopes = [{}]  # Stack of scopes for variable tracking\n",
    "    \n",
    "    def parse_code(self, code_str):\n",
    "        \"\"\"Parse code string into AST\"\"\"\n",
    "        return self.parser.parse(bytes(code_str, 'utf8'))\n",
    "    \n",
    "    def normalize_ast(self, node, language='python'):\n",
    "        \"\"\"Normalize AST by replacing all identifiers with generic names\"\"\"\n",
    "        normalized = {'type': node.type}\n",
    "        \n",
    "        # Check if this node is an identifier that needs normalization\n",
    "        identifier_type = self.get_identifier_type(node, language)\n",
    "        if identifier_type:\n",
    "            original_name = node.text.decode('utf8')\n",
    "            \n",
    "            # Check if we've seen this name in current scope\n",
    "            if original_name in self.scopes[-1]:\n",
    "                normalized['text'] = self.scopes[-1][original_name]\n",
    "            else:\n",
    "                # Create new normalized name\n",
    "                norm_name = f\"{identifier_type}_{self.counters[identifier_type]}\"\n",
    "                self.counters[identifier_type] += 1\n",
    "                self.scopes[-1][original_name] = norm_name\n",
    "                normalized['text'] = norm_name\n",
    "        \n",
    "        # Handle scoped constructs (functions, classes, etc.)\n",
    "        if node.type == 'function_definition':\n",
    "            self.scopes.append({})  # New scope for function\n",
    "            normalized['children'] = [self.normalize_ast(child, language) \n",
    "                                    for child in node.children]\n",
    "            self.scopes.pop()\n",
    "        elif node.type == 'class_definition':\n",
    "            self.scopes.append({})  # New scope for class\n",
    "            normalized['children'] = [self.normalize_ast(child, language) \n",
    "                                    for child in node.children]\n",
    "            self.scopes.pop()\n",
    "        else:\n",
    "            # Process children normally\n",
    "            normalized['children'] = [self.normalize_ast(child, language) \n",
    "                                    for child in node.children]\n",
    "        \n",
    "        return normalized\n",
    "    \n",
    "    def get_identifier_type(self, node, language):\n",
    "        \"\"\"Determine what kind of identifier this node represents\"\"\"\n",
    "        rules = self.identifier_types.get(language, {})\n",
    "        \n",
    "        # Check variable rules\n",
    "        if node.type in rules.get('variable', []):\n",
    "            return 'var'\n",
    "        \n",
    "        # Check if this is a function name\n",
    "        if (node.parent and node.parent.type in ['function_definition', 'call'] and \n",
    "            node == node.parent.child_by_field_name('name')):\n",
    "            return 'func'\n",
    "        \n",
    "        # Check if this is a class name\n",
    "        if (node.parent and node.parent.type == 'class_definition' and \n",
    "            node == node.parent.child_by_field_name('name')):\n",
    "            return 'class'\n",
    "        \n",
    "        # Check if this is a parameter\n",
    "        if (node.parent and node.parent.type in ['parameters', 'lambda_parameters']):\n",
    "            return 'param'\n",
    "        \n",
    "        # Check if this is an attribute\n",
    "        if (node.parent and node.parent.type == 'attribute' and \n",
    "            node == node.parent.child_by_field_name('attribute')):\n",
    "            return 'attr'\n",
    "        \n",
    "        # Check for constants (uppercase)\n",
    "        if node.text.decode('utf8').isupper():\n",
    "            return 'CONST'\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def compare_code(self, code1, code2, language='python'):\n",
    "        \"\"\"Compare two code strings after normalization\"\"\"\n",
    "        # Reset state for fresh comparison\n",
    "        self.counters = {\n",
    "            'variable': 1,\n",
    "            'function': 1,\n",
    "            'class': 1,\n",
    "            'parameter': 1,\n",
    "            'attribute': 1,\n",
    "            'constant': 1\n",
    "        }\n",
    "        self.scopes = [{}]\n",
    "        \n",
    "        # Parse and normalize first code\n",
    "        tree1 = self.parse_code(code1)\n",
    "        norm_ast1 = self.normalize_ast(tree1.root_node, language)\n",
    "        \n",
    "        # Reset state again for second code\n",
    "        self.counters = {\n",
    "            'variable': 1,\n",
    "            'function': 1,\n",
    "            'class': 1,\n",
    "            'parameter': 1,\n",
    "            'attribute': 1,\n",
    "            'constant': 1\n",
    "        }\n",
    "        self.scopes = [{}]\n",
    "        \n",
    "        # Parse and normalize second code\n",
    "        tree2 = self.parse_code(code2)\n",
    "        norm_ast2 = self.normalize_ast(tree2.root_node, language)\n",
    "        \n",
    "        # Compare normalized ASTs\n",
    "        return self.compare_asts(norm_ast1, norm_ast2)\n",
    "    \n",
    "    def compare_asts(self, ast1, ast2):\n",
    "        \"\"\"Recursively compare two normalized ASTs\"\"\"\n",
    "        if ast1['type'] != ast2['type']:\n",
    "            return False\n",
    "        \n",
    "        # Compare normalized identifiers\n",
    "        if 'text' in ast1 or 'text' in ast2:\n",
    "            if 'text' not in ast1 or 'text' not in ast2:\n",
    "                return False\n",
    "            # Only compare the prefix (var1 vs var2 should match)\n",
    "            if ast1['text'].split('_')[0] != ast2['text'].split('_')[0]:\n",
    "                return False\n",
    "        \n",
    "        # Compare children\n",
    "        if len(ast1.get('children', [])) != len(ast2.get('children', [])):\n",
    "            return False\n",
    "        \n",
    "        for child1, child2 in zip(ast1.get('children', []), ast2.get('children', [])):\n",
    "            if not self.compare_asts(child1, child2):\n",
    "                return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    comparator = CodeComparator()\n",
    "    \n",
    "    code1 = \"\"\"\n",
    "    def calculate_sum(a, b):\n",
    "        result = a + b\n",
    "        return result\n",
    "    \n",
    "    class DataProcessor:\n",
    "        def __init__(self, data):\n",
    "            self.data = data\n",
    "    \"\"\"\n",
    "    \n",
    "    code2 = \"\"\"\n",
    "    def compute_total(x, y):\n",
    "        total = x + y\n",
    "        return total\n",
    "    \n",
    "    class InfoHandler:\n",
    "        def __init__(self, info):\n",
    "            self.info = info\n",
    "    \"\"\"\n",
    "    \n",
    "    # These should be structurally identical\n",
    "    code3 = \"\"\"\n",
    "    def func1(param1, param2):\n",
    "        var1 = param1 + param2\n",
    "        return var1\n",
    "    \n",
    "    class Class1:\n",
    "        def __init__(self, param1):\n",
    "            self.attr1 = param1\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Comparing code1 and code2:\", comparator.compare_code(code1, code2))  # True\n",
    "    print(\"Comparing code1 and code3:\", comparator.compare_code(code1, code3))  # True\n",
    "    \n",
    "    # Different structure\n",
    "    code4 = \"\"\"\n",
    "    def process_data(input):\n",
    "        return input * 2\n",
    "    \"\"\"\n",
    "    print(\"Comparing code1 and code4:\", comparator.compare_code(code1, code4))  # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code : \n",
      " def writeBoolean(self, n):\n",
      "    t = TYPE_BOOL \n",
      "\n",
      "Code : \n",
      " def writeBoolean(self, n):\n",
      "    t = TYPE_BOOL_TRUE\n",
      "    if n == 0:\n",
      "        t = TYPE_BOOL_FALSE\n",
      "    self.stream.write(t)\n",
      "    return t \n",
      "\n",
      "Code : \n",
      " def writeBoolean(self, n):\n",
      "    t = TYPE_BOOL_TRUE\n",
      "    if n == False:\n",
      "        t = TYPE_BOOL_FALSE\n",
      "    self.stream.write(t)\n",
      "    return t \n",
      "\n",
      "Similarity between code1 and code2: 1.00\n",
      "Normalized 1: func_1 param_1 param_2 var_1 const_1 \n",
      "Normalized 2: func_1 param_1 param_2 var_1 const_1 param_2 var_1 const_2 param_1 attr_1 attr_2 var_1 var_1 \n",
      "\n",
      "Similarity between code1 and code3: 1.00\n",
      "Normalized 1: func_1 param_1 param_2 var_1 const_1 \n",
      "Normalized 2: func_1 param_1 param_2 var_1 const_1 param_2 var_1 const_2 param_1 attr_1 attr_2 var_1 var_1 \n"
     ]
    }
   ],
   "source": [
    "from tree_sitter import Parser, Language\n",
    "import os\n",
    "import tree_sitter_python as tspython\n",
    "import pandas as pd\n",
    "\n",
    "class ImprovedCodeComparator:\n",
    "    def __init__(self, language='python'):\n",
    "        self.language = Language(tspython.language())\n",
    "        self.parser = Parser(self.language)\n",
    "        \n",
    "        # Track identifier usage across scopes\n",
    "        self.scope_stack = [defaultdict(int)]\n",
    "        self.current_scope = self.scope_stack[-1]\n",
    "        self.normalized_code = []\n",
    "        \n",
    "        # Configuration\n",
    "        self.special_tokens = {'True', 'False', 'None'}\n",
    "\n",
    "    def normalize_code(self, code_str):\n",
    "        \"\"\"Normalize code with proper scoping\"\"\"\n",
    "        \n",
    "        tree = self.parser.parse(bytes(code_str, 'utf8'))\n",
    "        self._normalize_node(tree.root_node)\n",
    "        return ' '.join(self.normalized_code)\n",
    "\n",
    "    def _normalize_node(self, node):\n",
    "        \"\"\"Recursive normalization with scope handling\"\"\"\n",
    "        if node.type == 'identifier':\n",
    "            text = node.text.decode('utf8')\n",
    "            \n",
    "            if text in self.special_tokens:\n",
    "                self.normalized_code.append(text)\n",
    "                return\n",
    "                \n",
    "            # Get normalized name based on scope\n",
    "            norm_name = self._get_normalized_name(node)\n",
    "            self.normalized_code.append(norm_name)\n",
    "            return\n",
    "            \n",
    "        # Handle new scopes\n",
    "        if node.type in ('function_definition', 'class_definition', 'block'):\n",
    "            self.scope_stack.append(defaultdict(int))\n",
    "            self.current_scope = self.scope_stack[-1]\n",
    "            \n",
    "        for child in node.children:\n",
    "            self._normalize_node(child)\n",
    "            \n",
    "        # Exit scope\n",
    "        if node.type in ('function_definition', 'class_definition', 'block'):\n",
    "            self.scope_stack.pop()\n",
    "            self.current_scope = self.scope_stack[-1]\n",
    "\n",
    "    def _get_normalized_name(self, node):\n",
    "        \"\"\"Get normalized identifier name with proper scoping\"\"\"\n",
    "        text = node.text.decode('utf8')\n",
    "        parent = node.parent\n",
    "        \n",
    "        # Determine identifier type\n",
    "        if parent.type == 'function_definition' and node == parent.child_by_field_name('name'):\n",
    "            prefix = 'func'\n",
    "        elif parent.type == 'class_definition' and node == parent.child_by_field_name('name'):\n",
    "            prefix = 'class'\n",
    "        elif parent.type in ('parameters', 'lambda_parameters'):\n",
    "            prefix = 'param'\n",
    "        elif text.isupper():\n",
    "            prefix = 'CONST'\n",
    "        else:\n",
    "            prefix = 'var'\n",
    "            \n",
    "        # Track usage in current scope\n",
    "        self.current_scope[(prefix, text)] += 1\n",
    "        count = self.current_scope[(prefix, text)]\n",
    "        \n",
    "        return f\"{prefix}_{count}\"\n",
    "\n",
    "    def calculate_similarity(self, norm1, norm2):\n",
    "        \"\"\"Calculate similarity between normalized code strings\"\"\"\n",
    "        tokens1 = norm1.split()\n",
    "        tokens2 = norm2.split()\n",
    "        \n",
    "        # Create frequency maps\n",
    "        freq1 = defaultdict(int)\n",
    "        freq2 = defaultdict(int)\n",
    "        \n",
    "        for token in tokens1:\n",
    "            freq1[token] += 1\n",
    "        for token in tokens2:\n",
    "            freq2[token] += 1\n",
    "            \n",
    "        # Calculate intersection\n",
    "        common = 0\n",
    "        for token in freq1:\n",
    "            common += min(freq1[token], freq2[token])\n",
    "            \n",
    "        # Return similarity score (0.0 to 1.0)\n",
    "        max_len = max(len(tokens1), len(tokens2))\n",
    "        return common / max_len if max_len > 0 else 0.0\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        comparator = CodeComparator()\n",
    "        df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/code generation/deepseek_cleaned_code_results_dir/split_part_0_results_results.csv\")\n",
    "        df = df.iloc[0]\n",
    "        code1 = df[\"Generated_Code_deepseek_2_code1\"]\n",
    "        code2 = df[\"Generated_Code_deepseek_2_code2\"]\n",
    "        code3 = df[\"Generated_Code_deepseek_2_code3\"]\n",
    "        print(\"Code : \\n\",code1,\"\\n\")\n",
    "        print(\"Code : \\n\",code2,\"\\n\")\n",
    "        print(\"Code : \\n\",code3,\"\\n\")\n",
    "        # Test cases\n",
    "        # code1 = \"\"\"\n",
    "        # def calculate_sum(a, b):\n",
    "        #     result = a + b\n",
    "        #     return result\n",
    "        # \"\"\"\n",
    "        \n",
    "        # code2 = \"\"\"\n",
    "        # def compute_total(x, y):\n",
    "        #     total = x + y\n",
    "        #     return total\n",
    "        # \"\"\"\n",
    "        \n",
    "        # code3 = \"\"\"\n",
    "        # def process_data(input):\n",
    "        #     return input * 2\n",
    "        # \"\"\"\n",
    "        \n",
    "        # Compare similar functions\n",
    "        result = comparator.compare_code(code1, code2)\n",
    "        print(f\"Similarity between code1 and code2: {result['similarity']:.2f}\")\n",
    "        print(\"Normalized 1:\", result['normalized_code1'])\n",
    "        print(\"Normalized 2:\", result['normalized_code2'])\n",
    "        \n",
    "        # Compare different functions\n",
    "        result = comparator.compare_code(code1, code3)\n",
    "        print(f\"\\nSimilarity between code1 and code3: {result['similarity']:.2f}\")\n",
    "        print(\"Normalized 1:\", result['normalized_code1'])\n",
    "        print(\"Normalized 2:\", result['normalized_code2'])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Initialization failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between code1 and code2: 0.48\n",
      "Similarity between code1 and code3: 0.48\n",
      "Similarity between code2 and code3: 1.00\n"
     ]
    }
   ],
   "source": [
    "from tree_sitter import Parser, Language\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import tree_sitter_python as tspython\n",
    "import pandas as pd\n",
    "       \n",
    "\n",
    "class AccurateCodeComparator:\n",
    "    def __init__(self, language='python'):\n",
    "        # Initialize parser\n",
    "        self.language = Language(tspython.language())\n",
    "        self.parser = Parser(self.language)\n",
    "        \n",
    "        # Special tokens to preserve\n",
    "        self.preserved_tokens = {'True', 'False', 'None', '0', '1'}\n",
    "        \n",
    "        # For similarity calculation\n",
    "        self.weights = {\n",
    "            'function_def': 0.3,\n",
    "            'control_flow': 0.25,\n",
    "            'operations': 0.2,\n",
    "            'literals': 0.15,\n",
    "            'returns': 0.1\n",
    "        }\n",
    "\n",
    "    def normalize_code(self, code_str):\n",
    "        \"\"\"Normalize code while preserving structure\"\"\"\n",
    "        tree = self.parser.parse(bytes(code_str, 'utf8'))\n",
    "        features = self._extract_features(tree.root_node)\n",
    "        return features\n",
    "\n",
    "    def _extract_features(self, node):\n",
    "        \"\"\"Extract structural features from AST\"\"\"\n",
    "        features = defaultdict(int)\n",
    "        \n",
    "        if node.type == 'function_definition':\n",
    "            features['function_def'] += 1\n",
    "            # Don't normalize function name for comparison\n",
    "            fn_name = node.child_by_field_name('name')\n",
    "            if fn_name:\n",
    "                features[f'fn_name:{fn_name.text.decode()}'] += 1\n",
    "            \n",
    "        elif node.type in ('if_statement', 'for_statement', 'while_statement'):\n",
    "            features['control_flow'] += 1\n",
    "            \n",
    "        elif node.type in ('binary_operator', 'unary_operator'):\n",
    "            features['operations'] += 1\n",
    "            op = node.child_by_field_name('operator')\n",
    "            if op:\n",
    "                features[f'op:{op.text.decode()}'] += 1\n",
    "                \n",
    "        elif node.type == 'return_statement':\n",
    "            features['returns'] += 1\n",
    "            \n",
    "        elif node.type == 'identifier':\n",
    "            text = node.text.decode('utf8')\n",
    "            if text in self.preserved_tokens:\n",
    "                features[f'literal:{text}'] += 1\n",
    "            else:\n",
    "                # Normalize other identifiers\n",
    "                features['identifier'] += 1\n",
    "                \n",
    "        # Recursively process children\n",
    "        for child in node.children:\n",
    "            child_features = self._extract_features(child)\n",
    "            for k, v in child_features.items():\n",
    "                features[k] += v\n",
    "                \n",
    "        return features\n",
    "\n",
    "    def calculate_similarity(self, features1, features2):\n",
    "        \"\"\"Calculate weighted similarity between feature sets\"\"\"\n",
    "        all_keys = set(features1.keys()) | set(features2.keys())\n",
    "        similarity = 0.0\n",
    "        total_weight = 0.0\n",
    "        \n",
    "        for key in all_keys:\n",
    "            # Determine feature weight\n",
    "            if key.startswith('fn_name:'):\n",
    "                weight = self.weights['function_def'] * 0.5\n",
    "            elif key.startswith('op:'):\n",
    "                weight = self.weights['operations'] * 0.3\n",
    "            elif key.startswith('literal:'):\n",
    "                weight = self.weights['literals']\n",
    "            elif key == 'function_def':\n",
    "                weight = self.weights['function_def']\n",
    "            elif key == 'control_flow':\n",
    "                weight = self.weights['control_flow']\n",
    "            elif key == 'operations':\n",
    "                weight = self.weights['operations'] * 0.7\n",
    "            elif key == 'returns':\n",
    "                weight = self.weights['returns']\n",
    "            else:\n",
    "                weight = 0.05  # Default low weight\n",
    "                \n",
    "            # Calculate feature similarity\n",
    "            val1 = features1.get(key, 0)\n",
    "            val2 = features2.get(key, 0)\n",
    "            similarity += min(val1, val2) * weight\n",
    "            total_weight += max(val1, val2) * weight\n",
    "            \n",
    "        return similarity / total_weight if total_weight > 0 else 0.0\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    comparator = AccurateCodeComparator()\n",
    "    \n",
    "    code1 = \"\"\"def writeBoolean(self, n):\n",
    "    t = TYPE_BOOL\"\"\"\n",
    "    \n",
    "    code2 = \"\"\"def writeBoolean(self, n):\n",
    "    t = TYPE_BOOL_TRUE\n",
    "    if n == 0:\n",
    "        t = TYPE_BOOL_FALSE\n",
    "    self.stream.write(t)\n",
    "    return t\"\"\"\n",
    "    \n",
    "    code3 = \"\"\"def writeBoolean(self, n):\n",
    "    t = TYPE_BOOL_TRUE\n",
    "    if n == False:\n",
    "        t = TYPE_BOOL_FALSE\n",
    "    self.stream.write(t)\n",
    "    return t\"\"\"\n",
    "    \n",
    "    # Extract features\n",
    "    features1 = comparator.normalize_code(code1)\n",
    "    features2 = comparator.normalize_code(code2)\n",
    "    features3 = comparator.normalize_code(code3)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    sim1_2 = comparator.calculate_similarity(features1, features2)\n",
    "    sim1_3 = comparator.calculate_similarity(features1, features3)\n",
    "    sim2_3 = comparator.calculate_similarity(features2, features3)\n",
    "    \n",
    "    print(f\"Similarity between code1 and code2: {sim1_2:.2f}\")\n",
    "    print(f\"Similarity between code1 and code3: {sim1_3:.2f}\")\n",
    "    print(f\"Similarity between code2 and code3: {sim2_3:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between code1 and code2: 0.45\n",
      "Similarity between code1 and code3: 0.42\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/code generation/deepseek_cleaned_code_results_dir/split_part_0_results_results.csv\")\n",
    "df = df.iloc[1]\n",
    "code1 = df[\"Original_Code\"]\n",
    "code2 = df[\"Generated_Code_deepseek_2_code1\"]\n",
    "code3 = df[\"Generated_Code_deepseek_2_code2\"]\n",
    "\n",
    "features1 = comparator.normalize_code(code1)\n",
    "features2 = comparator.normalize_code(code2)\n",
    "features3 = comparator.normalize_code(code3)\n",
    "\n",
    "# Calculate similarities\n",
    "sim1_2 = comparator.calculate_similarity(features1, features2)\n",
    "sim1_3 = comparator.calculate_similarity(features1, features3)\n",
    "\n",
    "print(f\"Similarity between code1 and code2: {sim1_2:.2f}\")\n",
    "print(f\"Similarity between code1 and code3: {sim1_3:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'function_def': 1, 'fn_name:paste': 1, 'identifier': 15, 'returns': 1})\n"
     ]
    }
   ],
   "source": [
    "print(features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>Original_Code</th>\n",
       "      <th>Generated_Code_deepseek_1_code1</th>\n",
       "      <th>Generated_Code_deepseek_1_code2</th>\n",
       "      <th>Generated_Code_deepseek_1_code3</th>\n",
       "      <th>Generated_Code_deepseek_2_code1</th>\n",
       "      <th>Generated_Code_deepseek_2_code2</th>\n",
       "      <th>Generated_Code_deepseek_2_code3</th>\n",
       "      <th>Generated_Code_deepseek_3_code1</th>\n",
       "      <th>Generated_Code_deepseek_3_code2</th>\n",
       "      <th>Generated_Code_deepseek_3_code3</th>\n",
       "      <th>Generated_Code_deepseek_4_code1</th>\n",
       "      <th>Generated_Code_deepseek_4_code2</th>\n",
       "      <th>Generated_Code_deepseek_4_code3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1</td>\n",
       "      <td>q1</td>\n",
       "      <td>def writeBoolean(self, n):\\n        \"\"\"\\n     ...</td>\n",
       "      <td>def flip_stream(condition):\\n    # code</td>\n",
       "      <td>def f(n):\\n    # ... code ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def writeBoolean(self, n):\\n    t = TYPE_BOOL</td>\n",
       "      <td>def writeBoolean(self, n):\\n    t = TYPE_BOOL_...</td>\n",
       "      <td>def writeBoolean(self, n):\\n    t = TYPE_BOOL_...</td>\n",
       "      <td>def writeBoolean(n):\\n    t = TYPE_BOOL_TRUE</td>\n",
       "      <td>def writeBoolean(n):\\n    # Initialize t to TY...</td>\n",
       "      <td>def writeBoolean(n):\\n    t = TYPE_BOOL_TRUE\\n...</td>\n",
       "      <td>def writeBoolean(n):\\n    t = TYPE_BOOL_TRUE\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2</td>\n",
       "      <td>q2</td>\n",
       "      <td>def paste(xsel=False):\\n    \"\"\"Returns system ...</td>\n",
       "      <td>def paste(xsel=False):\\n    selection = \"prima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def paste(xsel=False):\\n\\n    \"\"\"Pastes data f...</td>\n",
       "      <td>def paste(xsel=None):\\n    # Line 2: set selec...</td>\n",
       "      <td>def paste(xsel=None):\\n    # ... code here ...</td>\n",
       "      <td>def paste(xsel=None):\\n    if xsel is None:\\n ...</td>\n",
       "      <td>def paste(xsel=None):\\n    if xsel is not None...</td>\n",
       "      <td>def paste(xsel=None):\\n    if xsel is None:\\n ...</td>\n",
       "      <td>def paste(xsel=None):</td>\n",
       "      <td>def paste(xsel=None):\\n    # ... code ...\\n   ...</td>\n",
       "      <td>def paste(xsel=None):\\n    # ... code here ......</td>\n",
       "      <td>def paste(xsel=None):</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d3</td>\n",
       "      <td>q3</td>\n",
       "      <td>def _format_json(data, theme):\\n    \"\"\"Pretty ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    return jso...</td>\n",
       "      <td>def format_json(data, theme):\\n    # ... code ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    # Code\\n  ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    output = j...</td>\n",
       "      <td>pygments.highlight(output, JsonLexer()</td>\n",
       "      <td>def _format_json(data, theme):\\n    \"\"\"Pretty ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    try:\\n    ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    # ... code...</td>\n",
       "      <td>def _format_json(data, theme):\\n    # ... code...</td>\n",
       "      <td>def _format_json(data, theme):\\n\\n    if sys.o...</td>\n",
       "      <td>def format_json(data, theme):\\n    # ... code ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    # ... code...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d4</td>\n",
       "      <td>q4</td>\n",
       "      <td>def create_path(path):\\n    \"\"\"Creates a absol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def f(a, b, c, d, e, f, g, h, i, j, k, l, m, n...</td>\n",
       "      <td>def absolute_path(relative_path):\\n    # code ...</td>\n",
       "      <td>def create_path(path):\\n    if not os.path.exi...</td>\n",
       "      <td>def create_path(path):\\n    if os.path.isabs(p...</td>\n",
       "      <td>def create_path(path):\\n    # Check if the pat...</td>\n",
       "      <td>def file_path(file_path):\\n    # ... code ...\\...</td>\n",
       "      <td>def __init__(self, path):\\n    # ... code here...</td>\n",
       "      <td>def __file__(path):\\n    # ... code here ...</td>\n",
       "      <td>def create_path(path):\\n    import os\\n    if ...</td>\n",
       "      <td>def create_path(path):\\n    import os\\n    if ...</td>\n",
       "      <td>def create_path(path):\\n    import os\\n    if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d5</td>\n",
       "      <td>q5</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    \"\"\"...</td>\n",
       "      <td>def check_array(x):\\n    # code here\\n    retu...</td>\n",
       "      <td>np.array(x)</td>\n",
       "      <td>def array_to_column_vector(x):\\n    # Check if...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    if ...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    if ...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    # c...</td>\n",
       "      <td>np.column_stack()</td>\n",
       "      <td>def _vector_or_scalar(x, type=None):\\n    # co...</td>\n",
       "      <td>def _vector_or_scalar(x, type=None):\\n    # co...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    if ...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    # C...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    # c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  corpus_id query_id                                      Original_Code  \\\n",
       "0        d1       q1  def writeBoolean(self, n):\\n        \"\"\"\\n     ...   \n",
       "1        d2       q2  def paste(xsel=False):\\n    \"\"\"Returns system ...   \n",
       "2        d3       q3  def _format_json(data, theme):\\n    \"\"\"Pretty ...   \n",
       "3        d4       q4  def create_path(path):\\n    \"\"\"Creates a absol...   \n",
       "4        d5       q5  def _vector_or_scalar(x, type='row'):\\n    \"\"\"...   \n",
       "\n",
       "                     Generated_Code_deepseek_1_code1  \\\n",
       "0            def flip_stream(condition):\\n    # code   \n",
       "1  def paste(xsel=False):\\n    selection = \"prima...   \n",
       "2  def _format_json(data, theme):\\n    return jso...   \n",
       "3                                                NaN   \n",
       "4  def check_array(x):\\n    # code here\\n    retu...   \n",
       "\n",
       "                     Generated_Code_deepseek_1_code2  \\\n",
       "0                      def f(n):\\n    # ... code ...   \n",
       "1                                                NaN   \n",
       "2  def format_json(data, theme):\\n    # ... code ...   \n",
       "3  def f(a, b, c, d, e, f, g, h, i, j, k, l, m, n...   \n",
       "4                                        np.array(x)   \n",
       "\n",
       "                     Generated_Code_deepseek_1_code3  \\\n",
       "0                                                NaN   \n",
       "1  def paste(xsel=False):\\n\\n    \"\"\"Pastes data f...   \n",
       "2  def _format_json(data, theme):\\n    # Code\\n  ...   \n",
       "3  def absolute_path(relative_path):\\n    # code ...   \n",
       "4  def array_to_column_vector(x):\\n    # Check if...   \n",
       "\n",
       "                     Generated_Code_deepseek_2_code1  \\\n",
       "0      def writeBoolean(self, n):\\n    t = TYPE_BOOL   \n",
       "1  def paste(xsel=None):\\n    # Line 2: set selec...   \n",
       "2  def _format_json(data, theme):\\n    output = j...   \n",
       "3  def create_path(path):\\n    if not os.path.exi...   \n",
       "4  def _vector_or_scalar(x, type='row'):\\n    if ...   \n",
       "\n",
       "                     Generated_Code_deepseek_2_code2  \\\n",
       "0  def writeBoolean(self, n):\\n    t = TYPE_BOOL_...   \n",
       "1     def paste(xsel=None):\\n    # ... code here ...   \n",
       "2             pygments.highlight(output, JsonLexer()   \n",
       "3  def create_path(path):\\n    if os.path.isabs(p...   \n",
       "4  def _vector_or_scalar(x, type='row'):\\n    if ...   \n",
       "\n",
       "                     Generated_Code_deepseek_2_code3  \\\n",
       "0  def writeBoolean(self, n):\\n    t = TYPE_BOOL_...   \n",
       "1  def paste(xsel=None):\\n    if xsel is None:\\n ...   \n",
       "2  def _format_json(data, theme):\\n    \"\"\"Pretty ...   \n",
       "3  def create_path(path):\\n    # Check if the pat...   \n",
       "4  def _vector_or_scalar(x, type='row'):\\n    # c...   \n",
       "\n",
       "                     Generated_Code_deepseek_3_code1  \\\n",
       "0       def writeBoolean(n):\\n    t = TYPE_BOOL_TRUE   \n",
       "1  def paste(xsel=None):\\n    if xsel is not None...   \n",
       "2  def _format_json(data, theme):\\n    try:\\n    ...   \n",
       "3  def file_path(file_path):\\n    # ... code ...\\...   \n",
       "4                                  np.column_stack()   \n",
       "\n",
       "                     Generated_Code_deepseek_3_code2  \\\n",
       "0  def writeBoolean(n):\\n    # Initialize t to TY...   \n",
       "1  def paste(xsel=None):\\n    if xsel is None:\\n ...   \n",
       "2  def _format_json(data, theme):\\n    # ... code...   \n",
       "3  def __init__(self, path):\\n    # ... code here...   \n",
       "4  def _vector_or_scalar(x, type=None):\\n    # co...   \n",
       "\n",
       "                     Generated_Code_deepseek_3_code3  \\\n",
       "0  def writeBoolean(n):\\n    t = TYPE_BOOL_TRUE\\n...   \n",
       "1                              def paste(xsel=None):   \n",
       "2  def _format_json(data, theme):\\n    # ... code...   \n",
       "3       def __file__(path):\\n    # ... code here ...   \n",
       "4  def _vector_or_scalar(x, type=None):\\n    # co...   \n",
       "\n",
       "                     Generated_Code_deepseek_4_code1  \\\n",
       "0  def writeBoolean(n):\\n    t = TYPE_BOOL_TRUE\\n...   \n",
       "1  def paste(xsel=None):\\n    # ... code ...\\n   ...   \n",
       "2  def _format_json(data, theme):\\n\\n    if sys.o...   \n",
       "3  def create_path(path):\\n    import os\\n    if ...   \n",
       "4  def _vector_or_scalar(x, type='row'):\\n    if ...   \n",
       "\n",
       "                     Generated_Code_deepseek_4_code2  \\\n",
       "0                                                NaN   \n",
       "1  def paste(xsel=None):\\n    # ... code here ......   \n",
       "2  def format_json(data, theme):\\n    # ... code ...   \n",
       "3  def create_path(path):\\n    import os\\n    if ...   \n",
       "4  def _vector_or_scalar(x, type='row'):\\n    # C...   \n",
       "\n",
       "                     Generated_Code_deepseek_4_code3  \n",
       "0                                                NaN  \n",
       "1                              def paste(xsel=None):  \n",
       "2  def _format_json(data, theme):\\n    # ... code...  \n",
       "3  def create_path(path):\\n    import os\\n    if ...  \n",
       "4  def _vector_or_scalar(x, type='row'):\\n    # c...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/code generation/deepseek_cleaned_code_results_dir/split_part_0_results_results.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm 1 module function_definition def FUNC_1 parameters ( PARAM_2 , PARAM_3 ) : block expression_statement assignment VAR_4 = binary_operator PARAM_2 + PARAM_3 return_statement return VAR_4\n",
      "Norm 2 module function_definition def FUNC_1 parameters ( PARAM_2 , PARAM_3 ) : block expression_statement assignment VAR_4 = binary_operator PARAM_2 + PARAM_3 return_statement return VAR_4\n",
      "Similarity (code1 vs code2): 0.9999999999999998\n",
      "Norm 1 module function_definition def FUNC_1 parameters ( PARAM_2 , PARAM_3 ) : block expression_statement assignment VAR_4 = binary_operator PARAM_2 + PARAM_3 return_statement return VAR_4\n",
      "Norm 2 module function_definition def FUNC_1 parameters ( PARAM_2 ) : block if_statement if comparison_operator PARAM_2 > integer : block return_statement return binary_operator PARAM_2 * integer return_statement return integer\n",
      "Similarity (code1 vs code3): 0.4375526574551408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/pi_wenlongzhao_umass_edu/27/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tree_sitter import Parser, Language\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import tree_sitter_python as tspython\n",
    "\n",
    "class CodeSimilarityCalculator:\n",
    "    def __init__(self, language='python'):\n",
    "        # Initialize parser\n",
    "        self.language = Language(tspython.language())\n",
    "        self.parser = Parser(self.language)\n",
    "        \n",
    "        # For normalization\n",
    "        self.identifier_counter = 1\n",
    "        self.identifier_map = {}\n",
    "        self.scope_stack = [{}]\n",
    "        \n",
    "        # Special tokens to preserve\n",
    "        self.preserved_tokens = {'True', 'False', 'None', '0', '1', 'if', 'else', 'for', 'while', 'return'}\n",
    "        \n",
    "        # For vectorization\n",
    "        self.vectorizer = TfidfVectorizer(tokenizer=self._tokenize_code, lowercase=False)\n",
    "\n",
    "    def normalize_code(self, code_str):\n",
    "        \"\"\"Normalize code by generalizing identifiers\"\"\"\n",
    "        self.identifier_counter = 1\n",
    "        self.identifier_map = {}\n",
    "        self.scope_stack = [{}]\n",
    "        \n",
    "        tree = self.parser.parse(bytes(code_str, 'utf8'))\n",
    "        normalized = self._normalize_node(tree.root_node)\n",
    "        return self._structure_to_text(normalized)\n",
    "\n",
    "    def _normalize_node(self, node):\n",
    "        \"\"\"Recursively normalize AST nodes\"\"\"\n",
    "        normalized = {'type': node.type}\n",
    "        \n",
    "        # Handle identifiers\n",
    "        if node.type == 'identifier':\n",
    "            text = node.text.decode('utf8')\n",
    "            if text in self.preserved_tokens:\n",
    "                return {'type': 'literal', 'value': text}\n",
    "            return {'type': 'identifier', 'name': self._get_normalized_name(node)}\n",
    "        \n",
    "        # Handle new scopes\n",
    "        if node.type in ('function_definition', 'class_definition', 'block'):\n",
    "            self.scope_stack.append({})\n",
    "            \n",
    "        # Process children\n",
    "        normalized['children'] = []\n",
    "        for child in node.children:\n",
    "            norm_child = self._normalize_node(child)\n",
    "            if norm_child:\n",
    "                normalized['children'].append(norm_child)\n",
    "        \n",
    "        # Exit scope\n",
    "        if node.type in ('function_definition', 'class_definition', 'block'):\n",
    "            self.scope_stack.pop()\n",
    "            \n",
    "        return normalized\n",
    "\n",
    "    def _get_normalized_name(self, node):\n",
    "        \"\"\"Generate consistent normalized names\"\"\"\n",
    "        text = node.text.decode('utf8')\n",
    "        parent = node.parent\n",
    "        \n",
    "        # Check current scope first\n",
    "        for scope in reversed(self.scope_stack):\n",
    "            if text in scope:\n",
    "                return scope[text]\n",
    "        \n",
    "        # Determine type prefix\n",
    "        if parent.type == 'function_definition' and node == parent.child_by_field_name('name'):\n",
    "            prefix = 'FUNC'\n",
    "        elif parent.type == 'class_definition' and node == parent.child_by_field_name('name'):\n",
    "            prefix = 'CLASS'\n",
    "        elif parent.type in ('parameters', 'lambda_parameters'):\n",
    "            prefix = 'PARAM'\n",
    "        elif text.isupper():\n",
    "            prefix = 'CONST'\n",
    "        else:\n",
    "            prefix = 'VAR'\n",
    "            \n",
    "        # Create and store normalized name\n",
    "        norm_name = f\"{prefix}_{self.identifier_counter}\"\n",
    "        self.identifier_counter += 1\n",
    "        self.scope_stack[-1][text] = norm_name\n",
    "        return norm_name\n",
    "\n",
    "    def _structure_to_text(self, node):\n",
    "        \"\"\"Convert normalized structure to comparable text\"\"\"\n",
    "        if node['type'] == 'identifier':\n",
    "            return node['name']\n",
    "        elif node['type'] == 'literal':\n",
    "            return node['value']\n",
    "        \n",
    "        parts = [node['type']]\n",
    "        for child in node.get('children', []):\n",
    "            parts.append(self._structure_to_text(child))\n",
    "        return ' '.join(parts)\n",
    "\n",
    "    def _tokenize_code(self, code_text):\n",
    "        \"\"\"Tokenize normalized code for vectorization\"\"\"\n",
    "        # Split by operators, brackets, etc. while preserving tokens\n",
    "        tokens = re.findall(r'[A-Za-z_][A-Za-z0-9_]*|[0-9]+|\\S', code_text)\n",
    "        return [t for t in tokens if t.strip()]\n",
    "\n",
    "    def cosine_similarity(self, code1, code2):\n",
    "        \"\"\"Calculate cosine similarity between two code snippets\"\"\"\n",
    "        norm1 = self.normalize_code(code1)\n",
    "        norm2 = self.normalize_code(code2)\n",
    "        print(\"Norm 1\", norm1)\n",
    "        print(\"Norm 2\", norm2)\n",
    "        \n",
    "        # Fit vectorizer and transform\n",
    "        vectors = self.vectorizer.fit_transform([norm1, norm2])\n",
    "        return cosine_similarity(vectors[0], vectors[1])[0][0]\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    comparator = CodeSimilarityCalculator()\n",
    "    \n",
    "    # Similar functions\n",
    "    code1 = \"\"\"\n",
    "    def calculate(x, y):\n",
    "        result = x + y\n",
    "        return result\n",
    "    \"\"\"\n",
    "    \n",
    "    code2 = \"\"\"\n",
    "    def compute(a, b):\n",
    "        total = a + b\n",
    "        return total\n",
    "    \"\"\"\n",
    "    \n",
    "    # Different function\n",
    "    code3 = \"\"\"\n",
    "    def process_data(input):\n",
    "        if input > 0:\n",
    "            return input * 2\n",
    "        return 0\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/code generation/deepseek_cleaned_code_results_dir/split_part_0_results_results.csv\")\n",
    "    df = df.iloc[1]\n",
    "    print(\"Similarity (code1 vs code2):\", \n",
    "          comparator.cosine_similarity(code1, code2))  # Should be high (~0.8-1.0)\n",
    "    \n",
    "    print(\"Similarity (code1 vs code3):\", \n",
    "          comparator.cosine_similarity(code1, code3))  # Should be low (~0.1-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>Original_Code</th>\n",
       "      <th>Generated_Code_deepseek_1</th>\n",
       "      <th>Generated_Code_deepseek_2</th>\n",
       "      <th>Generated_Code_deepseek_3</th>\n",
       "      <th>Generated_Code_deepseek_4</th>\n",
       "      <th>Generated_Code_granite_1</th>\n",
       "      <th>Generated_Code_granite_2</th>\n",
       "      <th>Generated_Code_granite_3</th>\n",
       "      <th>Generated_Code_granite_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1</td>\n",
       "      <td>q1</td>\n",
       "      <td>def writeBoolean(self, n):\\n        \"\"\"\\n     ...</td>\n",
       "      <td>```python\\ndef flip_stream(n):\\n    current_va...</td>\n",
       "      <td>def writeBoolean(self, n: int) -&gt; None:\\n    i...</td>\n",
       "      <td>```python\\ndef writeBoolean(n):\\n    t = TYPE_...</td>\n",
       "      <td>The Python function is named writeBoolean and ...</td>\n",
       "      <td>```python\\ndef writeBoolean(self, n):\\n    \"\"\"...</td>\n",
       "      <td>```python\\ndef writeBoolean(self, n):\\n    \"\"\"...</td>\n",
       "      <td>```python\\ndef write_bool(stream, n):\\n    t =...</td>\n",
       "      <td>```python\\ndef writeBoolean(self, n):\\n    \"\"\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2</td>\n",
       "      <td>q2</td>\n",
       "      <td>def paste(xsel=False):\\n    \"\"\"Returns system ...</td>\n",
       "      <td>```python\\ndef paste(xsel=False):\\n    \"\"\"Past...</td>\n",
       "      <td>```python\\ndef paste(xsel=None):\\n    selectio...</td>\n",
       "      <td>```python\\ndef paste(xsel=None):\\n    if xsel ...</td>\n",
       "      <td>```python\\ndef paste(xsel=None):\\n    if xsel ...</td>\n",
       "      <td>```python\\nimport subprocess\\n\\nclass XclipNot...</td>\n",
       "      <td>```python\\ndef paste(xsel=False):\\n    \"\"\"Retu...</td>\n",
       "      <td>```python\\nimport subprocess\\n\\ndef get_clipbo...</td>\n",
       "      <td>```python\\nimport subprocess\\n\\ndef paste(xsel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d3</td>\n",
       "      <td>q3</td>\n",
       "      <td>def _format_json(data, theme):\\n    \"\"\"Pretty ...</td>\n",
       "      <td>def format_json(data, theme):\\n    return json...</td>\n",
       "      <td>```python\\ndef _format_json(data, theme):\\n   ...</td>\n",
       "      <td>```python\\nimport json\\n\\ndef _format_json(dat...</td>\n",
       "      <td>```python\\nimport json\\n\\ndef _format_json(dat...</td>\n",
       "      <td>```python\\nimport json\\nimport sys\\nfrom pygme...</td>\n",
       "      <td>```python\\ndef _format_json(data, theme):\\n   ...</td>\n",
       "      <td>```python\\nimport json\\nimport pygments\\nfrom ...</td>\n",
       "      <td>```python\\nimport json\\nimport sys\\nimport pyg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d4</td>\n",
       "      <td>q4</td>\n",
       "      <td>def create_path(path):\\n    \"\"\"Creates a absol...</td>\n",
       "      <td>def relative_to_absolute(s):\\n    return s.lst...</td>\n",
       "      <td>import os\\n\\ndef create_path(path):\\n    if no...</td>\n",
       "      <td>def create_path_system(path):\\n    import os\\n...</td>\n",
       "      <td>```python\\ndef create_path(path):\\n    import ...</td>\n",
       "      <td>```python\\nimport os\\n\\ndef create_path(path):...</td>\n",
       "      <td>```python\\nimport os\\n\\ndef create_path(path):...</td>\n",
       "      <td>```python\\nimport os\\n\\ndef create_directory(p...</td>\n",
       "      <td>```python\\nimport os\\n\\ndef create_path(path):...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d5</td>\n",
       "      <td>q5</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    \"\"\"...</td>\n",
       "      <td>```python\\nimport numpy as np\\n\\ndef check_arr...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    if ...</td>\n",
       "      <td>```python\\nimport numpy as np\\n\\ndef _vector_o...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    if ...</td>\n",
       "      <td>```python\\nimport numpy as np\\n\\ndef _vector_o...</td>\n",
       "      <td>```python\\nimport numpy as np\\n\\ndef _vector_o...</td>\n",
       "      <td>```python\\nimport numpy as np\\n\\ndef convert_a...</td>\n",
       "      <td>```python\\nimport numpy as np\\n\\ndef _vector_o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  corpus_id query_id                                      Original_Code  \\\n",
       "0        d1       q1  def writeBoolean(self, n):\\n        \"\"\"\\n     ...   \n",
       "1        d2       q2  def paste(xsel=False):\\n    \"\"\"Returns system ...   \n",
       "2        d3       q3  def _format_json(data, theme):\\n    \"\"\"Pretty ...   \n",
       "3        d4       q4  def create_path(path):\\n    \"\"\"Creates a absol...   \n",
       "4        d5       q5  def _vector_or_scalar(x, type='row'):\\n    \"\"\"...   \n",
       "\n",
       "                           Generated_Code_deepseek_1  \\\n",
       "0  ```python\\ndef flip_stream(n):\\n    current_va...   \n",
       "1  ```python\\ndef paste(xsel=False):\\n    \"\"\"Past...   \n",
       "2  def format_json(data, theme):\\n    return json...   \n",
       "3  def relative_to_absolute(s):\\n    return s.lst...   \n",
       "4  ```python\\nimport numpy as np\\n\\ndef check_arr...   \n",
       "\n",
       "                           Generated_Code_deepseek_2  \\\n",
       "0  def writeBoolean(self, n: int) -> None:\\n    i...   \n",
       "1  ```python\\ndef paste(xsel=None):\\n    selectio...   \n",
       "2  ```python\\ndef _format_json(data, theme):\\n   ...   \n",
       "3  import os\\n\\ndef create_path(path):\\n    if no...   \n",
       "4  def _vector_or_scalar(x, type='row'):\\n    if ...   \n",
       "\n",
       "                           Generated_Code_deepseek_3  \\\n",
       "0  ```python\\ndef writeBoolean(n):\\n    t = TYPE_...   \n",
       "1  ```python\\ndef paste(xsel=None):\\n    if xsel ...   \n",
       "2  ```python\\nimport json\\n\\ndef _format_json(dat...   \n",
       "3  def create_path_system(path):\\n    import os\\n...   \n",
       "4  ```python\\nimport numpy as np\\n\\ndef _vector_o...   \n",
       "\n",
       "                           Generated_Code_deepseek_4  \\\n",
       "0  The Python function is named writeBoolean and ...   \n",
       "1  ```python\\ndef paste(xsel=None):\\n    if xsel ...   \n",
       "2  ```python\\nimport json\\n\\ndef _format_json(dat...   \n",
       "3  ```python\\ndef create_path(path):\\n    import ...   \n",
       "4  def _vector_or_scalar(x, type='row'):\\n    if ...   \n",
       "\n",
       "                            Generated_Code_granite_1  \\\n",
       "0  ```python\\ndef writeBoolean(self, n):\\n    \"\"\"...   \n",
       "1  ```python\\nimport subprocess\\n\\nclass XclipNot...   \n",
       "2  ```python\\nimport json\\nimport sys\\nfrom pygme...   \n",
       "3  ```python\\nimport os\\n\\ndef create_path(path):...   \n",
       "4  ```python\\nimport numpy as np\\n\\ndef _vector_o...   \n",
       "\n",
       "                            Generated_Code_granite_2  \\\n",
       "0  ```python\\ndef writeBoolean(self, n):\\n    \"\"\"...   \n",
       "1  ```python\\ndef paste(xsel=False):\\n    \"\"\"Retu...   \n",
       "2  ```python\\ndef _format_json(data, theme):\\n   ...   \n",
       "3  ```python\\nimport os\\n\\ndef create_path(path):...   \n",
       "4  ```python\\nimport numpy as np\\n\\ndef _vector_o...   \n",
       "\n",
       "                            Generated_Code_granite_3  \\\n",
       "0  ```python\\ndef write_bool(stream, n):\\n    t =...   \n",
       "1  ```python\\nimport subprocess\\n\\ndef get_clipbo...   \n",
       "2  ```python\\nimport json\\nimport pygments\\nfrom ...   \n",
       "3  ```python\\nimport os\\n\\ndef create_directory(p...   \n",
       "4  ```python\\nimport numpy as np\\n\\ndef convert_a...   \n",
       "\n",
       "                            Generated_Code_granite_4  \n",
       "0  ```python\\ndef writeBoolean(self, n):\\n    \"\"\"...  \n",
       "1  ```python\\nimport subprocess\\n\\ndef paste(xsel...  \n",
       "2  ```python\\nimport json\\nimport sys\\nimport pyg...  \n",
       "3  ```python\\nimport os\\n\\ndef create_path(path):...  \n",
       "4  ```python\\nimport numpy as np\\n\\ndef _vector_o...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_1/code_generation/cleaned_deepseek_exps_results_dir/split_part_0_results.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model =\"granite\"\n",
    "df = pd.read_csv(f\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_1/code_generation/cleaned_{model}_exps_results_dir/split_part_0_results.csv\")\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        df = df.rename(columns={f'Generated_Code_{model}_{i+1}': f'Generated_Code_{model}_{i+1}_code_{j+1}'})\n",
    "df.to_csv(f\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_1/code_generation/cleaned_{model}_exps_results_dir/split_part_0_results.csv\",index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CodeBLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final CodeBLEU Score: None\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "def run_codebleu_on_strings(reference_codes, generated_code, lang='python', params='0.25,0.25,0.25,0.25', script_path='codebleu_eval.py'):\n",
    "    # Step 1: Write reference code(s) to temp files\n",
    "    ref_paths = []\n",
    "    try:\n",
    "        for ref_code in reference_codes:\n",
    "            tmp_ref = tempfile.NamedTemporaryFile(mode='w+', delete=False, suffix='.txt')\n",
    "            tmp_ref.write(ref_code.strip() + \"\\n\")\n",
    "            tmp_ref.flush()\n",
    "            ref_paths.append(tmp_ref.name)\n",
    "            tmp_ref.close()\n",
    "\n",
    "        # Step 2: Write generated code to a temp file\n",
    "        tmp_hyp = tempfile.NamedTemporaryFile(mode='w+', delete=False, suffix='.txt')\n",
    "        tmp_hyp.write(generated_code.strip() + \"\\n\")\n",
    "        tmp_hyp.flush()\n",
    "        hyp_path = tmp_hyp.name\n",
    "        tmp_hyp.close()\n",
    "\n",
    "        # Step 3: Build and run subprocess\n",
    "        cmd = [\"python\", script_path, \"--refs\", *ref_paths, \"--hyp\", hyp_path, \"--lang\", lang, \"--params\", params]\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "        print(result.stdout)  # Optional debug\n",
    "        score_line = [line for line in result.stdout.splitlines() if 'CodeBLEU score:' in line]\n",
    "        score = float(score_line[0].split()[-1]) if score_line else None\n",
    "\n",
    "    finally:\n",
    "        # Step 4: Clean up all temp files\n",
    "        for path in ref_paths:\n",
    "            os.remove(path)\n",
    "        if 'hyp_path' in locals():\n",
    "            os.remove(hyp_path)\n",
    "\n",
    "    return score\n",
    "ref_codes = [\n",
    "    \"def add(a, b): return a + b\",\n",
    "    \"def sum(x, y): return x + y\"\n",
    "]\n",
    "\n",
    "generated = \"def add(a, b): return a + b\"\n",
    "\n",
    "score = run_codebleu_on_strings(ref_codes, generated)\n",
    "print(\"Final CodeBLEU Score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>Original_Code</th>\n",
       "      <th>Generated_Code_granite_1_code1</th>\n",
       "      <th>Generated_Code_granite_1_code2</th>\n",
       "      <th>Generated_Code_granite_1_code3</th>\n",
       "      <th>Generated_Code_granite_2_code1</th>\n",
       "      <th>Generated_Code_granite_2_code2</th>\n",
       "      <th>Generated_Code_granite_2_code3</th>\n",
       "      <th>Generated_Code_granite_3_code1</th>\n",
       "      <th>Generated_Code_granite_3_code2</th>\n",
       "      <th>Generated_Code_granite_3_code3</th>\n",
       "      <th>Generated_Code_granite_4_code1</th>\n",
       "      <th>Generated_Code_granite_4_code2</th>\n",
       "      <th>Generated_Code_granite_4_code3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1</td>\n",
       "      <td>q1</td>\n",
       "      <td>def writeBoolean(self, n):\\n        \"\"\"\\n     ...</td>\n",
       "      <td>def writeBoolean(n):\\n    if not n:\\n        r...</td>\n",
       "      <td>def writeBoolean(self, n):\\n    if not n:\\n   ...</td>\n",
       "      <td>def writeBoolean(self, n):\\n    if not n:\\n   ...</td>\n",
       "      <td>def writeBoolean(self, n):\\n    \"\"\"\\n    This ...</td>\n",
       "      <td>def writeBoolean(self, n):\\n    \"\"\"\\n    This ...</td>\n",
       "      <td>def writeBoolean(self, n):\\n    \"\"\"\\n    This ...</td>\n",
       "      <td>def write_bool(stream, n):\\n    t = 'True' if ...</td>\n",
       "      <td>def write_bool(stream, n):\\n    t = 'True' if ...</td>\n",
       "      <td>def write_bool(stream, n):\\n    t = 'True' if ...</td>\n",
       "      <td>def writeBoolean(self, n):\\n    \"\"\"\\n    Write...</td>\n",
       "      <td>def writeBoolean(self, n):\\n    \"\"\"Writes a Bo...</td>\n",
       "      <td>def writeBoolean(self, n):\\n    \"\"\"\\n    Write...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2</td>\n",
       "      <td>q2</td>\n",
       "      <td>def paste(xsel=False):\\n    \"\"\"Returns system ...</td>\n",
       "      <td>def paste(xsel=False):\\n    \"\"\"Returns system ...</td>\n",
       "      <td>def paste(xsel=False):\\n    \"\"\"Returns system ...</td>\n",
       "      <td>def paste(xsel=False):\\n    \"\"\"Returns system ...</td>\n",
       "      <td>def paste(xsel=False):\\n    \"\"\"Returns system ...</td>\n",
       "      <td>def paste(xsel=False):\\n    \"\"\"Returns system ...</td>\n",
       "      <td>def paste(xsel=False):\\n    \"\"\"Returns system ...</td>\n",
       "      <td>def get_clipboard():\\n    try:\\n        if xse...</td>\n",
       "      <td>def get_clipboard():\\n    try:\\n        if xse...</td>\n",
       "      <td>def get_clipboard():\\n    try:\\n        if xse...</td>\n",
       "      <td>def paste(xsel=False):\\n    try:\\n        if x...</td>\n",
       "      <td>def paste(xsel=False):\\n    try:\\n        if x...</td>\n",
       "      <td>def paste(xsel=False):\\n    try:\\n        if x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d3</td>\n",
       "      <td>q3</td>\n",
       "      <td>def _format_json(data, theme):\\n    \"\"\"Pretty ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    try:\\n    ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    try:\\n    ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    try:\\n    ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    \"\"\"Pretty ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    \"\"\"Pretty ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    \"\"\"Pretty ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    json_strin...</td>\n",
       "      <td>def _format_json(data, theme):\\n    json_strin...</td>\n",
       "      <td>def _format_json(data, theme):\\n    import jso...</td>\n",
       "      <td>def _format_json(data, theme):\\n    \"\"\"\\n    P...</td>\n",
       "      <td>def _format_json(data, theme):\\n    \"\"\"\\n    P...</td>\n",
       "      <td>def _format_json(data, theme):\\n    \"\"\"\\n    P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d4</td>\n",
       "      <td>q4</td>\n",
       "      <td>def create_path(path):\\n    \"\"\"Creates a absol...</td>\n",
       "      <td>def create_path(path):\\n    os.makedirs(path, ...</td>\n",
       "      <td>def create_path(path):\\n    os.makedirs(path, ...</td>\n",
       "      <td>def create_path(path):\\n    os.makedirs(path, ...</td>\n",
       "      <td>def create_path(path):\\n    \"\"\"\\n    This func...</td>\n",
       "      <td>def create_path(path):\\n    \"\"\"\\n    This func...</td>\n",
       "      <td>def create_path(path):\\n    \"\"\"\\n    This func...</td>\n",
       "      <td>def create_directory(path):\\n    if not os.pat...</td>\n",
       "      <td>def create_directory(path):\\n    if not os.pat...</td>\n",
       "      <td>def create_directory(path):\\n    if not os.pat...</td>\n",
       "      <td>def create_path(path):\\n    \"\"\"\\n    Creates a...</td>\n",
       "      <td>def create_path(path):\\n    \"\"\"\\n    Creates a...</td>\n",
       "      <td>def create_path(path):\\n    \"\"\"\\n    This func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d5</td>\n",
       "      <td>q5</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    \"\"\"...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    if ...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    if ...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    if ...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    if ...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    if ...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    if ...</td>\n",
       "      <td>def convert_and_reshape(input_data, vector_typ...</td>\n",
       "      <td>def convert_and_reshape(input_data, type='row'...</td>\n",
       "      <td>def convert_and_reshape(input_data, type='row'...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    if ...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    if ...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5146</th>\n",
       "      <td>d5147</td>\n",
       "      <td>q5147</td>\n",
       "      <td>def is_symlink(self):\\n        \"\"\"\\n        Wh...</td>\n",
       "      <td>def is_symlink(path):\\n    try:\\n        st = ...</td>\n",
       "      <td>def is_symlink(path):\\n    try:\\n        stat ...</td>\n",
       "      <td>def is_symlink(path):\\n    try:\\n        retur...</td>\n",
       "      <td>def is_symlink(self):\\n    \"\"\"\\n    This funct...</td>\n",
       "      <td>def is_symlink(self):\\n    \"\"\"\\n    This funct...</td>\n",
       "      <td>def is_symlink(self):\\n    \"\"\"\\n    This funct...</td>\n",
       "      <td>def is_symlink(path):\\n    if not os.path.exis...</td>\n",
       "      <td>def is_symlink(path):\\n    try:\\n        info ...</td>\n",
       "      <td>def is_symlink(path):\\n    if not os.path.exis...</td>\n",
       "      <td>def is_symlink(self):\\n    \"\"\"...\"\"\"\\n    try:...</td>\n",
       "      <td>def is_symlink(self):\\n    \"\"\"\\n    ...\\n    \"...</td>\n",
       "      <td>def is_symlink(self):\\n    \"\"\"...\"\"\"\\n    try:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>d5148</td>\n",
       "      <td>q5148</td>\n",
       "      <td>def makedirs(path, mode=0o777, exist_ok=False)...</td>\n",
       "      <td>def makedirs(path, mode=0o777, exist_ok=False)...</td>\n",
       "      <td>def makedir(path, mode=0o777, exist_ok=False):...</td>\n",
       "      <td>def makedirs(path, mode=0o777, exist_ok=False)...</td>\n",
       "      <td>def makedirs(path, mode=0o777, exist_ok=False)...</td>\n",
       "      <td>def makedirs(path, mode=0o777, exist_ok=False)...</td>\n",
       "      <td>def makedirs(path, mode=0o777, exist_ok=False)...</td>\n",
       "      <td>def makedirs(path, mode=0o777, exist_ok=False)...</td>\n",
       "      <td>def makedirs(path, mode=0o777, exist_ok=False)...</td>\n",
       "      <td>def makedirs(path, mode=0o777, exist_ok=False)...</td>\n",
       "      <td>def makedirs(path, mode=0o777, exist_ok=False)...</td>\n",
       "      <td>def makedirs(path, mode=0o777, exist_ok=False)...</td>\n",
       "      <td>def makedirs(path, mode=0o777, exist_ok=False)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5148</th>\n",
       "      <td>d5149</td>\n",
       "      <td>q5149</td>\n",
       "      <td>def is_json_file(filename, show_warnings = Fal...</td>\n",
       "      <td>def is_json_file(file_path, file_type=\"json\", ...</td>\n",
       "      <td>def load_config(file_path, file_type, show_war...</td>\n",
       "      <td>def is_json_file(file_path, file_type=\"json\", ...</td>\n",
       "      <td>def is_json_file(filename, show_warnings = Fal...</td>\n",
       "      <td>def is_json_file(filename, show_warnings = Fal...</td>\n",
       "      <td>def is_json_file(filename, show_warnings = Fal...</td>\n",
       "      <td>def is_valid_json_file(file_path, show_warning...</td>\n",
       "      <td>def is_valid_json_file(file_path, show_warning...</td>\n",
       "      <td>def load_config(file_path):\\n    # Implementat...</td>\n",
       "      <td>def is_json_file(filename, show_warnings):\\n  ...</td>\n",
       "      <td>def is_json_file(filename, show_warnings=False...</td>\n",
       "      <td>def is_json_file(filename, show_warnings=False...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5149</th>\n",
       "      <td>d5150</td>\n",
       "      <td>q5150</td>\n",
       "      <td>async def _thread_coro(self, *args):\\n        ...</td>\n",
       "      <td>class MyClass:\\n    async def _thread_coro(sel...</td>\n",
       "      <td>def MapAsync(loop, executor, func, *args, **kw...</td>\n",
       "      <td>loop.run_in_executor(executor, func, *args, **...</td>\n",
       "      <td>_loop.run_in_executor(self._executor, self._fu...</td>\n",
       "      <td>_loop.run_in_executor(self._executor, self._fu...</td>\n",
       "      <td>_loop.run_in_executor(self._executor, self._fu...</td>\n",
       "      <td>class MyClass:\\n    def __init__(self):\\n     ...</td>\n",
       "      <td>class MyClass:\\n    def __init__(self):\\n     ...</td>\n",
       "      <td>class MyClass:\\n    def __init__(self):\\n     ...</td>\n",
       "      <td>_loop.run_in_executor(self._executor, self._fu...</td>\n",
       "      <td>_loop.run_in_executor(self._executor, self._fu...</td>\n",
       "      <td>_loop.run_in_executor(self._executor, self._fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5150</th>\n",
       "      <td>d5151</td>\n",
       "      <td>q5151</td>\n",
       "      <td>def __contains__(self, key):\\n        \"\"\"\\n   ...</td>\n",
       "      <td>def __contains__(self, key):\\n    key = self._...</td>\n",
       "      <td>def _real_key(key):\\n    return key.lower()</td>\n",
       "      <td>def __contains__(self, key):\\n    return self....</td>\n",
       "      <td>def __contains__(self, key):\\n    \"\"\"\\n    Thi...</td>\n",
       "      <td>def __contains__(self, key):\\n    \"\"\"\\n    Thi...</td>\n",
       "      <td>def __contains__(self, key):\\n    \"\"\"\\n    Thi...</td>\n",
       "      <td>def check_key(self, key):\\n    return key.lowe...</td>\n",
       "      <td>def check_key(self, key):\\n    return key.lowe...</td>\n",
       "      <td>def check_key(key):\\n    return key.lower() in...</td>\n",
       "      <td>def __contains__(self, key):\\n    k = self._re...</td>\n",
       "      <td>def __contains__(self, key):\\n    k = self._re...</td>\n",
       "      <td>def __contains__(self, key):\\n    k = self._re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5151 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     corpus_id query_id                                      Original_Code  \\\n",
       "0           d1       q1  def writeBoolean(self, n):\\n        \"\"\"\\n     ...   \n",
       "1           d2       q2  def paste(xsel=False):\\n    \"\"\"Returns system ...   \n",
       "2           d3       q3  def _format_json(data, theme):\\n    \"\"\"Pretty ...   \n",
       "3           d4       q4  def create_path(path):\\n    \"\"\"Creates a absol...   \n",
       "4           d5       q5  def _vector_or_scalar(x, type='row'):\\n    \"\"\"...   \n",
       "...        ...      ...                                                ...   \n",
       "5146     d5147    q5147  def is_symlink(self):\\n        \"\"\"\\n        Wh...   \n",
       "5147     d5148    q5148  def makedirs(path, mode=0o777, exist_ok=False)...   \n",
       "5148     d5149    q5149  def is_json_file(filename, show_warnings = Fal...   \n",
       "5149     d5150    q5150  async def _thread_coro(self, *args):\\n        ...   \n",
       "5150     d5151    q5151  def __contains__(self, key):\\n        \"\"\"\\n   ...   \n",
       "\n",
       "                         Generated_Code_granite_1_code1  \\\n",
       "0     def writeBoolean(n):\\n    if not n:\\n        r...   \n",
       "1     def paste(xsel=False):\\n    \"\"\"Returns system ...   \n",
       "2     def _format_json(data, theme):\\n    try:\\n    ...   \n",
       "3     def create_path(path):\\n    os.makedirs(path, ...   \n",
       "4     def _vector_or_scalar(x, type='row'):\\n    if ...   \n",
       "...                                                 ...   \n",
       "5146  def is_symlink(path):\\n    try:\\n        st = ...   \n",
       "5147  def makedirs(path, mode=0o777, exist_ok=False)...   \n",
       "5148  def is_json_file(file_path, file_type=\"json\", ...   \n",
       "5149  class MyClass:\\n    async def _thread_coro(sel...   \n",
       "5150  def __contains__(self, key):\\n    key = self._...   \n",
       "\n",
       "                         Generated_Code_granite_1_code2  \\\n",
       "0     def writeBoolean(self, n):\\n    if not n:\\n   ...   \n",
       "1     def paste(xsel=False):\\n    \"\"\"Returns system ...   \n",
       "2     def _format_json(data, theme):\\n    try:\\n    ...   \n",
       "3     def create_path(path):\\n    os.makedirs(path, ...   \n",
       "4     def _vector_or_scalar(x, type='row'):\\n    if ...   \n",
       "...                                                 ...   \n",
       "5146  def is_symlink(path):\\n    try:\\n        stat ...   \n",
       "5147  def makedir(path, mode=0o777, exist_ok=False):...   \n",
       "5148  def load_config(file_path, file_type, show_war...   \n",
       "5149  def MapAsync(loop, executor, func, *args, **kw...   \n",
       "5150        def _real_key(key):\\n    return key.lower()   \n",
       "\n",
       "                         Generated_Code_granite_1_code3  \\\n",
       "0     def writeBoolean(self, n):\\n    if not n:\\n   ...   \n",
       "1     def paste(xsel=False):\\n    \"\"\"Returns system ...   \n",
       "2     def _format_json(data, theme):\\n    try:\\n    ...   \n",
       "3     def create_path(path):\\n    os.makedirs(path, ...   \n",
       "4     def _vector_or_scalar(x, type='row'):\\n    if ...   \n",
       "...                                                 ...   \n",
       "5146  def is_symlink(path):\\n    try:\\n        retur...   \n",
       "5147  def makedirs(path, mode=0o777, exist_ok=False)...   \n",
       "5148  def is_json_file(file_path, file_type=\"json\", ...   \n",
       "5149  loop.run_in_executor(executor, func, *args, **...   \n",
       "5150  def __contains__(self, key):\\n    return self....   \n",
       "\n",
       "                         Generated_Code_granite_2_code1  \\\n",
       "0     def writeBoolean(self, n):\\n    \"\"\"\\n    This ...   \n",
       "1     def paste(xsel=False):\\n    \"\"\"Returns system ...   \n",
       "2     def _format_json(data, theme):\\n    \"\"\"Pretty ...   \n",
       "3     def create_path(path):\\n    \"\"\"\\n    This func...   \n",
       "4     def _vector_or_scalar(x, type='row'):\\n    if ...   \n",
       "...                                                 ...   \n",
       "5146  def is_symlink(self):\\n    \"\"\"\\n    This funct...   \n",
       "5147  def makedirs(path, mode=0o777, exist_ok=False)...   \n",
       "5148  def is_json_file(filename, show_warnings = Fal...   \n",
       "5149  _loop.run_in_executor(self._executor, self._fu...   \n",
       "5150  def __contains__(self, key):\\n    \"\"\"\\n    Thi...   \n",
       "\n",
       "                         Generated_Code_granite_2_code2  \\\n",
       "0     def writeBoolean(self, n):\\n    \"\"\"\\n    This ...   \n",
       "1     def paste(xsel=False):\\n    \"\"\"Returns system ...   \n",
       "2     def _format_json(data, theme):\\n    \"\"\"Pretty ...   \n",
       "3     def create_path(path):\\n    \"\"\"\\n    This func...   \n",
       "4     def _vector_or_scalar(x, type='row'):\\n    if ...   \n",
       "...                                                 ...   \n",
       "5146  def is_symlink(self):\\n    \"\"\"\\n    This funct...   \n",
       "5147  def makedirs(path, mode=0o777, exist_ok=False)...   \n",
       "5148  def is_json_file(filename, show_warnings = Fal...   \n",
       "5149  _loop.run_in_executor(self._executor, self._fu...   \n",
       "5150  def __contains__(self, key):\\n    \"\"\"\\n    Thi...   \n",
       "\n",
       "                         Generated_Code_granite_2_code3  \\\n",
       "0     def writeBoolean(self, n):\\n    \"\"\"\\n    This ...   \n",
       "1     def paste(xsel=False):\\n    \"\"\"Returns system ...   \n",
       "2     def _format_json(data, theme):\\n    \"\"\"Pretty ...   \n",
       "3     def create_path(path):\\n    \"\"\"\\n    This func...   \n",
       "4     def _vector_or_scalar(x, type='row'):\\n    if ...   \n",
       "...                                                 ...   \n",
       "5146  def is_symlink(self):\\n    \"\"\"\\n    This funct...   \n",
       "5147  def makedirs(path, mode=0o777, exist_ok=False)...   \n",
       "5148  def is_json_file(filename, show_warnings = Fal...   \n",
       "5149  _loop.run_in_executor(self._executor, self._fu...   \n",
       "5150  def __contains__(self, key):\\n    \"\"\"\\n    Thi...   \n",
       "\n",
       "                         Generated_Code_granite_3_code1  \\\n",
       "0     def write_bool(stream, n):\\n    t = 'True' if ...   \n",
       "1     def get_clipboard():\\n    try:\\n        if xse...   \n",
       "2     def _format_json(data, theme):\\n    json_strin...   \n",
       "3     def create_directory(path):\\n    if not os.pat...   \n",
       "4     def convert_and_reshape(input_data, vector_typ...   \n",
       "...                                                 ...   \n",
       "5146  def is_symlink(path):\\n    if not os.path.exis...   \n",
       "5147  def makedirs(path, mode=0o777, exist_ok=False)...   \n",
       "5148  def is_valid_json_file(file_path, show_warning...   \n",
       "5149  class MyClass:\\n    def __init__(self):\\n     ...   \n",
       "5150  def check_key(self, key):\\n    return key.lowe...   \n",
       "\n",
       "                         Generated_Code_granite_3_code2  \\\n",
       "0     def write_bool(stream, n):\\n    t = 'True' if ...   \n",
       "1     def get_clipboard():\\n    try:\\n        if xse...   \n",
       "2     def _format_json(data, theme):\\n    json_strin...   \n",
       "3     def create_directory(path):\\n    if not os.pat...   \n",
       "4     def convert_and_reshape(input_data, type='row'...   \n",
       "...                                                 ...   \n",
       "5146  def is_symlink(path):\\n    try:\\n        info ...   \n",
       "5147  def makedirs(path, mode=0o777, exist_ok=False)...   \n",
       "5148  def is_valid_json_file(file_path, show_warning...   \n",
       "5149  class MyClass:\\n    def __init__(self):\\n     ...   \n",
       "5150  def check_key(self, key):\\n    return key.lowe...   \n",
       "\n",
       "                         Generated_Code_granite_3_code3  \\\n",
       "0     def write_bool(stream, n):\\n    t = 'True' if ...   \n",
       "1     def get_clipboard():\\n    try:\\n        if xse...   \n",
       "2     def _format_json(data, theme):\\n    import jso...   \n",
       "3     def create_directory(path):\\n    if not os.pat...   \n",
       "4     def convert_and_reshape(input_data, type='row'...   \n",
       "...                                                 ...   \n",
       "5146  def is_symlink(path):\\n    if not os.path.exis...   \n",
       "5147  def makedirs(path, mode=0o777, exist_ok=False)...   \n",
       "5148  def load_config(file_path):\\n    # Implementat...   \n",
       "5149  class MyClass:\\n    def __init__(self):\\n     ...   \n",
       "5150  def check_key(key):\\n    return key.lower() in...   \n",
       "\n",
       "                         Generated_Code_granite_4_code1  \\\n",
       "0     def writeBoolean(self, n):\\n    \"\"\"\\n    Write...   \n",
       "1     def paste(xsel=False):\\n    try:\\n        if x...   \n",
       "2     def _format_json(data, theme):\\n    \"\"\"\\n    P...   \n",
       "3     def create_path(path):\\n    \"\"\"\\n    Creates a...   \n",
       "4     def _vector_or_scalar(x, type='row'):\\n    if ...   \n",
       "...                                                 ...   \n",
       "5146  def is_symlink(self):\\n    \"\"\"...\"\"\"\\n    try:...   \n",
       "5147  def makedirs(path, mode=0o777, exist_ok=False)...   \n",
       "5148  def is_json_file(filename, show_warnings):\\n  ...   \n",
       "5149  _loop.run_in_executor(self._executor, self._fu...   \n",
       "5150  def __contains__(self, key):\\n    k = self._re...   \n",
       "\n",
       "                         Generated_Code_granite_4_code2  \\\n",
       "0     def writeBoolean(self, n):\\n    \"\"\"Writes a Bo...   \n",
       "1     def paste(xsel=False):\\n    try:\\n        if x...   \n",
       "2     def _format_json(data, theme):\\n    \"\"\"\\n    P...   \n",
       "3     def create_path(path):\\n    \"\"\"\\n    Creates a...   \n",
       "4     def _vector_or_scalar(x, type='row'):\\n    if ...   \n",
       "...                                                 ...   \n",
       "5146  def is_symlink(self):\\n    \"\"\"\\n    ...\\n    \"...   \n",
       "5147  def makedirs(path, mode=0o777, exist_ok=False)...   \n",
       "5148  def is_json_file(filename, show_warnings=False...   \n",
       "5149  _loop.run_in_executor(self._executor, self._fu...   \n",
       "5150  def __contains__(self, key):\\n    k = self._re...   \n",
       "\n",
       "                         Generated_Code_granite_4_code3  \n",
       "0     def writeBoolean(self, n):\\n    \"\"\"\\n    Write...  \n",
       "1     def paste(xsel=False):\\n    try:\\n        if x...  \n",
       "2     def _format_json(data, theme):\\n    \"\"\"\\n    P...  \n",
       "3     def create_path(path):\\n    \"\"\"\\n    This func...  \n",
       "4     def _vector_or_scalar(x, type='row'):\\n    if ...  \n",
       "...                                                 ...  \n",
       "5146  def is_symlink(self):\\n    \"\"\"...\"\"\"\\n    try:...  \n",
       "5147  def makedirs(path, mode=0o777, exist_ok=False)...  \n",
       "5148  def is_json_file(filename, show_warnings=False...  \n",
       "5149  _loop.run_in_executor(self._executor, self._fu...  \n",
       "5150  def __contains__(self, key):\\n    k = self._re...  \n",
       "\n",
       "[5151 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/granite_cleaned_code_results_dir/split_part_0_results_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "t=pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/codebleusample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>Original_Code</th>\n",
       "      <th>Generated_Code_deepseek_1_code1</th>\n",
       "      <th>Generated_Code_deepseek_1_code2</th>\n",
       "      <th>Generated_Code_deepseek_1_code3</th>\n",
       "      <th>Generated_Code_deepseek_2_code1</th>\n",
       "      <th>Generated_Code_deepseek_2_code2</th>\n",
       "      <th>Generated_Code_deepseek_2_code3</th>\n",
       "      <th>Generated_Code_deepseek_3_code1</th>\n",
       "      <th>...</th>\n",
       "      <th>CodeBLEU_Score_deepseek_2_code2</th>\n",
       "      <th>CodeBLEU_Score_deepseek_2_code3</th>\n",
       "      <th>CodeBLEU_Score_deepseek_3_code1</th>\n",
       "      <th>CodeBLEU_Score_deepseek_3_code2</th>\n",
       "      <th>CodeBLEU_Score_deepseek_3_code3</th>\n",
       "      <th>CodeBLEU_Score_deepseek_4_code1</th>\n",
       "      <th>CodeBLEU_Score_deepseek_4_code2</th>\n",
       "      <th>CodeBLEU_Score_deepseek_4_code3</th>\n",
       "      <th>RTC_deepseek_CodeBLEU_Score</th>\n",
       "      <th>Pass@1_deepseek_CodeBLEU_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1</td>\n",
       "      <td>q1</td>\n",
       "      <td>def writeBoolean(self, n):\\n        \"\"\"\\n     ...</td>\n",
       "      <td>def flip_stream(condition):\\n    # code</td>\n",
       "      <td>def f(n):\\n    # ... code ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def writeBoolean(self, n):\\n    t = TYPE_BOOL</td>\n",
       "      <td>def writeBoolean(self, n):\\n    t = TYPE_BOOL_...</td>\n",
       "      <td>def writeBoolean(self, n):\\n    t = TYPE_BOOL_...</td>\n",
       "      <td>def writeBoolean(n):\\n    t = TYPE_BOOL_TRUE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507716</td>\n",
       "      <td>0.553623</td>\n",
       "      <td>0.050869</td>\n",
       "      <td>0.088725</td>\n",
       "      <td>0.113273</td>\n",
       "      <td>0.373600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147562</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2</td>\n",
       "      <td>q2</td>\n",
       "      <td>def paste(xsel=False):\\n    \"\"\"Returns system ...</td>\n",
       "      <td>def paste(xsel=False):\\n    selection = \"prima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def paste(xsel=False):\\n\\n    \"\"\"Pastes data f...</td>\n",
       "      <td>def paste(xsel=None):\\n    # Line 2: set selec...</td>\n",
       "      <td>def paste(xsel=None):\\n    # ... code here ...</td>\n",
       "      <td>def paste(xsel=None):\\n    if xsel is None:\\n ...</td>\n",
       "      <td>def paste(xsel=None):\\n    if xsel is not None...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059629</td>\n",
       "      <td>0.363184</td>\n",
       "      <td>0.092915</td>\n",
       "      <td>0.192409</td>\n",
       "      <td>0.057818</td>\n",
       "      <td>0.066185</td>\n",
       "      <td>0.070713</td>\n",
       "      <td>0.057818</td>\n",
       "      <td>0.142211</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  corpus_id query_id                                      Original_Code  \\\n",
       "0        d1       q1  def writeBoolean(self, n):\\n        \"\"\"\\n     ...   \n",
       "1        d2       q2  def paste(xsel=False):\\n    \"\"\"Returns system ...   \n",
       "\n",
       "                     Generated_Code_deepseek_1_code1  \\\n",
       "0            def flip_stream(condition):\\n    # code   \n",
       "1  def paste(xsel=False):\\n    selection = \"prima...   \n",
       "\n",
       "  Generated_Code_deepseek_1_code2  \\\n",
       "0   def f(n):\\n    # ... code ...   \n",
       "1                             NaN   \n",
       "\n",
       "                     Generated_Code_deepseek_1_code3  \\\n",
       "0                                                NaN   \n",
       "1  def paste(xsel=False):\\n\\n    \"\"\"Pastes data f...   \n",
       "\n",
       "                     Generated_Code_deepseek_2_code1  \\\n",
       "0      def writeBoolean(self, n):\\n    t = TYPE_BOOL   \n",
       "1  def paste(xsel=None):\\n    # Line 2: set selec...   \n",
       "\n",
       "                     Generated_Code_deepseek_2_code2  \\\n",
       "0  def writeBoolean(self, n):\\n    t = TYPE_BOOL_...   \n",
       "1     def paste(xsel=None):\\n    # ... code here ...   \n",
       "\n",
       "                     Generated_Code_deepseek_2_code3  \\\n",
       "0  def writeBoolean(self, n):\\n    t = TYPE_BOOL_...   \n",
       "1  def paste(xsel=None):\\n    if xsel is None:\\n ...   \n",
       "\n",
       "                     Generated_Code_deepseek_3_code1  ...  \\\n",
       "0       def writeBoolean(n):\\n    t = TYPE_BOOL_TRUE  ...   \n",
       "1  def paste(xsel=None):\\n    if xsel is not None...  ...   \n",
       "\n",
       "  CodeBLEU_Score_deepseek_2_code2 CodeBLEU_Score_deepseek_2_code3  \\\n",
       "0                        0.507716                        0.553623   \n",
       "1                        0.059629                        0.363184   \n",
       "\n",
       "  CodeBLEU_Score_deepseek_3_code1 CodeBLEU_Score_deepseek_3_code2  \\\n",
       "0                        0.050869                        0.088725   \n",
       "1                        0.092915                        0.192409   \n",
       "\n",
       "  CodeBLEU_Score_deepseek_3_code3  CodeBLEU_Score_deepseek_4_code1  \\\n",
       "0                        0.113273                         0.373600   \n",
       "1                        0.057818                         0.066185   \n",
       "\n",
       "   CodeBLEU_Score_deepseek_4_code2  CodeBLEU_Score_deepseek_4_code3  \\\n",
       "0                         0.000000                         0.000000   \n",
       "1                         0.070713                         0.057818   \n",
       "\n",
       "   RTC_deepseek_CodeBLEU_Score  Pass@1_deepseek_CodeBLEU_Score  \n",
       "0                     0.147562                             0.0  \n",
       "1                     0.142211                             0.0  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanations 4 code 1 Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7988853255083227, 0.4788875946418171)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_1/metrics/deepseek_codebert_metrics_results.csv\")\n",
    "df[\"RTC_deepseek_CodeBERT_Score\"].mean(), df[\"Pass@1_deepseek_CodeBERT_Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8181990188456257, 0.5276645311589983)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_1/metrics/granite_codebert_metrics_results.csv\")\n",
    "df[\"RTC_granite_CodeBERT_Score\"].mean(), df[\"Pass@1_granite_CodeBERT_Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19067342299863155, 0.002899922345175694)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_1/metrics/deepseek_codebleu_metrics_results.csv\")\n",
    "df[\"RTC_deepseek_CodeBLEU_Score\"].mean(), df[\"Pass@1_deepseek_CodeBLEU_Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2808076462208245, 0.0005217433508056688)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_1/metrics/granite_codebleu_metrics_results.csv\")\n",
    "df[\"RTC_granite_CodeBLEU_Score\"].mean(), df[\"Pass@1_granite_CodeBLEU_Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5533682343234323, 0.08770141720054359)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_1/metrics/deepseek_struct_metrics_results.csv\")\n",
    "df[\"RTC_deepseek_Struct_Score\"].mean(), df[\"Pass@1_deepseek_Struct_Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5454818190642593, 0.08141622985827994)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_1/metrics/granite_struct_metrics_results.csv\")\n",
    "df[\"RTC_granite_Struct_Score\"].mean(), df[\"Pass@1_granite_Struct_Score\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanations 4 Code 3 Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6938504823207198, 0.4252612761276128)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "final=[]\n",
    "folder = \"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/metrics/deepseek_codebert_metrics_results_dir/\"\n",
    "for file in os.listdir(folder):\n",
    "    df = pd.read_csv(folder+file)\n",
    "    final.append(df)\n",
    "combined_df = pd.concat(final, ignore_index=True)\n",
    "\n",
    "combined_df[\"RTC_deepseek_CodeBERT_Score\"].mean(), combined_df[\"Pass@1_deepseek_CodeBERT_Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('def writeBoolean(self, n):\\n        t = TYPE_BOOL_TRUE\\n        if n is False:\\n            t = TYPE_BOOL_FALSE\\n        self.stream.write(t)',\n",
       " '        \"\"\"\\n        Writes a Boolean to the stream.\\n        \"\"\"')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/cleanedsample.csv\")\n",
    "test[\"Original_Code\"][0], test[\"Original_Code_comments\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8446780312333867, 0.7549100498285123)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "final=[]\n",
    "folder = \"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/metrics/granite_codebert_metrics_results_dir/\"\n",
    "for file in os.listdir(folder):\n",
    "    df = pd.read_csv(folder+file)\n",
    "    final.append(df)\n",
    "combined_df = pd.concat(final, ignore_index=True)\n",
    "\n",
    "combined_df[\"RTC_granite_CodeBERT_Score\"].mean(), combined_df[\"Pass@1_granite_CodeBERT_Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1762703079252538, 0.01751682521193296)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/metrics/deepseek_codebleu_metrics_results.csv\")\n",
    "df[\"RTC_deepseek_CodeBLEU_Score\"].mean(), df[\"Pass@1_deepseek_CodeBLEU_Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3679706074539154, 0.12515369183977226)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/metrics/granite_codebleu_metrics_results.csv\")\n",
    "df[\"RTC_granite_CodeBLEU_Score\"].mean(), df[\"Pass@1_granite_CodeBLEU_Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5034404193360513, 0.2888595612502427)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/metrics/deepseek_struct_metrics_results.csv\")\n",
    "df[\"RTC_deepseek_Struct_Score\"].mean(), df[\"Pass@1_deepseek_Struct_Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7545834595224229, 0.5597583721607454)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/metrics/granite_struct_metrics_results.csv\")\n",
    "df[\"RTC_granite_Struct_Score\"].mean(), df[\"Pass@1_granite_Struct_Score\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanations 4 Code 3 - Removed Comments from Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_id</th>\n",
       "      <th>query_id</th>\n",
       "      <th>Original_Code</th>\n",
       "      <th>Generated_Code_deepseek_1_code1</th>\n",
       "      <th>Generated_Code_deepseek_1_code2</th>\n",
       "      <th>Generated_Code_deepseek_1_code3</th>\n",
       "      <th>Generated_Code_deepseek_2_code1</th>\n",
       "      <th>Generated_Code_deepseek_2_code2</th>\n",
       "      <th>Generated_Code_deepseek_2_code3</th>\n",
       "      <th>Generated_Code_deepseek_3_code1</th>\n",
       "      <th>...</th>\n",
       "      <th>CodeBERT_Score_deepseek_3_code_3</th>\n",
       "      <th>Exact_Match_deepseek_3_code_3</th>\n",
       "      <th>CodeBERT_Score_deepseek_4_code_1</th>\n",
       "      <th>Exact_Match_deepseek_4_code_1</th>\n",
       "      <th>CodeBERT_Score_deepseek_4_code_2</th>\n",
       "      <th>Exact_Match_deepseek_4_code_2</th>\n",
       "      <th>CodeBERT_Score_deepseek_4_code_3</th>\n",
       "      <th>Exact_Match_deepseek_4_code_3</th>\n",
       "      <th>RTC_deepseek_CodeBERT_Score</th>\n",
       "      <th>Pass@1_deepseek_CodeBERT_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1</td>\n",
       "      <td>q1</td>\n",
       "      <td>def writeBoolean(self, n):\\n        \"\"\"\\n     ...</td>\n",
       "      <td>def flip_stream(condition):\\n    # code</td>\n",
       "      <td>def f(n):\\n    # ... code ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def writeBoolean(self, n):\\n    t = TYPE_BOOL</td>\n",
       "      <td>def writeBoolean(self, n):\\n    t = TYPE_BOOL_...</td>\n",
       "      <td>def writeBoolean(self, n):\\n    t = TYPE_BOOL_...</td>\n",
       "      <td>def writeBoolean(n):\\n    t = TYPE_BOOL_TRUE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d2</td>\n",
       "      <td>q2</td>\n",
       "      <td>def paste(xsel=False):\\n    \"\"\"Returns system ...</td>\n",
       "      <td>def paste(xsel=False):\\n    selection = \"prima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def paste(xsel=False):\\n\\n    \"\"\"Pastes data f...</td>\n",
       "      <td>def paste(xsel=None):\\n    # Line 2: set selec...</td>\n",
       "      <td>def paste(xsel=None):\\n    # ... code here ...</td>\n",
       "      <td>def paste(xsel=None):\\n    if xsel is None:\\n ...</td>\n",
       "      <td>def paste(xsel=None):\\n    if xsel is not None...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d3</td>\n",
       "      <td>q3</td>\n",
       "      <td>def _format_json(data, theme):\\n    \"\"\"Pretty ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    return jso...</td>\n",
       "      <td>def format_json(data, theme):\\n    # ... code ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    # Code\\n  ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    output = j...</td>\n",
       "      <td>pygments.highlight(output, JsonLexer()</td>\n",
       "      <td>def _format_json(data, theme):\\n    \"\"\"Pretty ...</td>\n",
       "      <td>def _format_json(data, theme):\\n    try:\\n    ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d4</td>\n",
       "      <td>q4</td>\n",
       "      <td>def create_path(path):\\n    \"\"\"Creates a absol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def f(a, b, c, d, e, f, g, h, i, j, k, l, m, n...</td>\n",
       "      <td>def absolute_path(relative_path):\\n    # code ...</td>\n",
       "      <td>def create_path(path):\\n    if not os.path.exi...</td>\n",
       "      <td>def create_path(path):\\n    if os.path.isabs(p...</td>\n",
       "      <td>def create_path(path):\\n    # Check if the pat...</td>\n",
       "      <td>def file_path(file_path):\\n    # ... code ...\\...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d5</td>\n",
       "      <td>q5</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    \"\"\"...</td>\n",
       "      <td>def check_array(x):\\n    # code here\\n    retu...</td>\n",
       "      <td>np.array(x)</td>\n",
       "      <td>def array_to_column_vector(x):\\n    # Check if...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    if ...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    if ...</td>\n",
       "      <td>def _vector_or_scalar(x, type='row'):\\n    # c...</td>\n",
       "      <td>np.column_stack()</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d6</td>\n",
       "      <td>q6</td>\n",
       "      <td>def experiment_property(prop):\\n    \"\"\"Get a p...</td>\n",
       "      <td>def get_property(obj, prop):\\n    # code here\\...</td>\n",
       "      <td>def get_property(obj, property_name):\\n    # ....</td>\n",
       "      <td>def get_property(object, property_name):\\n    ...</td>\n",
       "      <td>def experiment_property(prop):\\n    exp = expe...</td>\n",
       "      <td>def experiment_property(prop, exp=None):\\n    ...</td>\n",
       "      <td>def experiment_property(prop, session):\\n    e...</td>\n",
       "      <td>def experiment_property(prop):\\n    # code\\n  ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d7</td>\n",
       "      <td>q7</td>\n",
       "      <td>def data_from_file(file):\\n    \"\"\"Return (firs...</td>\n",
       "      <td>def extract_and_interleave_wav_file(wav_file):...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>struct.unpack()</td>\n",
       "      <td>struct.unpack()</td>\n",
       "      <td>fp.getnframes()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>d8</td>\n",
       "      <td>q8</td>\n",
       "      <td>def source_range(start, end, nr_var_dict):\\n  ...</td>\n",
       "      <td>def process_range(start, end, source_range_tup...</td>\n",
       "      <td>def f(k, e):\\n    # ... code here ...\\n    # ....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def source_range(start, end, nr_var_dict):\\n  ...</td>\n",
       "      <td>def source_range(start, end, nr_var_dict):\\n  ...</td>\n",
       "      <td>def source_range(start, end, nr_var_dict):\\n  ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>d9</td>\n",
       "      <td>q9</td>\n",
       "      <td>def timespan(start_time):\\n    \"\"\"Return time ...</td>\n",
       "      <td>def timespan(start_time, current_time):\\n    r...</td>\n",
       "      <td>def timespan(start_time):\\n    # ... code ...</td>\n",
       "      <td>def timespan(start_time, current_time):\\n    #...</td>\n",
       "      <td>def timespan(start_time):\\n    \"\"\"Return time ...</td>\n",
       "      <td>timespan.total_seconds()</td>\n",
       "      <td>def timespan(start_time):\\n    \"\"\"\"\"\"\\n    tim...</td>\n",
       "      <td>def timespan(start_time):\\n    current_time = ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d10</td>\n",
       "      <td>q10</td>\n",
       "      <td>def _convert_to_array(array_like, dtype):\\n   ...</td>\n",
       "      <td>def convert_to_char_array(array_like_or_buffer...</td>\n",
       "      <td>def f(arr):\\n    # code here\\n    # no return ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def _convert_to_array(array_like, dtype):\\n   ...</td>\n",
       "      <td>def _convert_to_array(array_like, dtype):\\n   ...</td>\n",
       "      <td>def _convert_to_array(array_like, dtype):\\n   ...</td>\n",
       "      <td>def convert_to_char(arr):\\n    if isinstance(a...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  corpus_id query_id                                      Original_Code  \\\n",
       "0        d1       q1  def writeBoolean(self, n):\\n        \"\"\"\\n     ...   \n",
       "1        d2       q2  def paste(xsel=False):\\n    \"\"\"Returns system ...   \n",
       "2        d3       q3  def _format_json(data, theme):\\n    \"\"\"Pretty ...   \n",
       "3        d4       q4  def create_path(path):\\n    \"\"\"Creates a absol...   \n",
       "4        d5       q5  def _vector_or_scalar(x, type='row'):\\n    \"\"\"...   \n",
       "5        d6       q6  def experiment_property(prop):\\n    \"\"\"Get a p...   \n",
       "6        d7       q7  def data_from_file(file):\\n    \"\"\"Return (firs...   \n",
       "7        d8       q8  def source_range(start, end, nr_var_dict):\\n  ...   \n",
       "8        d9       q9  def timespan(start_time):\\n    \"\"\"Return time ...   \n",
       "9       d10      q10  def _convert_to_array(array_like, dtype):\\n   ...   \n",
       "\n",
       "                     Generated_Code_deepseek_1_code1  \\\n",
       "0            def flip_stream(condition):\\n    # code   \n",
       "1  def paste(xsel=False):\\n    selection = \"prima...   \n",
       "2  def _format_json(data, theme):\\n    return jso...   \n",
       "3                                                NaN   \n",
       "4  def check_array(x):\\n    # code here\\n    retu...   \n",
       "5  def get_property(obj, prop):\\n    # code here\\...   \n",
       "6  def extract_and_interleave_wav_file(wav_file):...   \n",
       "7  def process_range(start, end, source_range_tup...   \n",
       "8  def timespan(start_time, current_time):\\n    r...   \n",
       "9  def convert_to_char_array(array_like_or_buffer...   \n",
       "\n",
       "                     Generated_Code_deepseek_1_code2  \\\n",
       "0                      def f(n):\\n    # ... code ...   \n",
       "1                                                NaN   \n",
       "2  def format_json(data, theme):\\n    # ... code ...   \n",
       "3  def f(a, b, c, d, e, f, g, h, i, j, k, l, m, n...   \n",
       "4                                        np.array(x)   \n",
       "5  def get_property(obj, property_name):\\n    # ....   \n",
       "6                                                NaN   \n",
       "7  def f(k, e):\\n    # ... code here ...\\n    # ....   \n",
       "8      def timespan(start_time):\\n    # ... code ...   \n",
       "9  def f(arr):\\n    # code here\\n    # no return ...   \n",
       "\n",
       "                     Generated_Code_deepseek_1_code3  \\\n",
       "0                                                NaN   \n",
       "1  def paste(xsel=False):\\n\\n    \"\"\"Pastes data f...   \n",
       "2  def _format_json(data, theme):\\n    # Code\\n  ...   \n",
       "3  def absolute_path(relative_path):\\n    # code ...   \n",
       "4  def array_to_column_vector(x):\\n    # Check if...   \n",
       "5  def get_property(object, property_name):\\n    ...   \n",
       "6                                                NaN   \n",
       "7                                                NaN   \n",
       "8  def timespan(start_time, current_time):\\n    #...   \n",
       "9                                                NaN   \n",
       "\n",
       "                     Generated_Code_deepseek_2_code1  \\\n",
       "0      def writeBoolean(self, n):\\n    t = TYPE_BOOL   \n",
       "1  def paste(xsel=None):\\n    # Line 2: set selec...   \n",
       "2  def _format_json(data, theme):\\n    output = j...   \n",
       "3  def create_path(path):\\n    if not os.path.exi...   \n",
       "4  def _vector_or_scalar(x, type='row'):\\n    if ...   \n",
       "5  def experiment_property(prop):\\n    exp = expe...   \n",
       "6                                    struct.unpack()   \n",
       "7                                                NaN   \n",
       "8  def timespan(start_time):\\n    \"\"\"Return time ...   \n",
       "9  def _convert_to_array(array_like, dtype):\\n   ...   \n",
       "\n",
       "                     Generated_Code_deepseek_2_code2  \\\n",
       "0  def writeBoolean(self, n):\\n    t = TYPE_BOOL_...   \n",
       "1     def paste(xsel=None):\\n    # ... code here ...   \n",
       "2             pygments.highlight(output, JsonLexer()   \n",
       "3  def create_path(path):\\n    if os.path.isabs(p...   \n",
       "4  def _vector_or_scalar(x, type='row'):\\n    if ...   \n",
       "5  def experiment_property(prop, exp=None):\\n    ...   \n",
       "6                                    struct.unpack()   \n",
       "7  def source_range(start, end, nr_var_dict):\\n  ...   \n",
       "8                           timespan.total_seconds()   \n",
       "9  def _convert_to_array(array_like, dtype):\\n   ...   \n",
       "\n",
       "                     Generated_Code_deepseek_2_code3  \\\n",
       "0  def writeBoolean(self, n):\\n    t = TYPE_BOOL_...   \n",
       "1  def paste(xsel=None):\\n    if xsel is None:\\n ...   \n",
       "2  def _format_json(data, theme):\\n    \"\"\"Pretty ...   \n",
       "3  def create_path(path):\\n    # Check if the pat...   \n",
       "4  def _vector_or_scalar(x, type='row'):\\n    # c...   \n",
       "5  def experiment_property(prop, session):\\n    e...   \n",
       "6                                    fp.getnframes()   \n",
       "7  def source_range(start, end, nr_var_dict):\\n  ...   \n",
       "8  def timespan(start_time):\\n    \"\"\"\"\"\"\\n    tim...   \n",
       "9  def _convert_to_array(array_like, dtype):\\n   ...   \n",
       "\n",
       "                     Generated_Code_deepseek_3_code1  ...  \\\n",
       "0       def writeBoolean(n):\\n    t = TYPE_BOOL_TRUE  ...   \n",
       "1  def paste(xsel=None):\\n    if xsel is not None...  ...   \n",
       "2  def _format_json(data, theme):\\n    try:\\n    ...  ...   \n",
       "3  def file_path(file_path):\\n    # ... code ...\\...  ...   \n",
       "4                                  np.column_stack()  ...   \n",
       "5  def experiment_property(prop):\\n    # code\\n  ...  ...   \n",
       "6                                                NaN  ...   \n",
       "7  def source_range(start, end, nr_var_dict):\\n  ...  ...   \n",
       "8  def timespan(start_time):\\n    current_time = ...  ...   \n",
       "9  def convert_to_char(arr):\\n    if isinstance(a...  ...   \n",
       "\n",
       "  CodeBERT_Score_deepseek_3_code_3 Exact_Match_deepseek_3_code_3  \\\n",
       "0                              0.0                         False   \n",
       "1                              0.0                         False   \n",
       "2                              0.0                         False   \n",
       "3                              0.0                         False   \n",
       "4                              0.0                         False   \n",
       "5                              0.0                         False   \n",
       "6                              0.0                         False   \n",
       "7                              0.0                         False   \n",
       "8                              0.0                         False   \n",
       "9                              0.0                         False   \n",
       "\n",
       "  CodeBERT_Score_deepseek_4_code_1 Exact_Match_deepseek_4_code_1  \\\n",
       "0                              0.0                         False   \n",
       "1                              0.0                         False   \n",
       "2                              0.0                         False   \n",
       "3                              0.0                         False   \n",
       "4                              0.0                         False   \n",
       "5                              0.0                         False   \n",
       "6                              0.0                         False   \n",
       "7                              0.0                         False   \n",
       "8                              0.0                         False   \n",
       "9                              0.0                         False   \n",
       "\n",
       "  CodeBERT_Score_deepseek_4_code_2  Exact_Match_deepseek_4_code_2  \\\n",
       "0                              0.0                          False   \n",
       "1                              0.0                          False   \n",
       "2                              0.0                          False   \n",
       "3                              0.0                          False   \n",
       "4                              0.0                          False   \n",
       "5                              0.0                          False   \n",
       "6                              0.0                          False   \n",
       "7                              0.0                          False   \n",
       "8                              0.0                          False   \n",
       "9                              0.0                          False   \n",
       "\n",
       "   CodeBERT_Score_deepseek_4_code_3  Exact_Match_deepseek_4_code_3  \\\n",
       "0                               0.0                          False   \n",
       "1                               0.0                          False   \n",
       "2                               0.0                          False   \n",
       "3                               0.0                          False   \n",
       "4                               0.0                          False   \n",
       "5                               0.0                          False   \n",
       "6                               0.0                          False   \n",
       "7                               0.0                          False   \n",
       "8                               0.0                          False   \n",
       "9                               0.0                          False   \n",
       "\n",
       "   RTC_deepseek_CodeBERT_Score  Pass@1_deepseek_CodeBERT_Score  \n",
       "0                          0.0                             0.0  \n",
       "1                          0.0                             0.0  \n",
       "2                          0.0                             0.0  \n",
       "3                          0.0                             0.0  \n",
       "4                          0.0                             0.0  \n",
       "5                          0.0                             0.0  \n",
       "6                          0.0                             0.0  \n",
       "7                          0.0                             0.0  \n",
       "8                          0.0                             0.0  \n",
       "9                          0.0                             0.0  \n",
       "\n",
       "[10 rows x 41 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/codebertsample.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23075010677548258, 0.08677926616191033)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "final=[]\n",
    "folder = \"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/metrics/deepseek_codebleu_metrics_results_dir2/\"\n",
    "for file in os.listdir(folder):\n",
    "    df = pd.read_csv(folder+file)\n",
    "    final.append(df)\n",
    "combined_df = pd.concat(final, ignore_index=True)\n",
    "\n",
    "combined_df[\"RTC_deepseek_CodeBLEU_Score\"].mean(), combined_df[\"Pass@1_deepseek_CodeBLEU_Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43083045557768157, 0.23423849737914967)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "final=[]\n",
    "folder = \"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/metrics/granite_codebleu_metrics_results_dir2/\"\n",
    "for file in os.listdir(folder):\n",
    "    df = pd.read_csv(folder+file)\n",
    "    final.append(df)\n",
    "combined_df = pd.concat(final, ignore_index=True)\n",
    "\n",
    "combined_df[\"RTC_granite_CodeBLEU_Score\"].mean(), combined_df[\"Pass@1_granite_CodeBLEU_Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5008180887206367, 0.2964793438167346)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "final=[]\n",
    "folder = \"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/metrics/deepseek_struct_metrics_results_dir2/\"\n",
    "for file in os.listdir(folder):\n",
    "    df = pd.read_csv(folder+file)\n",
    "    final.append(df)\n",
    "combined_df = pd.concat(final, ignore_index=True)\n",
    "\n",
    "combined_df[\"RTC_deepseek_Struct_Score\"].mean(), combined_df[\"Pass@1_deepseek_Struct_Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.720783357600466, 0.5717587458745874)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "final=[]\n",
    "folder = \"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/metrics/granite_struct_metrics_results_dir2/\"\n",
    "for file in os.listdir(folder):\n",
    "    df = pd.read_csv(folder+file)\n",
    "    final.append(df)\n",
    "combined_df = pd.concat(final, ignore_index=True)\n",
    "\n",
    "combined_df[\"RTC_granite_Struct_Score\"].mean(), combined_df[\"Pass@1_granite_Struct_Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.79225653401665, 0.7413393300114326)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "final=[]\n",
    "folder = \"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/metrics/granite_codebert_metrics_results_dir2/\"\n",
    "for file in os.listdir(folder):\n",
    "    df = pd.read_csv(folder+file)\n",
    "    final.append(df)\n",
    "combined_df = pd.concat(final, ignore_index=True)\n",
    "\n",
    "combined_df[\"RTC_granite_CodeBERT_Score\"].mean(), combined_df[\"Pass@1_granite_CodeBERT_Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.700403080274779, 0.48196143143726144)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "final=[]\n",
    "folder = \"/work/pi_wenlongzhao_umass_edu/27/janet/validation_tool/RTC/results/explanations_4_codes_3/metrics/deepseek_codebert_metrics_results_dir2/\"\n",
    "for file in os.listdir(folder):\n",
    "    df = pd.read_csv(folder+file)\n",
    "    final.append(df)\n",
    "combined_df = pd.concat(final, ignore_index=True)\n",
    "\n",
    "combined_df[\"RTC_deepseek_CodeBERT_Score\"].mean(), combined_df[\"Pass@1_deepseek_CodeBERT_Score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
